Log file created at: 2020/11/04 23:37:20
Running on machine: lin-MS-7B47
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1104 23:37:20.260721 12945 caffe.cpp:218] Using GPUs 0
I1104 23:37:20.273633 12945 caffe.cpp:223] GPU 0: GeForce GTX 1080 Ti
I1104 23:37:20.436988 12945 solver.cpp:44] Initializing solver from parameters: 
train_net: "./alexnet-train-dy.prototxt"
test_net: "./alexnet-test-dy.prototxt"
test_iter: 1
test_interval: 5000
base_lr: 0.01
display: 100
max_iter: 20000
lr_policy: "triangular"
power: 1
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "./snapshot/1/alex-dy"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
test_initialization: false
split_iter: 2000
I1104 23:37:20.437085 12945 solver.cpp:77] Creating training net from train_net file: ./alexnet-train-dy.prototxt
I1104 23:37:20.437510 12945 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-train-ignet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  top: "extra"
  transform_param {
    scale: 0.0039215689
    mirror: true
    crop_size: 224
    mean_file: "../../data/1/256_train_mean.binaryproto"
  }
  image_data_param {
    source: "../../data/1/train_1.txt"
    batch_size: 32
    shuffle: true
    new_height: 256
    new_width: 256
    root_folder: "../../data/faces/"
    reference: false
  }
}
layer {
  name: "embedding_fc1"
  type: "InnerProduct"
  bottom: "extra"
  top: "embedding_fc1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_embedding_fc1"
  type: "BatchNorm"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_embedding_fc1"
  type: "Scale"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_embedding_fc1"
  type: "ReLU"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
}
layer {
  name: "embedding_fc2"
  type: "InnerProduct"
  bottom: "embedding_fc1"
  top: "embedding_fc2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip2"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 307200
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  bottom: "filter_ip2"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip3"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 884736
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  bottom: "filter_ip3"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "filter_ip4"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 663552
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  bottom: "filter_ip4"
  top: "conv4"
  param {
    name: "conv4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "filter_ip5"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 442368
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  bottom: "filter_ip5"
  top: "conv5"
  param {
    name: "conv5_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip6"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4718592
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "feat0"
  type: "Convolution"
  bottom: "pool5"
  bottom: "filter_ip6"
  top: "feat0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 6
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_feat0"
  type: "BatchNorm"
  bottom: "feat0"
  top: "feat0"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_feat0"
  type: "Scale"
  bottom: "feat0"
  top: "feat0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_feat0"
  type: "ReLU"
  bottom: "feat0"
  top: "feat0"
}
layer {
  name: "filter_ip7"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "feat1"
  type: "Convolution"
  bottom: "feat0"
  bottom: "filter_ip7"
  top: "feat1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "eucli_loss"
  type: "EuclideanLoss"
  bottom: "feat1"
  bottom: "label"
  top: "eucli_loss"
}
I1104 23:37:20.437808 12945 layer_factory.hpp:77] Creating layer data
I1104 23:37:20.437831 12945 net.cpp:84] Creating Layer data
I1104 23:37:20.437839 12945 net.cpp:380] data -> data
I1104 23:37:20.437852 12945 net.cpp:380] data -> label
I1104 23:37:20.437861 12945 net.cpp:380] data -> extra
I1104 23:37:20.437871 12945 data_transformer.cpp:28] Loading mean file from: ../../data/1/256_train_mean.binaryproto
I1104 23:37:20.439896 12945 image_data_layer.cpp:38] Opening file ../../data/1/train_1.txt
I1104 23:37:20.440618 12945 image_data_layer.cpp:53] Shuffling data
I1104 23:37:20.440714 12945 image_data_layer.cpp:63] A total of 4400 images.
I1104 23:37:20.443140 12945 image_data_layer.cpp:90] output data size: 32,3,224,224
I1104 23:37:20.467213 12945 net.cpp:122] Setting up data
I1104 23:37:20.467260 12945 net.cpp:129] Top shape: 32 3 224 224 (4816896)
I1104 23:37:20.467267 12945 net.cpp:129] Top shape: 32 (32)
I1104 23:37:20.467270 12945 net.cpp:129] Top shape: 32 2 1 1 (64)
I1104 23:37:20.467272 12945 net.cpp:137] Memory required for data: 19267968
I1104 23:37:20.467280 12945 layer_factory.hpp:77] Creating layer embedding_fc1
I1104 23:37:20.467293 12945 net.cpp:84] Creating Layer embedding_fc1
I1104 23:37:20.467298 12945 net.cpp:406] embedding_fc1 <- extra
I1104 23:37:20.467309 12945 net.cpp:380] embedding_fc1 -> embedding_fc1
I1104 23:37:20.468209 12945 net.cpp:122] Setting up embedding_fc1
I1104 23:37:20.468236 12945 net.cpp:129] Top shape: 32 256 (8192)
I1104 23:37:20.468240 12945 net.cpp:137] Memory required for data: 19300736
I1104 23:37:20.468256 12945 layer_factory.hpp:77] Creating layer bn_embedding_fc1
I1104 23:37:20.468266 12945 net.cpp:84] Creating Layer bn_embedding_fc1
I1104 23:37:20.468269 12945 net.cpp:406] bn_embedding_fc1 <- embedding_fc1
I1104 23:37:20.468273 12945 net.cpp:367] bn_embedding_fc1 -> embedding_fc1 (in-place)
I1104 23:37:20.468374 12945 net.cpp:122] Setting up bn_embedding_fc1
I1104 23:37:20.468394 12945 net.cpp:129] Top shape: 32 256 (8192)
I1104 23:37:20.468397 12945 net.cpp:137] Memory required for data: 19333504
I1104 23:37:20.468405 12945 layer_factory.hpp:77] Creating layer scale_embedding_fc1
I1104 23:37:20.468410 12945 net.cpp:84] Creating Layer scale_embedding_fc1
I1104 23:37:20.468412 12945 net.cpp:406] scale_embedding_fc1 <- embedding_fc1
I1104 23:37:20.468417 12945 net.cpp:367] scale_embedding_fc1 -> embedding_fc1 (in-place)
I1104 23:37:20.468442 12945 layer_factory.hpp:77] Creating layer scale_embedding_fc1
I1104 23:37:20.468499 12945 net.cpp:122] Setting up scale_embedding_fc1
I1104 23:37:20.468505 12945 net.cpp:129] Top shape: 32 256 (8192)
I1104 23:37:20.468508 12945 net.cpp:137] Memory required for data: 19366272
I1104 23:37:20.468511 12945 layer_factory.hpp:77] Creating layer relu_embedding_fc1
I1104 23:37:20.468518 12945 net.cpp:84] Creating Layer relu_embedding_fc1
I1104 23:37:20.468519 12945 net.cpp:406] relu_embedding_fc1 <- embedding_fc1
I1104 23:37:20.468523 12945 net.cpp:367] relu_embedding_fc1 -> embedding_fc1 (in-place)
I1104 23:37:20.874176 12945 net.cpp:122] Setting up relu_embedding_fc1
I1104 23:37:20.874198 12945 net.cpp:129] Top shape: 32 256 (8192)
I1104 23:37:20.874202 12945 net.cpp:137] Memory required for data: 19399040
I1104 23:37:20.874208 12945 layer_factory.hpp:77] Creating layer embedding_fc2
I1104 23:37:20.874218 12945 net.cpp:84] Creating Layer embedding_fc2
I1104 23:37:20.874222 12945 net.cpp:406] embedding_fc2 <- embedding_fc1
I1104 23:37:20.874228 12945 net.cpp:380] embedding_fc2 -> embedding_fc2
I1104 23:37:20.874317 12945 net.cpp:122] Setting up embedding_fc2
I1104 23:37:20.874323 12945 net.cpp:129] Top shape: 32 1 (32)
I1104 23:37:20.874326 12945 net.cpp:137] Memory required for data: 19399168
I1104 23:37:20.874333 12945 layer_factory.hpp:77] Creating layer embedding_fc2_embedding_fc2_0_split
I1104 23:37:20.874339 12945 net.cpp:84] Creating Layer embedding_fc2_embedding_fc2_0_split
I1104 23:37:20.874342 12945 net.cpp:406] embedding_fc2_embedding_fc2_0_split <- embedding_fc2
I1104 23:37:20.874347 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_0
I1104 23:37:20.874352 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_1
I1104 23:37:20.874359 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_2
I1104 23:37:20.874364 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_3
I1104 23:37:20.874370 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_4
I1104 23:37:20.874374 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_5
I1104 23:37:20.874429 12945 net.cpp:122] Setting up embedding_fc2_embedding_fc2_0_split
I1104 23:37:20.874434 12945 net.cpp:129] Top shape: 32 1 (32)
I1104 23:37:20.874437 12945 net.cpp:129] Top shape: 32 1 (32)
I1104 23:37:20.874439 12945 net.cpp:129] Top shape: 32 1 (32)
I1104 23:37:20.874442 12945 net.cpp:129] Top shape: 32 1 (32)
I1104 23:37:20.874445 12945 net.cpp:129] Top shape: 32 1 (32)
I1104 23:37:20.874447 12945 net.cpp:129] Top shape: 32 1 (32)
I1104 23:37:20.874449 12945 net.cpp:137] Memory required for data: 19399936
I1104 23:37:20.874452 12945 layer_factory.hpp:77] Creating layer conv1
I1104 23:37:20.874462 12945 net.cpp:84] Creating Layer conv1
I1104 23:37:20.874465 12945 net.cpp:406] conv1 <- data
I1104 23:37:20.874472 12945 net.cpp:380] conv1 -> conv1
I1104 23:37:20.875993 12945 net.cpp:122] Setting up conv1
I1104 23:37:20.876004 12945 net.cpp:129] Top shape: 32 96 54 54 (8957952)
I1104 23:37:20.876008 12945 net.cpp:137] Memory required for data: 55231744
I1104 23:37:20.876013 12945 layer_factory.hpp:77] Creating layer bn_conv1
I1104 23:37:20.876021 12945 net.cpp:84] Creating Layer bn_conv1
I1104 23:37:20.876024 12945 net.cpp:406] bn_conv1 <- conv1
I1104 23:37:20.876029 12945 net.cpp:367] bn_conv1 -> conv1 (in-place)
I1104 23:37:20.876173 12945 net.cpp:122] Setting up bn_conv1
I1104 23:37:20.876196 12945 net.cpp:129] Top shape: 32 96 54 54 (8957952)
I1104 23:37:20.876199 12945 net.cpp:137] Memory required for data: 91063552
I1104 23:37:20.876204 12945 layer_factory.hpp:77] Creating layer scale_conv1
I1104 23:37:20.876209 12945 net.cpp:84] Creating Layer scale_conv1
I1104 23:37:20.876211 12945 net.cpp:406] scale_conv1 <- conv1
I1104 23:37:20.876215 12945 net.cpp:367] scale_conv1 -> conv1 (in-place)
I1104 23:37:20.876243 12945 layer_factory.hpp:77] Creating layer scale_conv1
I1104 23:37:20.876324 12945 net.cpp:122] Setting up scale_conv1
I1104 23:37:20.876330 12945 net.cpp:129] Top shape: 32 96 54 54 (8957952)
I1104 23:37:20.876333 12945 net.cpp:137] Memory required for data: 126895360
I1104 23:37:20.876338 12945 layer_factory.hpp:77] Creating layer relu1
I1104 23:37:20.876341 12945 net.cpp:84] Creating Layer relu1
I1104 23:37:20.876345 12945 net.cpp:406] relu1 <- conv1
I1104 23:37:20.876348 12945 net.cpp:367] relu1 -> conv1 (in-place)
I1104 23:37:20.876701 12945 net.cpp:122] Setting up relu1
I1104 23:37:20.876709 12945 net.cpp:129] Top shape: 32 96 54 54 (8957952)
I1104 23:37:20.876713 12945 net.cpp:137] Memory required for data: 162727168
I1104 23:37:20.876714 12945 layer_factory.hpp:77] Creating layer pool1
I1104 23:37:20.876720 12945 net.cpp:84] Creating Layer pool1
I1104 23:37:20.876722 12945 net.cpp:406] pool1 <- conv1
I1104 23:37:20.876726 12945 net.cpp:380] pool1 -> pool1
I1104 23:37:20.876765 12945 net.cpp:122] Setting up pool1
I1104 23:37:20.876770 12945 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I1104 23:37:20.876771 12945 net.cpp:137] Memory required for data: 171685120
I1104 23:37:20.876775 12945 layer_factory.hpp:77] Creating layer filter_ip2
I1104 23:37:20.876780 12945 net.cpp:84] Creating Layer filter_ip2
I1104 23:37:20.876781 12945 net.cpp:406] filter_ip2 <- embedding_fc2_embedding_fc2_0_split_0
I1104 23:37:20.876786 12945 net.cpp:380] filter_ip2 -> filter_ip2
I1104 23:37:20.879356 12945 net.cpp:122] Setting up filter_ip2
I1104 23:37:20.879369 12945 net.cpp:129] Top shape: 32 307200 (9830400)
I1104 23:37:20.879371 12945 net.cpp:137] Memory required for data: 211006720
I1104 23:37:20.879379 12945 layer_factory.hpp:77] Creating layer conv2
I1104 23:37:20.879388 12945 net.cpp:84] Creating Layer conv2
I1104 23:37:20.879392 12945 net.cpp:406] conv2 <- pool1
I1104 23:37:20.879397 12945 net.cpp:406] conv2 <- filter_ip2
I1104 23:37:20.879401 12945 net.cpp:380] conv2 -> conv2
I1104 23:37:20.881927 12945 net.cpp:122] Setting up conv2
I1104 23:37:20.881938 12945 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1104 23:37:20.881942 12945 net.cpp:137] Memory required for data: 234894592
I1104 23:37:20.881947 12945 layer_factory.hpp:77] Creating layer bn_conv2
I1104 23:37:20.881953 12945 net.cpp:84] Creating Layer bn_conv2
I1104 23:37:20.881956 12945 net.cpp:406] bn_conv2 <- conv2
I1104 23:37:20.881959 12945 net.cpp:367] bn_conv2 -> conv2 (in-place)
I1104 23:37:20.882094 12945 net.cpp:122] Setting up bn_conv2
I1104 23:37:20.882102 12945 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1104 23:37:20.882103 12945 net.cpp:137] Memory required for data: 258782464
I1104 23:37:20.882108 12945 layer_factory.hpp:77] Creating layer scale_conv2
I1104 23:37:20.882113 12945 net.cpp:84] Creating Layer scale_conv2
I1104 23:37:20.882117 12945 net.cpp:406] scale_conv2 <- conv2
I1104 23:37:20.882119 12945 net.cpp:367] scale_conv2 -> conv2 (in-place)
I1104 23:37:20.882148 12945 layer_factory.hpp:77] Creating layer scale_conv2
I1104 23:37:20.882225 12945 net.cpp:122] Setting up scale_conv2
I1104 23:37:20.882231 12945 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1104 23:37:20.882234 12945 net.cpp:137] Memory required for data: 282670336
I1104 23:37:20.882238 12945 layer_factory.hpp:77] Creating layer relu2
I1104 23:37:20.882244 12945 net.cpp:84] Creating Layer relu2
I1104 23:37:20.882247 12945 net.cpp:406] relu2 <- conv2
I1104 23:37:20.882252 12945 net.cpp:367] relu2 -> conv2 (in-place)
I1104 23:37:20.882742 12945 net.cpp:122] Setting up relu2
I1104 23:37:20.882752 12945 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1104 23:37:20.882771 12945 net.cpp:137] Memory required for data: 306558208
I1104 23:37:20.882776 12945 layer_factory.hpp:77] Creating layer pool2
I1104 23:37:20.882782 12945 net.cpp:84] Creating Layer pool2
I1104 23:37:20.882786 12945 net.cpp:406] pool2 <- conv2
I1104 23:37:20.882791 12945 net.cpp:380] pool2 -> pool2
I1104 23:37:20.882827 12945 net.cpp:122] Setting up pool2
I1104 23:37:20.882831 12945 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1104 23:37:20.882833 12945 net.cpp:137] Memory required for data: 312096000
I1104 23:37:20.882836 12945 layer_factory.hpp:77] Creating layer filter_ip3
I1104 23:37:20.882843 12945 net.cpp:84] Creating Layer filter_ip3
I1104 23:37:20.882844 12945 net.cpp:406] filter_ip3 <- embedding_fc2_embedding_fc2_0_split_1
I1104 23:37:20.882848 12945 net.cpp:380] filter_ip3 -> filter_ip3
I1104 23:37:20.890122 12945 net.cpp:122] Setting up filter_ip3
I1104 23:37:20.890139 12945 net.cpp:129] Top shape: 32 884736 (28311552)
I1104 23:37:20.890142 12945 net.cpp:137] Memory required for data: 425342208
I1104 23:37:20.890149 12945 layer_factory.hpp:77] Creating layer conv3
I1104 23:37:20.890162 12945 net.cpp:84] Creating Layer conv3
I1104 23:37:20.890167 12945 net.cpp:406] conv3 <- pool2
I1104 23:37:20.890172 12945 net.cpp:406] conv3 <- filter_ip3
I1104 23:37:20.890177 12945 net.cpp:380] conv3 -> conv3
I1104 23:37:20.896472 12945 net.cpp:122] Setting up conv3
I1104 23:37:20.896488 12945 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1104 23:37:20.896492 12945 net.cpp:137] Memory required for data: 433648896
I1104 23:37:20.896497 12945 layer_factory.hpp:77] Creating layer bn_conv3
I1104 23:37:20.896502 12945 net.cpp:84] Creating Layer bn_conv3
I1104 23:37:20.896505 12945 net.cpp:406] bn_conv3 <- conv3
I1104 23:37:20.896509 12945 net.cpp:367] bn_conv3 -> conv3 (in-place)
I1104 23:37:20.896641 12945 net.cpp:122] Setting up bn_conv3
I1104 23:37:20.896647 12945 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1104 23:37:20.896651 12945 net.cpp:137] Memory required for data: 441955584
I1104 23:37:20.896656 12945 layer_factory.hpp:77] Creating layer scale_conv3
I1104 23:37:20.896661 12945 net.cpp:84] Creating Layer scale_conv3
I1104 23:37:20.896663 12945 net.cpp:406] scale_conv3 <- conv3
I1104 23:37:20.896667 12945 net.cpp:367] scale_conv3 -> conv3 (in-place)
I1104 23:37:20.896693 12945 layer_factory.hpp:77] Creating layer scale_conv3
I1104 23:37:20.896771 12945 net.cpp:122] Setting up scale_conv3
I1104 23:37:20.896777 12945 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1104 23:37:20.896780 12945 net.cpp:137] Memory required for data: 450262272
I1104 23:37:20.896788 12945 layer_factory.hpp:77] Creating layer relu3
I1104 23:37:20.896793 12945 net.cpp:84] Creating Layer relu3
I1104 23:37:20.896796 12945 net.cpp:406] relu3 <- conv3
I1104 23:37:20.896800 12945 net.cpp:367] relu3 -> conv3 (in-place)
I1104 23:37:20.897135 12945 net.cpp:122] Setting up relu3
I1104 23:37:20.897142 12945 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1104 23:37:20.897145 12945 net.cpp:137] Memory required for data: 458568960
I1104 23:37:20.897147 12945 layer_factory.hpp:77] Creating layer filter_ip4
I1104 23:37:20.897153 12945 net.cpp:84] Creating Layer filter_ip4
I1104 23:37:20.897156 12945 net.cpp:406] filter_ip4 <- embedding_fc2_embedding_fc2_0_split_2
I1104 23:37:20.897162 12945 net.cpp:380] filter_ip4 -> filter_ip4
I1104 23:37:20.902724 12945 net.cpp:122] Setting up filter_ip4
I1104 23:37:20.902741 12945 net.cpp:129] Top shape: 32 663552 (21233664)
I1104 23:37:20.902745 12945 net.cpp:137] Memory required for data: 543503616
I1104 23:37:20.902752 12945 layer_factory.hpp:77] Creating layer conv4
I1104 23:37:20.902762 12945 net.cpp:84] Creating Layer conv4
I1104 23:37:20.902767 12945 net.cpp:406] conv4 <- conv3
I1104 23:37:20.902772 12945 net.cpp:406] conv4 <- filter_ip4
I1104 23:37:20.902779 12945 net.cpp:380] conv4 -> conv4
I1104 23:37:20.907594 12945 net.cpp:122] Setting up conv4
I1104 23:37:20.907609 12945 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1104 23:37:20.907613 12945 net.cpp:137] Memory required for data: 551810304
I1104 23:37:20.907634 12945 layer_factory.hpp:77] Creating layer bn_conv4
I1104 23:37:20.907644 12945 net.cpp:84] Creating Layer bn_conv4
I1104 23:37:20.907646 12945 net.cpp:406] bn_conv4 <- conv4
I1104 23:37:20.907652 12945 net.cpp:367] bn_conv4 -> conv4 (in-place)
I1104 23:37:20.907799 12945 net.cpp:122] Setting up bn_conv4
I1104 23:37:20.907804 12945 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1104 23:37:20.907807 12945 net.cpp:137] Memory required for data: 560116992
I1104 23:37:20.907812 12945 layer_factory.hpp:77] Creating layer scale_conv4
I1104 23:37:20.907817 12945 net.cpp:84] Creating Layer scale_conv4
I1104 23:37:20.907820 12945 net.cpp:406] scale_conv4 <- conv4
I1104 23:37:20.907824 12945 net.cpp:367] scale_conv4 -> conv4 (in-place)
I1104 23:37:20.907851 12945 layer_factory.hpp:77] Creating layer scale_conv4
I1104 23:37:20.907932 12945 net.cpp:122] Setting up scale_conv4
I1104 23:37:20.907938 12945 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1104 23:37:20.907940 12945 net.cpp:137] Memory required for data: 568423680
I1104 23:37:20.907945 12945 layer_factory.hpp:77] Creating layer relu4
I1104 23:37:20.907950 12945 net.cpp:84] Creating Layer relu4
I1104 23:37:20.907953 12945 net.cpp:406] relu4 <- conv4
I1104 23:37:20.907956 12945 net.cpp:367] relu4 -> conv4 (in-place)
I1104 23:37:20.908303 12945 net.cpp:122] Setting up relu4
I1104 23:37:20.908311 12945 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1104 23:37:20.908314 12945 net.cpp:137] Memory required for data: 576730368
I1104 23:37:20.908318 12945 layer_factory.hpp:77] Creating layer filter_ip5
I1104 23:37:20.908324 12945 net.cpp:84] Creating Layer filter_ip5
I1104 23:37:20.908327 12945 net.cpp:406] filter_ip5 <- embedding_fc2_embedding_fc2_0_split_3
I1104 23:37:20.908334 12945 net.cpp:380] filter_ip5 -> filter_ip5
I1104 23:37:20.912241 12945 net.cpp:122] Setting up filter_ip5
I1104 23:37:20.912252 12945 net.cpp:129] Top shape: 32 442368 (14155776)
I1104 23:37:20.912256 12945 net.cpp:137] Memory required for data: 633353472
I1104 23:37:20.912261 12945 layer_factory.hpp:77] Creating layer conv5
I1104 23:37:20.912269 12945 net.cpp:84] Creating Layer conv5
I1104 23:37:20.912272 12945 net.cpp:406] conv5 <- conv4
I1104 23:37:20.912277 12945 net.cpp:406] conv5 <- filter_ip5
I1104 23:37:20.912282 12945 net.cpp:380] conv5 -> conv5
I1104 23:37:20.915609 12945 net.cpp:122] Setting up conv5
I1104 23:37:20.915621 12945 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1104 23:37:20.915623 12945 net.cpp:137] Memory required for data: 638891264
I1104 23:37:20.915628 12945 layer_factory.hpp:77] Creating layer bn_conv5
I1104 23:37:20.915633 12945 net.cpp:84] Creating Layer bn_conv5
I1104 23:37:20.915637 12945 net.cpp:406] bn_conv5 <- conv5
I1104 23:37:20.915642 12945 net.cpp:367] bn_conv5 -> conv5 (in-place)
I1104 23:37:20.915786 12945 net.cpp:122] Setting up bn_conv5
I1104 23:37:20.915792 12945 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1104 23:37:20.915796 12945 net.cpp:137] Memory required for data: 644429056
I1104 23:37:20.915802 12945 layer_factory.hpp:77] Creating layer scale_conv5
I1104 23:37:20.915807 12945 net.cpp:84] Creating Layer scale_conv5
I1104 23:37:20.915810 12945 net.cpp:406] scale_conv5 <- conv5
I1104 23:37:20.915814 12945 net.cpp:367] scale_conv5 -> conv5 (in-place)
I1104 23:37:20.915844 12945 layer_factory.hpp:77] Creating layer scale_conv5
I1104 23:37:20.915923 12945 net.cpp:122] Setting up scale_conv5
I1104 23:37:20.915930 12945 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1104 23:37:20.915932 12945 net.cpp:137] Memory required for data: 649966848
I1104 23:37:20.915937 12945 layer_factory.hpp:77] Creating layer relu5
I1104 23:37:20.915946 12945 net.cpp:84] Creating Layer relu5
I1104 23:37:20.915949 12945 net.cpp:406] relu5 <- conv5
I1104 23:37:20.915953 12945 net.cpp:367] relu5 -> conv5 (in-place)
I1104 23:37:20.916421 12945 net.cpp:122] Setting up relu5
I1104 23:37:20.916430 12945 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1104 23:37:20.916433 12945 net.cpp:137] Memory required for data: 655504640
I1104 23:37:20.916450 12945 layer_factory.hpp:77] Creating layer pool5
I1104 23:37:20.916457 12945 net.cpp:84] Creating Layer pool5
I1104 23:37:20.916460 12945 net.cpp:406] pool5 <- conv5
I1104 23:37:20.916466 12945 net.cpp:380] pool5 -> pool5
I1104 23:37:20.916501 12945 net.cpp:122] Setting up pool5
I1104 23:37:20.916508 12945 net.cpp:129] Top shape: 32 256 6 6 (294912)
I1104 23:37:20.916512 12945 net.cpp:137] Memory required for data: 656684288
I1104 23:37:20.916513 12945 layer_factory.hpp:77] Creating layer filter_ip6
I1104 23:37:20.916518 12945 net.cpp:84] Creating Layer filter_ip6
I1104 23:37:20.916522 12945 net.cpp:406] filter_ip6 <- embedding_fc2_embedding_fc2_0_split_4
I1104 23:37:20.916527 12945 net.cpp:380] filter_ip6 -> filter_ip6
I1104 23:37:20.954192 12945 net.cpp:122] Setting up filter_ip6
I1104 23:37:20.954217 12945 net.cpp:129] Top shape: 32 4718592 (150994944)
I1104 23:37:20.954221 12945 net.cpp:137] Memory required for data: 1260664064
I1104 23:37:20.954229 12945 layer_factory.hpp:77] Creating layer feat0
I1104 23:37:20.954241 12945 net.cpp:84] Creating Layer feat0
I1104 23:37:20.954246 12945 net.cpp:406] feat0 <- pool5
I1104 23:37:20.954255 12945 net.cpp:406] feat0 <- filter_ip6
I1104 23:37:20.954260 12945 net.cpp:380] feat0 -> feat0
I1104 23:37:20.986625 12945 net.cpp:122] Setting up feat0
I1104 23:37:20.986646 12945 net.cpp:129] Top shape: 32 512 1 1 (16384)
I1104 23:37:20.986649 12945 net.cpp:137] Memory required for data: 1260729600
I1104 23:37:20.986655 12945 layer_factory.hpp:77] Creating layer bn_feat0
I1104 23:37:20.986663 12945 net.cpp:84] Creating Layer bn_feat0
I1104 23:37:20.986666 12945 net.cpp:406] bn_feat0 <- feat0
I1104 23:37:20.986672 12945 net.cpp:367] bn_feat0 -> feat0 (in-place)
I1104 23:37:20.986815 12945 net.cpp:122] Setting up bn_feat0
I1104 23:37:20.986821 12945 net.cpp:129] Top shape: 32 512 1 1 (16384)
I1104 23:37:20.986824 12945 net.cpp:137] Memory required for data: 1260795136
I1104 23:37:20.986829 12945 layer_factory.hpp:77] Creating layer scale_feat0
I1104 23:37:20.986835 12945 net.cpp:84] Creating Layer scale_feat0
I1104 23:37:20.986838 12945 net.cpp:406] scale_feat0 <- feat0
I1104 23:37:20.986841 12945 net.cpp:367] scale_feat0 -> feat0 (in-place)
I1104 23:37:20.986871 12945 layer_factory.hpp:77] Creating layer scale_feat0
I1104 23:37:20.986954 12945 net.cpp:122] Setting up scale_feat0
I1104 23:37:20.986960 12945 net.cpp:129] Top shape: 32 512 1 1 (16384)
I1104 23:37:20.986963 12945 net.cpp:137] Memory required for data: 1260860672
I1104 23:37:20.986966 12945 layer_factory.hpp:77] Creating layer relu_feat0
I1104 23:37:20.986970 12945 net.cpp:84] Creating Layer relu_feat0
I1104 23:37:20.986974 12945 net.cpp:406] relu_feat0 <- feat0
I1104 23:37:20.986977 12945 net.cpp:367] relu_feat0 -> feat0 (in-place)
I1104 23:37:20.987326 12945 net.cpp:122] Setting up relu_feat0
I1104 23:37:20.987334 12945 net.cpp:129] Top shape: 32 512 1 1 (16384)
I1104 23:37:20.987337 12945 net.cpp:137] Memory required for data: 1260926208
I1104 23:37:20.987339 12945 layer_factory.hpp:77] Creating layer filter_ip7
I1104 23:37:20.987346 12945 net.cpp:84] Creating Layer filter_ip7
I1104 23:37:20.987349 12945 net.cpp:406] filter_ip7 <- embedding_fc2_embedding_fc2_0_split_5
I1104 23:37:20.987354 12945 net.cpp:380] filter_ip7 -> filter_ip7
I1104 23:37:20.987439 12945 net.cpp:122] Setting up filter_ip7
I1104 23:37:20.987444 12945 net.cpp:129] Top shape: 32 512 (16384)
I1104 23:37:20.987447 12945 net.cpp:137] Memory required for data: 1260991744
I1104 23:37:20.987452 12945 layer_factory.hpp:77] Creating layer feat1
I1104 23:37:20.987458 12945 net.cpp:84] Creating Layer feat1
I1104 23:37:20.987462 12945 net.cpp:406] feat1 <- feat0
I1104 23:37:20.987464 12945 net.cpp:406] feat1 <- filter_ip7
I1104 23:37:20.987468 12945 net.cpp:380] feat1 -> feat1
I1104 23:37:20.987648 12945 net.cpp:122] Setting up feat1
I1104 23:37:20.987653 12945 net.cpp:129] Top shape: 32 1 1 1 (32)
I1104 23:37:20.987656 12945 net.cpp:137] Memory required for data: 1260991872
I1104 23:37:20.987666 12945 layer_factory.hpp:77] Creating layer eucli_loss
I1104 23:37:20.987689 12945 net.cpp:84] Creating Layer eucli_loss
I1104 23:37:20.987692 12945 net.cpp:406] eucli_loss <- feat1
I1104 23:37:20.987695 12945 net.cpp:406] eucli_loss <- label
I1104 23:37:20.987700 12945 net.cpp:380] eucli_loss -> eucli_loss
I1104 23:37:20.987731 12945 net.cpp:122] Setting up eucli_loss
I1104 23:37:20.987735 12945 net.cpp:129] Top shape: (1)
I1104 23:37:20.987740 12945 net.cpp:132]     with loss weight 1
I1104 23:37:20.987761 12945 net.cpp:137] Memory required for data: 1260991876
I1104 23:37:20.987763 12945 net.cpp:198] eucli_loss needs backward computation.
I1104 23:37:20.987771 12945 net.cpp:198] feat1 needs backward computation.
I1104 23:37:20.987773 12945 net.cpp:198] filter_ip7 needs backward computation.
I1104 23:37:20.987777 12945 net.cpp:198] relu_feat0 needs backward computation.
I1104 23:37:20.987780 12945 net.cpp:198] scale_feat0 needs backward computation.
I1104 23:37:20.987784 12945 net.cpp:198] bn_feat0 needs backward computation.
I1104 23:37:20.987787 12945 net.cpp:198] feat0 needs backward computation.
I1104 23:37:20.987792 12945 net.cpp:198] filter_ip6 needs backward computation.
I1104 23:37:20.987793 12945 net.cpp:198] pool5 needs backward computation.
I1104 23:37:20.987797 12945 net.cpp:198] relu5 needs backward computation.
I1104 23:37:20.987800 12945 net.cpp:198] scale_conv5 needs backward computation.
I1104 23:37:20.987803 12945 net.cpp:198] bn_conv5 needs backward computation.
I1104 23:37:20.987807 12945 net.cpp:198] conv5 needs backward computation.
I1104 23:37:20.987810 12945 net.cpp:198] filter_ip5 needs backward computation.
I1104 23:37:20.987813 12945 net.cpp:198] relu4 needs backward computation.
I1104 23:37:20.987816 12945 net.cpp:198] scale_conv4 needs backward computation.
I1104 23:37:20.987819 12945 net.cpp:198] bn_conv4 needs backward computation.
I1104 23:37:20.987823 12945 net.cpp:198] conv4 needs backward computation.
I1104 23:37:20.987828 12945 net.cpp:198] filter_ip4 needs backward computation.
I1104 23:37:20.987830 12945 net.cpp:198] relu3 needs backward computation.
I1104 23:37:20.987833 12945 net.cpp:198] scale_conv3 needs backward computation.
I1104 23:37:20.987838 12945 net.cpp:198] bn_conv3 needs backward computation.
I1104 23:37:20.987840 12945 net.cpp:198] conv3 needs backward computation.
I1104 23:37:20.987843 12945 net.cpp:198] filter_ip3 needs backward computation.
I1104 23:37:20.987848 12945 net.cpp:198] pool2 needs backward computation.
I1104 23:37:20.987851 12945 net.cpp:198] relu2 needs backward computation.
I1104 23:37:20.987854 12945 net.cpp:198] scale_conv2 needs backward computation.
I1104 23:37:20.987857 12945 net.cpp:198] bn_conv2 needs backward computation.
I1104 23:37:20.987860 12945 net.cpp:198] conv2 needs backward computation.
I1104 23:37:20.987864 12945 net.cpp:198] filter_ip2 needs backward computation.
I1104 23:37:20.987867 12945 net.cpp:198] pool1 needs backward computation.
I1104 23:37:20.987870 12945 net.cpp:198] relu1 needs backward computation.
I1104 23:37:20.987874 12945 net.cpp:198] scale_conv1 needs backward computation.
I1104 23:37:20.987876 12945 net.cpp:198] bn_conv1 needs backward computation.
I1104 23:37:20.987879 12945 net.cpp:198] conv1 needs backward computation.
I1104 23:37:20.987884 12945 net.cpp:198] embedding_fc2_embedding_fc2_0_split needs backward computation.
I1104 23:37:20.987886 12945 net.cpp:198] embedding_fc2 needs backward computation.
I1104 23:37:20.987890 12945 net.cpp:198] relu_embedding_fc1 needs backward computation.
I1104 23:37:20.987893 12945 net.cpp:198] scale_embedding_fc1 needs backward computation.
I1104 23:37:20.987897 12945 net.cpp:198] bn_embedding_fc1 needs backward computation.
I1104 23:37:20.987900 12945 net.cpp:198] embedding_fc1 needs backward computation.
I1104 23:37:20.987905 12945 net.cpp:200] data does not need backward computation.
I1104 23:37:20.987907 12945 net.cpp:242] This network produces output eucli_loss
I1104 23:37:20.987926 12945 net.cpp:255] Network initialization done.
I1104 23:37:20.988025 12945 solver.cpp:172] Creating test net (#0) specified by test_net file: ./alexnet-test-dy.prototxt
I1104 23:37:20.988059 12945 net.cpp:51] Initializing net from parameters: 
name: "AlexNet_dynamic_test"
state {
  phase: TEST
}
layer {
  name: "accuracy"
  type: "Python"
  top: "accuracy"
  top: "mae"
  top: "rmse"
  python_param {
    module: "correlation"
    layer: "CorrelationLayer"
    param_str: "{\'network_file\': \'./alexnet-deploy-dy.prototxt\', \'snapshot_prefix\': \'./snapshot/1/alex-dy_iter_\',\'snapshot_iter\': 5000, \'mean_file\': \'../../data/1/256_train_mean.binaryproto\', \'roots\': \'../../data/faces/\', \'file\': \'../../data/1/test_1.txt\'}"
  }
}
I1104 23:37:20.988078 12945 layer_factory.hpp:77] Creating layer accuracy
I1104 23:37:21.454407 12945 net.cpp:84] Creating Layer accuracy
I1104 23:37:21.454430 12945 net.cpp:380] accuracy -> accuracy
I1104 23:37:21.454440 12945 net.cpp:380] accuracy -> mae
I1104 23:37:21.454445 12945 net.cpp:380] accuracy -> rmse
I1104 23:37:21.454663 12945 net.cpp:122] Setting up accuracy
I1104 23:37:21.454672 12945 net.cpp:129] Top shape: 1 (1)
I1104 23:37:21.454676 12945 net.cpp:129] Top shape: 1 (1)
I1104 23:37:21.454679 12945 net.cpp:129] Top shape: 1 (1)
I1104 23:37:21.454681 12945 net.cpp:137] Memory required for data: 12
I1104 23:37:21.454684 12945 net.cpp:200] accuracy does not need backward computation.
I1104 23:37:21.454687 12945 net.cpp:242] This network produces output accuracy
I1104 23:37:21.454690 12945 net.cpp:242] This network produces output mae
I1104 23:37:21.454694 12945 net.cpp:242] This network produces output rmse
I1104 23:37:21.454696 12945 net.cpp:255] Network initialization done.
I1104 23:37:21.454712 12945 solver.cpp:56] Solver scaffolding done.
I1104 23:37:21.456408 12945 caffe.cpp:248] Starting Optimization
I1104 23:37:21.456416 12945 solver.cpp:272] Solving AlexNet-train-ignet
I1104 23:37:21.456418 12945 solver.cpp:273] Learning Rate Policy: triangular
I1104 23:37:21.616998 12945 solver.cpp:218] Iteration 0 (0.00207548 iter/s, 0.160504s/100 iters), loss = 4.04922
I1104 23:37:21.617031 12945 solver.cpp:237]     Train net output #0: eucli_loss = 4.04922 (* 1 = 4.04922 loss)
I1104 23:37:21.617043 12945 sgd_solver.cpp:114] Iteration 0, lr = 0
I1104 23:37:35.221454 12945 solver.cpp:218] Iteration 100 (7.35087 iter/s, 13.6038s/100 iters), loss = 2.14474
I1104 23:37:35.221495 12945 solver.cpp:237]     Train net output #0: eucli_loss = 2.14474 (* 1 = 2.14474 loss)
I1104 23:37:35.221503 12945 sgd_solver.cpp:114] Iteration 100, lr = 0.0005
I1104 23:37:48.873550 12945 solver.cpp:218] Iteration 200 (7.32523 iter/s, 13.6515s/100 iters), loss = 0.244453
I1104 23:37:48.873591 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.244453 (* 1 = 0.244453 loss)
I1104 23:37:48.873598 12945 sgd_solver.cpp:114] Iteration 200, lr = 0.001
I1104 23:38:02.547693 12945 solver.cpp:218] Iteration 300 (7.31343 iter/s, 13.6735s/100 iters), loss = 0.232429
I1104 23:38:02.547782 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.232429 (* 1 = 0.232429 loss)
I1104 23:38:02.547789 12945 sgd_solver.cpp:114] Iteration 300, lr = 0.0015
I1104 23:38:16.222268 12945 solver.cpp:218] Iteration 400 (7.31322 iter/s, 13.6739s/100 iters), loss = 0.222524
I1104 23:38:16.222311 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.222524 (* 1 = 0.222524 loss)
I1104 23:38:16.222317 12945 sgd_solver.cpp:114] Iteration 400, lr = 0.002
I1104 23:38:29.914697 12945 solver.cpp:218] Iteration 500 (7.30366 iter/s, 13.6918s/100 iters), loss = 0.250522
I1104 23:38:29.914738 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.250522 (* 1 = 0.250522 loss)
I1104 23:38:29.914746 12945 sgd_solver.cpp:114] Iteration 500, lr = 0.0025
I1104 23:38:43.602507 12945 solver.cpp:218] Iteration 600 (7.30613 iter/s, 13.6871s/100 iters), loss = 0.292927
I1104 23:38:43.602654 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.292927 (* 1 = 0.292927 loss)
I1104 23:38:43.602666 12945 sgd_solver.cpp:114] Iteration 600, lr = 0.003
I1104 23:38:57.311805 12945 solver.cpp:218] Iteration 700 (7.29473 iter/s, 13.7085s/100 iters), loss = 0.291984
I1104 23:38:57.311868 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.291984 (* 1 = 0.291984 loss)
I1104 23:38:57.311878 12945 sgd_solver.cpp:114] Iteration 700, lr = 0.0035
I1104 23:39:11.033390 12945 solver.cpp:218] Iteration 800 (7.28814 iter/s, 13.7209s/100 iters), loss = 0.179115
I1104 23:39:11.033432 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.179115 (* 1 = 0.179115 loss)
I1104 23:39:11.033437 12945 sgd_solver.cpp:114] Iteration 800, lr = 0.004
I1104 23:39:24.769229 12945 solver.cpp:218] Iteration 900 (7.28058 iter/s, 13.7352s/100 iters), loss = 0.258761
I1104 23:39:24.769416 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.258761 (* 1 = 0.258761 loss)
I1104 23:39:24.769428 12945 sgd_solver.cpp:114] Iteration 900, lr = 0.0045
I1104 23:39:38.501526 12945 solver.cpp:218] Iteration 1000 (7.28253 iter/s, 13.7315s/100 iters), loss = 0.187797
I1104 23:39:38.501571 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.187797 (* 1 = 0.187797 loss)
I1104 23:39:38.501579 12945 sgd_solver.cpp:114] Iteration 1000, lr = 0.005
I1104 23:39:52.292701 12945 solver.cpp:218] Iteration 1100 (7.25137 iter/s, 13.7905s/100 iters), loss = 0.275896
I1104 23:39:52.292742 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.275896 (* 1 = 0.275896 loss)
I1104 23:39:52.292750 12945 sgd_solver.cpp:114] Iteration 1100, lr = 0.0055
I1104 23:40:06.095183 12945 solver.cpp:218] Iteration 1200 (7.24542 iter/s, 13.8018s/100 iters), loss = 0.259541
I1104 23:40:06.095257 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.259541 (* 1 = 0.259541 loss)
I1104 23:40:06.095264 12945 sgd_solver.cpp:114] Iteration 1200, lr = 0.006
I1104 23:40:19.883468 12945 solver.cpp:218] Iteration 1300 (7.2529 iter/s, 13.7876s/100 iters), loss = 0.246923
I1104 23:40:19.883509 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.246923 (* 1 = 0.246923 loss)
I1104 23:40:19.883517 12945 sgd_solver.cpp:114] Iteration 1300, lr = 0.0065
I1104 23:40:33.685753 12945 solver.cpp:218] Iteration 1400 (7.24552 iter/s, 13.8016s/100 iters), loss = 0.145006
I1104 23:40:33.685796 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.145006 (* 1 = 0.145006 loss)
I1104 23:40:33.685803 12945 sgd_solver.cpp:114] Iteration 1400, lr = 0.007
I1104 23:40:47.494194 12945 solver.cpp:218] Iteration 1500 (7.24229 iter/s, 13.8078s/100 iters), loss = 0.102094
I1104 23:40:47.494333 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.102094 (* 1 = 0.102094 loss)
I1104 23:40:47.494343 12945 sgd_solver.cpp:114] Iteration 1500, lr = 0.0075
I1104 23:41:01.297948 12945 solver.cpp:218] Iteration 1600 (7.2448 iter/s, 13.803s/100 iters), loss = 0.15934
I1104 23:41:01.297991 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.15934 (* 1 = 0.15934 loss)
I1104 23:41:01.297997 12945 sgd_solver.cpp:114] Iteration 1600, lr = 0.008
I1104 23:41:15.100569 12945 solver.cpp:218] Iteration 1700 (7.24535 iter/s, 13.802s/100 iters), loss = 0.0775763
I1104 23:41:15.100611 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0775764 (* 1 = 0.0775764 loss)
I1104 23:41:15.100620 12945 sgd_solver.cpp:114] Iteration 1700, lr = 0.0085
I1104 23:41:28.902194 12945 solver.cpp:218] Iteration 1800 (7.24587 iter/s, 13.801s/100 iters), loss = 0.149601
I1104 23:41:28.902338 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.149601 (* 1 = 0.149601 loss)
I1104 23:41:28.902348 12945 sgd_solver.cpp:114] Iteration 1800, lr = 0.009
I1104 23:41:42.707599 12945 solver.cpp:218] Iteration 1900 (7.24393 iter/s, 13.8047s/100 iters), loss = 0.0906055
I1104 23:41:42.707639 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0906056 (* 1 = 0.0906056 loss)
I1104 23:41:42.707648 12945 sgd_solver.cpp:114] Iteration 1900, lr = 0.0095
I1104 23:41:56.514799 12945 solver.cpp:218] Iteration 2000 (7.24294 iter/s, 13.8065s/100 iters), loss = 0.0563701
I1104 23:41:56.514840 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0563701 (* 1 = 0.0563701 loss)
I1104 23:41:56.514847 12945 sgd_solver.cpp:114] Iteration 2000, lr = 0.01
I1104 23:42:10.315660 12945 solver.cpp:218] Iteration 2100 (7.24626 iter/s, 13.8002s/100 iters), loss = 0.0597607
I1104 23:42:10.315845 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0597607 (* 1 = 0.0597607 loss)
I1104 23:42:10.315857 12945 sgd_solver.cpp:114] Iteration 2100, lr = 0.00994444
I1104 23:42:24.121129 12945 solver.cpp:218] Iteration 2200 (7.24392 iter/s, 13.8047s/100 iters), loss = 0.0607357
I1104 23:42:24.121168 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0607357 (* 1 = 0.0607357 loss)
I1104 23:42:24.121177 12945 sgd_solver.cpp:114] Iteration 2200, lr = 0.00988889
I1104 23:42:37.928210 12945 solver.cpp:218] Iteration 2300 (7.243 iter/s, 13.8064s/100 iters), loss = 0.132424
I1104 23:42:37.928252 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.132424 (* 1 = 0.132424 loss)
I1104 23:42:37.928259 12945 sgd_solver.cpp:114] Iteration 2300, lr = 0.00983333
I1104 23:42:51.725796 12945 solver.cpp:218] Iteration 2400 (7.24798 iter/s, 13.7969s/100 iters), loss = 0.116261
I1104 23:42:51.725864 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.116261 (* 1 = 0.116261 loss)
I1104 23:42:51.725872 12945 sgd_solver.cpp:114] Iteration 2400, lr = 0.00977778
I1104 23:43:05.527390 12945 solver.cpp:218] Iteration 2500 (7.24589 iter/s, 13.8009s/100 iters), loss = 0.111463
I1104 23:43:05.527431 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.111463 (* 1 = 0.111463 loss)
I1104 23:43:05.527438 12945 sgd_solver.cpp:114] Iteration 2500, lr = 0.00972222
I1104 23:43:19.330422 12945 solver.cpp:218] Iteration 2600 (7.24512 iter/s, 13.8024s/100 iters), loss = 0.111693
I1104 23:43:19.330463 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.111693 (* 1 = 0.111693 loss)
I1104 23:43:19.330471 12945 sgd_solver.cpp:114] Iteration 2600, lr = 0.00966667
I1104 23:43:33.203472 12945 solver.cpp:218] Iteration 2700 (7.20856 iter/s, 13.8724s/100 iters), loss = 0.058204
I1104 23:43:33.203593 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.058204 (* 1 = 0.058204 loss)
I1104 23:43:33.203601 12945 sgd_solver.cpp:114] Iteration 2700, lr = 0.00961111
I1104 23:43:47.058557 12945 solver.cpp:218] Iteration 2800 (7.21794 iter/s, 13.8544s/100 iters), loss = 0.0932292
I1104 23:43:47.058596 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0932292 (* 1 = 0.0932292 loss)
I1104 23:43:47.058604 12945 sgd_solver.cpp:114] Iteration 2800, lr = 0.00955555
I1104 23:44:00.912637 12945 solver.cpp:218] Iteration 2900 (7.21842 iter/s, 13.8534s/100 iters), loss = 0.0558815
I1104 23:44:00.912681 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0558815 (* 1 = 0.0558815 loss)
I1104 23:44:00.912688 12945 sgd_solver.cpp:114] Iteration 2900, lr = 0.0095
I1104 23:44:14.818035 12945 solver.cpp:218] Iteration 3000 (7.19178 iter/s, 13.9048s/100 iters), loss = 0.083935
I1104 23:44:14.818101 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.083935 (* 1 = 0.083935 loss)
I1104 23:44:14.818109 12945 sgd_solver.cpp:114] Iteration 3000, lr = 0.00944444
I1104 23:44:28.700964 12945 solver.cpp:218] Iteration 3100 (7.20343 iter/s, 13.8823s/100 iters), loss = 0.0709602
I1104 23:44:28.701007 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0709602 (* 1 = 0.0709602 loss)
I1104 23:44:28.701015 12945 sgd_solver.cpp:114] Iteration 3100, lr = 0.00938889
I1104 23:44:42.560304 12945 solver.cpp:218] Iteration 3200 (7.21568 iter/s, 13.8587s/100 iters), loss = 0.0746458
I1104 23:44:42.560344 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0746458 (* 1 = 0.0746458 loss)
I1104 23:44:42.560351 12945 sgd_solver.cpp:114] Iteration 3200, lr = 0.00933333
I1104 23:44:56.471148 12945 solver.cpp:218] Iteration 3300 (7.18897 iter/s, 13.9102s/100 iters), loss = 0.0786621
I1104 23:44:56.471256 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0786621 (* 1 = 0.0786621 loss)
I1104 23:44:56.471266 12945 sgd_solver.cpp:114] Iteration 3300, lr = 0.00927778
I1104 23:45:10.376356 12945 solver.cpp:218] Iteration 3400 (7.19192 iter/s, 13.9045s/100 iters), loss = 0.0888344
I1104 23:45:10.376399 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0888344 (* 1 = 0.0888344 loss)
I1104 23:45:10.376405 12945 sgd_solver.cpp:114] Iteration 3400, lr = 0.00922222
I1104 23:45:24.272275 12945 solver.cpp:218] Iteration 3500 (7.19669 iter/s, 13.8953s/100 iters), loss = 0.0353413
I1104 23:45:24.272320 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0353413 (* 1 = 0.0353413 loss)
I1104 23:45:24.272326 12945 sgd_solver.cpp:114] Iteration 3500, lr = 0.00916667
I1104 23:45:38.169636 12945 solver.cpp:218] Iteration 3600 (7.19594 iter/s, 13.8967s/100 iters), loss = 0.0836393
I1104 23:45:38.169745 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0836393 (* 1 = 0.0836393 loss)
I1104 23:45:38.169754 12945 sgd_solver.cpp:114] Iteration 3600, lr = 0.00911111
I1104 23:45:52.074407 12945 solver.cpp:218] Iteration 3700 (7.19214 iter/s, 13.9041s/100 iters), loss = 0.0603313
I1104 23:45:52.074450 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0603313 (* 1 = 0.0603313 loss)
I1104 23:45:52.074458 12945 sgd_solver.cpp:114] Iteration 3700, lr = 0.00905555
I1104 23:46:05.972715 12945 solver.cpp:218] Iteration 3800 (7.19545 iter/s, 13.8977s/100 iters), loss = 0.0495547
I1104 23:46:05.972759 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0495547 (* 1 = 0.0495547 loss)
I1104 23:46:05.972764 12945 sgd_solver.cpp:114] Iteration 3800, lr = 0.009
I1104 23:46:19.889361 12945 solver.cpp:218] Iteration 3900 (7.18597 iter/s, 13.916s/100 iters), loss = 0.0396845
I1104 23:46:19.889434 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0396845 (* 1 = 0.0396845 loss)
I1104 23:46:19.889442 12945 sgd_solver.cpp:114] Iteration 3900, lr = 0.00894444
I1104 23:46:33.810766 12945 solver.cpp:218] Iteration 4000 (7.18353 iter/s, 13.9207s/100 iters), loss = 0.053972
I1104 23:46:33.810811 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.053972 (* 1 = 0.053972 loss)
I1104 23:46:33.810817 12945 sgd_solver.cpp:114] Iteration 4000, lr = 0.00888889
I1104 23:46:47.746937 12945 solver.cpp:218] Iteration 4100 (7.1759 iter/s, 13.9355s/100 iters), loss = 0.065837
I1104 23:46:47.746984 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.065837 (* 1 = 0.065837 loss)
I1104 23:46:47.746992 12945 sgd_solver.cpp:114] Iteration 4100, lr = 0.00883333
I1104 23:47:01.657413 12945 solver.cpp:218] Iteration 4200 (7.18916 iter/s, 13.9098s/100 iters), loss = 0.08724
I1104 23:47:01.657516 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.08724 (* 1 = 0.08724 loss)
I1104 23:47:01.657523 12945 sgd_solver.cpp:114] Iteration 4200, lr = 0.00877778
I1104 23:47:15.588721 12945 solver.cpp:218] Iteration 4300 (7.17844 iter/s, 13.9306s/100 iters), loss = 0.0368158
I1104 23:47:15.588764 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0368158 (* 1 = 0.0368158 loss)
I1104 23:47:15.588771 12945 sgd_solver.cpp:114] Iteration 4300, lr = 0.00872222
I1104 23:47:29.532366 12945 solver.cpp:218] Iteration 4400 (7.17206 iter/s, 13.943s/100 iters), loss = 0.0337181
I1104 23:47:29.532410 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0337181 (* 1 = 0.0337181 loss)
I1104 23:47:29.532418 12945 sgd_solver.cpp:114] Iteration 4400, lr = 0.00866667
I1104 23:47:43.436571 12945 solver.cpp:218] Iteration 4500 (7.1924 iter/s, 13.9036s/100 iters), loss = 0.0621643
I1104 23:47:43.436640 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0621643 (* 1 = 0.0621643 loss)
I1104 23:47:43.436647 12945 sgd_solver.cpp:114] Iteration 4500, lr = 0.00861111
I1104 23:47:57.335752 12945 solver.cpp:218] Iteration 4600 (7.19501 iter/s, 13.8985s/100 iters), loss = 0.0447075
I1104 23:47:57.335794 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0447075 (* 1 = 0.0447075 loss)
I1104 23:47:57.335803 12945 sgd_solver.cpp:114] Iteration 4600, lr = 0.00855555
I1104 23:48:11.254369 12945 solver.cpp:218] Iteration 4700 (7.18495 iter/s, 13.918s/100 iters), loss = 0.0464477
I1104 23:48:11.254413 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0464477 (* 1 = 0.0464477 loss)
I1104 23:48:11.254420 12945 sgd_solver.cpp:114] Iteration 4700, lr = 0.0085
I1104 23:48:25.186061 12945 solver.cpp:218] Iteration 4800 (7.17821 iter/s, 13.9311s/100 iters), loss = 0.0662297
I1104 23:48:25.186203 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0662297 (* 1 = 0.0662297 loss)
I1104 23:48:25.186210 12945 sgd_solver.cpp:114] Iteration 4800, lr = 0.00844444
I1104 23:48:39.116685 12945 solver.cpp:218] Iteration 4900 (7.17881 iter/s, 13.9299s/100 iters), loss = 0.0518401
I1104 23:48:39.116727 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0518401 (* 1 = 0.0518401 loss)
I1104 23:48:39.116735 12945 sgd_solver.cpp:114] Iteration 4900, lr = 0.00838889
I1104 23:48:52.868798 12945 solver.cpp:447] Snapshotting to binary proto file ./snapshot/1/alex-dy_iter_5000.caffemodel
I1104 23:48:53.281824 12945 sgd_solver.cpp:282] Snapshotting solver state to binary proto file ./snapshot/1/alex-dy_iter_5000.solverstate
I1104 23:48:53.378859 12945 solver.cpp:330] Iteration 5000, Testing net (#0)
I1104 23:48:53.378880 12945 net.cpp:676] Ignoring source layer data
I1104 23:48:53.378883 12945 net.cpp:676] Ignoring source layer embedding_fc1
I1104 23:48:53.378885 12945 net.cpp:676] Ignoring source layer bn_embedding_fc1
I1104 23:48:53.378887 12945 net.cpp:676] Ignoring source layer scale_embedding_fc1
I1104 23:48:53.378890 12945 net.cpp:676] Ignoring source layer relu_embedding_fc1
I1104 23:48:53.378891 12945 net.cpp:676] Ignoring source layer embedding_fc2
I1104 23:48:53.378895 12945 net.cpp:676] Ignoring source layer embedding_fc2_embedding_fc2_0_split
I1104 23:48:53.378896 12945 net.cpp:676] Ignoring source layer conv1
I1104 23:48:53.378898 12945 net.cpp:676] Ignoring source layer bn_conv1
I1104 23:48:53.378901 12945 net.cpp:676] Ignoring source layer scale_conv1
I1104 23:48:53.378902 12945 net.cpp:676] Ignoring source layer relu1
I1104 23:48:53.378904 12945 net.cpp:676] Ignoring source layer pool1
I1104 23:48:53.378906 12945 net.cpp:676] Ignoring source layer filter_ip2
I1104 23:48:53.378908 12945 net.cpp:676] Ignoring source layer conv2
I1104 23:48:53.378912 12945 net.cpp:676] Ignoring source layer bn_conv2
I1104 23:48:53.378914 12945 net.cpp:676] Ignoring source layer scale_conv2
I1104 23:48:53.378917 12945 net.cpp:676] Ignoring source layer relu2
I1104 23:48:53.378919 12945 net.cpp:676] Ignoring source layer pool2
I1104 23:48:53.378922 12945 net.cpp:676] Ignoring source layer filter_ip3
I1104 23:48:53.378924 12945 net.cpp:676] Ignoring source layer conv3
I1104 23:48:53.378926 12945 net.cpp:676] Ignoring source layer bn_conv3
I1104 23:48:53.378929 12945 net.cpp:676] Ignoring source layer scale_conv3
I1104 23:48:53.378932 12945 net.cpp:676] Ignoring source layer relu3
I1104 23:48:53.378934 12945 net.cpp:676] Ignoring source layer filter_ip4
I1104 23:48:53.378937 12945 net.cpp:676] Ignoring source layer conv4
I1104 23:48:53.378938 12945 net.cpp:676] Ignoring source layer bn_conv4
I1104 23:48:53.378942 12945 net.cpp:676] Ignoring source layer scale_conv4
I1104 23:48:53.378944 12945 net.cpp:676] Ignoring source layer relu4
I1104 23:48:53.378947 12945 net.cpp:676] Ignoring source layer filter_ip5
I1104 23:48:53.378949 12945 net.cpp:676] Ignoring source layer conv5
I1104 23:48:53.378952 12945 net.cpp:676] Ignoring source layer bn_conv5
I1104 23:48:53.378954 12945 net.cpp:676] Ignoring source layer scale_conv5
I1104 23:48:53.378957 12945 net.cpp:676] Ignoring source layer relu5
I1104 23:48:53.378959 12945 net.cpp:676] Ignoring source layer pool5
I1104 23:48:53.378962 12945 net.cpp:676] Ignoring source layer filter_ip6
I1104 23:48:53.378965 12945 net.cpp:676] Ignoring source layer feat0
I1104 23:48:53.378968 12945 net.cpp:676] Ignoring source layer bn_feat0
I1104 23:48:53.378969 12945 net.cpp:676] Ignoring source layer scale_feat0
I1104 23:48:53.378973 12945 net.cpp:676] Ignoring source layer relu_feat0
I1104 23:48:53.378975 12945 net.cpp:676] Ignoring source layer filter_ip7
I1104 23:48:53.378978 12945 net.cpp:676] Ignoring source layer feat1
I1104 23:48:53.378980 12945 net.cpp:676] Ignoring source layer eucli_loss
W1104 23:48:53.612169 12945 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W1104 23:48:53.612242 12945 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W1104 23:48:53.612252 12945 _caffe.cpp:142] Net('./alexnet-deploy-dy.prototxt', 1, weights='./snapshot/1/alex-dy_iter_5000.caffemodel')
I1104 23:48:53.612444 12945 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./alexnet-deploy-dy.prototxt
I1104 23:48:53.612455 12945 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W1104 23:48:53.612457 12945 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I1104 23:48:53.612638 12945 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-aanet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "extra"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 2
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding_fc1"
  type: "InnerProduct"
  bottom: "extra"
  top: "embedding_fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_embedding_fc1"
  type: "BatchNorm"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_embedding_fc1"
  type: "Scale"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_embedding_fc1"
  type: "ReLU"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
}
layer {
  name: "embedding_fc2"
  type: "InnerProduct"
  bottom: "embedding_fc1"
  top: "embedding_fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip2"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 307200
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  bottom: "filter_ip2"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip3"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 884736
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  bottom: "filter_ip3"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "filter_ip4"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 663552
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  bottom: "filter_ip4"
  top: "conv4"
  param {
    name: "conv4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "filter_ip5"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 442368
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  bottom: "filter_ip5"
  top: "conv5"
  param {
    name: "conv5_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip6"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4718592
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "feat0"
  type: "Convolution"
  bottom: "pool5"
  bottom: "filter_ip6"
  top: "feat0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 6
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_feat0"
  type: "BatchNorm"
  bottom: "feat0"
  top: "feat0"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_feat0"
  type: "Scale"
  bottom: "feat0"
  top: "feat0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_feat0"
  type: "ReLU"
  bottom: "feat0"
  top: "feat0"
}
layer {
  name: "filter_ip7"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "feat1"
  type: "Convolution"
  bottom: "feat0"
  bottom: "filter_ip7"
  top: "feat1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
I1104 23:48:53.612723 12945 layer_factory.hpp:77] Creating layer input
I1104 23:48:53.612730 12945 net.cpp:84] Creating Layer input
I1104 23:48:53.612732 12945 net.cpp:380] input -> data
I1104 23:48:53.612740 12945 net.cpp:380] input -> extra
I1104 23:48:53.612833 12945 net.cpp:122] Setting up input
I1104 23:48:53.612838 12945 net.cpp:129] Top shape: 1 3 224 224 (150528)
I1104 23:48:53.612840 12945 net.cpp:129] Top shape: 1 2 1 1 (2)
I1104 23:48:53.612841 12945 net.cpp:137] Memory required for data: 602120
I1104 23:48:53.612843 12945 layer_factory.hpp:77] Creating layer embedding_fc1
I1104 23:48:53.612848 12945 net.cpp:84] Creating Layer embedding_fc1
I1104 23:48:53.612850 12945 net.cpp:406] embedding_fc1 <- extra
I1104 23:48:53.612854 12945 net.cpp:380] embedding_fc1 -> embedding_fc1
I1104 23:48:53.612957 12945 net.cpp:122] Setting up embedding_fc1
I1104 23:48:53.612962 12945 net.cpp:129] Top shape: 1 256 (256)
I1104 23:48:53.612963 12945 net.cpp:137] Memory required for data: 603144
I1104 23:48:53.612969 12945 layer_factory.hpp:77] Creating layer bn_embedding_fc1
I1104 23:48:53.612973 12945 net.cpp:84] Creating Layer bn_embedding_fc1
I1104 23:48:53.612975 12945 net.cpp:406] bn_embedding_fc1 <- embedding_fc1
I1104 23:48:53.612978 12945 net.cpp:367] bn_embedding_fc1 -> embedding_fc1 (in-place)
I1104 23:48:53.613137 12945 net.cpp:122] Setting up bn_embedding_fc1
I1104 23:48:53.613140 12945 net.cpp:129] Top shape: 1 256 (256)
I1104 23:48:53.613142 12945 net.cpp:137] Memory required for data: 604168
I1104 23:48:53.613147 12945 layer_factory.hpp:77] Creating layer scale_embedding_fc1
I1104 23:48:53.613152 12945 net.cpp:84] Creating Layer scale_embedding_fc1
I1104 23:48:53.613153 12945 net.cpp:406] scale_embedding_fc1 <- embedding_fc1
I1104 23:48:53.613157 12945 net.cpp:367] scale_embedding_fc1 -> embedding_fc1 (in-place)
I1104 23:48:53.613186 12945 layer_factory.hpp:77] Creating layer scale_embedding_fc1
I1104 23:48:53.613276 12945 net.cpp:122] Setting up scale_embedding_fc1
I1104 23:48:53.613278 12945 net.cpp:129] Top shape: 1 256 (256)
I1104 23:48:53.613281 12945 net.cpp:137] Memory required for data: 605192
I1104 23:48:53.613283 12945 layer_factory.hpp:77] Creating layer relu_embedding_fc1
I1104 23:48:53.613287 12945 net.cpp:84] Creating Layer relu_embedding_fc1
I1104 23:48:53.613289 12945 net.cpp:406] relu_embedding_fc1 <- embedding_fc1
I1104 23:48:53.613297 12945 net.cpp:367] relu_embedding_fc1 -> embedding_fc1 (in-place)
I1104 23:48:53.613696 12945 net.cpp:122] Setting up relu_embedding_fc1
I1104 23:48:53.613701 12945 net.cpp:129] Top shape: 1 256 (256)
I1104 23:48:53.613703 12945 net.cpp:137] Memory required for data: 606216
I1104 23:48:53.613705 12945 layer_factory.hpp:77] Creating layer embedding_fc2
I1104 23:48:53.613708 12945 net.cpp:84] Creating Layer embedding_fc2
I1104 23:48:53.613710 12945 net.cpp:406] embedding_fc2 <- embedding_fc1
I1104 23:48:53.613713 12945 net.cpp:380] embedding_fc2 -> embedding_fc2
I1104 23:48:53.613807 12945 net.cpp:122] Setting up embedding_fc2
I1104 23:48:53.613811 12945 net.cpp:129] Top shape: 1 1 (1)
I1104 23:48:53.613812 12945 net.cpp:137] Memory required for data: 606220
I1104 23:48:53.613817 12945 layer_factory.hpp:77] Creating layer embedding_fc2_embedding_fc2_0_split
I1104 23:48:53.613821 12945 net.cpp:84] Creating Layer embedding_fc2_embedding_fc2_0_split
I1104 23:48:53.613822 12945 net.cpp:406] embedding_fc2_embedding_fc2_0_split <- embedding_fc2
I1104 23:48:53.613826 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_0
I1104 23:48:53.613831 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_1
I1104 23:48:53.613834 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_2
I1104 23:48:53.613837 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_3
I1104 23:48:53.613842 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_4
I1104 23:48:53.613845 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_5
I1104 23:48:53.613916 12945 net.cpp:122] Setting up embedding_fc2_embedding_fc2_0_split
I1104 23:48:53.613919 12945 net.cpp:129] Top shape: 1 1 (1)
I1104 23:48:53.613921 12945 net.cpp:129] Top shape: 1 1 (1)
I1104 23:48:53.613924 12945 net.cpp:129] Top shape: 1 1 (1)
I1104 23:48:53.613925 12945 net.cpp:129] Top shape: 1 1 (1)
I1104 23:48:53.613927 12945 net.cpp:129] Top shape: 1 1 (1)
I1104 23:48:53.613929 12945 net.cpp:129] Top shape: 1 1 (1)
I1104 23:48:53.613931 12945 net.cpp:137] Memory required for data: 606244
I1104 23:48:53.613934 12945 layer_factory.hpp:77] Creating layer conv1
I1104 23:48:53.613938 12945 net.cpp:84] Creating Layer conv1
I1104 23:48:53.613940 12945 net.cpp:406] conv1 <- data
I1104 23:48:53.613943 12945 net.cpp:380] conv1 -> conv1
I1104 23:48:53.614385 12945 net.cpp:122] Setting up conv1
I1104 23:48:53.614389 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1104 23:48:53.614392 12945 net.cpp:137] Memory required for data: 1725988
I1104 23:48:53.614394 12945 layer_factory.hpp:77] Creating layer bn_conv1
I1104 23:48:53.614399 12945 net.cpp:84] Creating Layer bn_conv1
I1104 23:48:53.614401 12945 net.cpp:406] bn_conv1 <- conv1
I1104 23:48:53.614403 12945 net.cpp:367] bn_conv1 -> conv1 (in-place)
I1104 23:48:53.614573 12945 net.cpp:122] Setting up bn_conv1
I1104 23:48:53.614576 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1104 23:48:53.614578 12945 net.cpp:137] Memory required for data: 2845732
I1104 23:48:53.614583 12945 layer_factory.hpp:77] Creating layer scale_conv1
I1104 23:48:53.614585 12945 net.cpp:84] Creating Layer scale_conv1
I1104 23:48:53.614588 12945 net.cpp:406] scale_conv1 <- conv1
I1104 23:48:53.614590 12945 net.cpp:367] scale_conv1 -> conv1 (in-place)
I1104 23:48:53.614622 12945 layer_factory.hpp:77] Creating layer scale_conv1
I1104 23:48:53.614723 12945 net.cpp:122] Setting up scale_conv1
I1104 23:48:53.614727 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1104 23:48:53.614729 12945 net.cpp:137] Memory required for data: 3965476
I1104 23:48:53.614732 12945 layer_factory.hpp:77] Creating layer relu1
I1104 23:48:53.614734 12945 net.cpp:84] Creating Layer relu1
I1104 23:48:53.614737 12945 net.cpp:406] relu1 <- conv1
I1104 23:48:53.614739 12945 net.cpp:367] relu1 -> conv1 (in-place)
I1104 23:48:53.615051 12945 net.cpp:122] Setting up relu1
I1104 23:48:53.615061 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1104 23:48:53.615064 12945 net.cpp:137] Memory required for data: 5085220
I1104 23:48:53.615067 12945 layer_factory.hpp:77] Creating layer pool1
I1104 23:48:53.615069 12945 net.cpp:84] Creating Layer pool1
I1104 23:48:53.615072 12945 net.cpp:406] pool1 <- conv1
I1104 23:48:53.615075 12945 net.cpp:380] pool1 -> pool1
I1104 23:48:53.615111 12945 net.cpp:122] Setting up pool1
I1104 23:48:53.615115 12945 net.cpp:129] Top shape: 1 96 27 27 (69984)
I1104 23:48:53.615116 12945 net.cpp:137] Memory required for data: 5365156
I1104 23:48:53.615118 12945 layer_factory.hpp:77] Creating layer filter_ip2
I1104 23:48:53.615123 12945 net.cpp:84] Creating Layer filter_ip2
I1104 23:48:53.615124 12945 net.cpp:406] filter_ip2 <- embedding_fc2_embedding_fc2_0_split_0
I1104 23:48:53.615128 12945 net.cpp:380] filter_ip2 -> filter_ip2
I1104 23:48:53.618144 12945 net.cpp:122] Setting up filter_ip2
I1104 23:48:53.618153 12945 net.cpp:129] Top shape: 1 307200 (307200)
I1104 23:48:53.618155 12945 net.cpp:137] Memory required for data: 6593956
I1104 23:48:53.618162 12945 layer_factory.hpp:77] Creating layer conv2
I1104 23:48:53.618168 12945 net.cpp:84] Creating Layer conv2
I1104 23:48:53.618171 12945 net.cpp:406] conv2 <- pool1
I1104 23:48:53.618175 12945 net.cpp:406] conv2 <- filter_ip2
I1104 23:48:53.618177 12945 net.cpp:380] conv2 -> conv2
I1104 23:48:53.620677 12945 net.cpp:122] Setting up conv2
I1104 23:48:53.620684 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1104 23:48:53.620687 12945 net.cpp:137] Memory required for data: 7340452
I1104 23:48:53.620689 12945 layer_factory.hpp:77] Creating layer bn_conv2
I1104 23:48:53.620694 12945 net.cpp:84] Creating Layer bn_conv2
I1104 23:48:53.620697 12945 net.cpp:406] bn_conv2 <- conv2
I1104 23:48:53.620699 12945 net.cpp:367] bn_conv2 -> conv2 (in-place)
I1104 23:48:53.620875 12945 net.cpp:122] Setting up bn_conv2
I1104 23:48:53.620879 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1104 23:48:53.620880 12945 net.cpp:137] Memory required for data: 8086948
I1104 23:48:53.620884 12945 layer_factory.hpp:77] Creating layer scale_conv2
I1104 23:48:53.620888 12945 net.cpp:84] Creating Layer scale_conv2
I1104 23:48:53.620890 12945 net.cpp:406] scale_conv2 <- conv2
I1104 23:48:53.620893 12945 net.cpp:367] scale_conv2 -> conv2 (in-place)
I1104 23:48:53.620926 12945 layer_factory.hpp:77] Creating layer scale_conv2
I1104 23:48:53.621023 12945 net.cpp:122] Setting up scale_conv2
I1104 23:48:53.621027 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1104 23:48:53.621029 12945 net.cpp:137] Memory required for data: 8833444
I1104 23:48:53.621032 12945 layer_factory.hpp:77] Creating layer relu2
I1104 23:48:53.621037 12945 net.cpp:84] Creating Layer relu2
I1104 23:48:53.621039 12945 net.cpp:406] relu2 <- conv2
I1104 23:48:53.621042 12945 net.cpp:367] relu2 -> conv2 (in-place)
I1104 23:48:53.621603 12945 net.cpp:122] Setting up relu2
I1104 23:48:53.621610 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1104 23:48:53.621613 12945 net.cpp:137] Memory required for data: 9579940
I1104 23:48:53.621615 12945 layer_factory.hpp:77] Creating layer pool2
I1104 23:48:53.621619 12945 net.cpp:84] Creating Layer pool2
I1104 23:48:53.621621 12945 net.cpp:406] pool2 <- conv2
I1104 23:48:53.621625 12945 net.cpp:380] pool2 -> pool2
I1104 23:48:53.621665 12945 net.cpp:122] Setting up pool2
I1104 23:48:53.621668 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1104 23:48:53.621670 12945 net.cpp:137] Memory required for data: 9752996
I1104 23:48:53.621672 12945 layer_factory.hpp:77] Creating layer filter_ip3
I1104 23:48:53.621677 12945 net.cpp:84] Creating Layer filter_ip3
I1104 23:48:53.621680 12945 net.cpp:406] filter_ip3 <- embedding_fc2_embedding_fc2_0_split_1
I1104 23:48:53.621682 12945 net.cpp:380] filter_ip3 -> filter_ip3
I1104 23:48:53.629215 12945 net.cpp:122] Setting up filter_ip3
I1104 23:48:53.629228 12945 net.cpp:129] Top shape: 1 884736 (884736)
I1104 23:48:53.629230 12945 net.cpp:137] Memory required for data: 13291940
I1104 23:48:53.629251 12945 layer_factory.hpp:77] Creating layer conv3
I1104 23:48:53.629261 12945 net.cpp:84] Creating Layer conv3
I1104 23:48:53.629264 12945 net.cpp:406] conv3 <- pool2
I1104 23:48:53.629268 12945 net.cpp:406] conv3 <- filter_ip3
I1104 23:48:53.629271 12945 net.cpp:380] conv3 -> conv3
I1104 23:48:53.635670 12945 net.cpp:122] Setting up conv3
I1104 23:48:53.635685 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1104 23:48:53.635687 12945 net.cpp:137] Memory required for data: 13551524
I1104 23:48:53.635692 12945 layer_factory.hpp:77] Creating layer bn_conv3
I1104 23:48:53.635699 12945 net.cpp:84] Creating Layer bn_conv3
I1104 23:48:53.635701 12945 net.cpp:406] bn_conv3 <- conv3
I1104 23:48:53.635704 12945 net.cpp:367] bn_conv3 -> conv3 (in-place)
I1104 23:48:53.635929 12945 net.cpp:122] Setting up bn_conv3
I1104 23:48:53.635933 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1104 23:48:53.635936 12945 net.cpp:137] Memory required for data: 13811108
I1104 23:48:53.635941 12945 layer_factory.hpp:77] Creating layer scale_conv3
I1104 23:48:53.635944 12945 net.cpp:84] Creating Layer scale_conv3
I1104 23:48:53.635946 12945 net.cpp:406] scale_conv3 <- conv3
I1104 23:48:53.635949 12945 net.cpp:367] scale_conv3 -> conv3 (in-place)
I1104 23:48:53.635979 12945 layer_factory.hpp:77] Creating layer scale_conv3
I1104 23:48:53.636081 12945 net.cpp:122] Setting up scale_conv3
I1104 23:48:53.636085 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1104 23:48:53.636086 12945 net.cpp:137] Memory required for data: 14070692
I1104 23:48:53.636093 12945 layer_factory.hpp:77] Creating layer relu3
I1104 23:48:53.636096 12945 net.cpp:84] Creating Layer relu3
I1104 23:48:53.636098 12945 net.cpp:406] relu3 <- conv3
I1104 23:48:53.636101 12945 net.cpp:367] relu3 -> conv3 (in-place)
I1104 23:48:53.636426 12945 net.cpp:122] Setting up relu3
I1104 23:48:53.636431 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1104 23:48:53.636435 12945 net.cpp:137] Memory required for data: 14330276
I1104 23:48:53.636435 12945 layer_factory.hpp:77] Creating layer filter_ip4
I1104 23:48:53.636440 12945 net.cpp:84] Creating Layer filter_ip4
I1104 23:48:53.636442 12945 net.cpp:406] filter_ip4 <- embedding_fc2_embedding_fc2_0_split_2
I1104 23:48:53.636446 12945 net.cpp:380] filter_ip4 -> filter_ip4
I1104 23:48:53.642091 12945 net.cpp:122] Setting up filter_ip4
I1104 23:48:53.642102 12945 net.cpp:129] Top shape: 1 663552 (663552)
I1104 23:48:53.642104 12945 net.cpp:137] Memory required for data: 16984484
I1104 23:48:53.642112 12945 layer_factory.hpp:77] Creating layer conv4
I1104 23:48:53.642119 12945 net.cpp:84] Creating Layer conv4
I1104 23:48:53.642122 12945 net.cpp:406] conv4 <- conv3
I1104 23:48:53.642125 12945 net.cpp:406] conv4 <- filter_ip4
I1104 23:48:53.642129 12945 net.cpp:380] conv4 -> conv4
I1104 23:48:53.646905 12945 net.cpp:122] Setting up conv4
I1104 23:48:53.646916 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1104 23:48:53.646919 12945 net.cpp:137] Memory required for data: 17244068
I1104 23:48:53.646924 12945 layer_factory.hpp:77] Creating layer bn_conv4
I1104 23:48:53.646929 12945 net.cpp:84] Creating Layer bn_conv4
I1104 23:48:53.646932 12945 net.cpp:406] bn_conv4 <- conv4
I1104 23:48:53.646935 12945 net.cpp:367] bn_conv4 -> conv4 (in-place)
I1104 23:48:53.647111 12945 net.cpp:122] Setting up bn_conv4
I1104 23:48:53.647115 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1104 23:48:53.647117 12945 net.cpp:137] Memory required for data: 17503652
I1104 23:48:53.647121 12945 layer_factory.hpp:77] Creating layer scale_conv4
I1104 23:48:53.647126 12945 net.cpp:84] Creating Layer scale_conv4
I1104 23:48:53.647128 12945 net.cpp:406] scale_conv4 <- conv4
I1104 23:48:53.647131 12945 net.cpp:367] scale_conv4 -> conv4 (in-place)
I1104 23:48:53.647161 12945 layer_factory.hpp:77] Creating layer scale_conv4
I1104 23:48:53.647259 12945 net.cpp:122] Setting up scale_conv4
I1104 23:48:53.647264 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1104 23:48:53.647264 12945 net.cpp:137] Memory required for data: 17763236
I1104 23:48:53.647284 12945 layer_factory.hpp:77] Creating layer relu4
I1104 23:48:53.647289 12945 net.cpp:84] Creating Layer relu4
I1104 23:48:53.647290 12945 net.cpp:406] relu4 <- conv4
I1104 23:48:53.647294 12945 net.cpp:367] relu4 -> conv4 (in-place)
I1104 23:48:53.647625 12945 net.cpp:122] Setting up relu4
I1104 23:48:53.647630 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1104 23:48:53.647632 12945 net.cpp:137] Memory required for data: 18022820
I1104 23:48:53.647634 12945 layer_factory.hpp:77] Creating layer filter_ip5
I1104 23:48:53.647639 12945 net.cpp:84] Creating Layer filter_ip5
I1104 23:48:53.647641 12945 net.cpp:406] filter_ip5 <- embedding_fc2_embedding_fc2_0_split_3
I1104 23:48:53.647644 12945 net.cpp:380] filter_ip5 -> filter_ip5
I1104 23:48:53.651646 12945 net.cpp:122] Setting up filter_ip5
I1104 23:48:53.651655 12945 net.cpp:129] Top shape: 1 442368 (442368)
I1104 23:48:53.651657 12945 net.cpp:137] Memory required for data: 19792292
I1104 23:48:53.651662 12945 layer_factory.hpp:77] Creating layer conv5
I1104 23:48:53.651669 12945 net.cpp:84] Creating Layer conv5
I1104 23:48:53.651672 12945 net.cpp:406] conv5 <- conv4
I1104 23:48:53.651675 12945 net.cpp:406] conv5 <- filter_ip5
I1104 23:48:53.651679 12945 net.cpp:380] conv5 -> conv5
I1104 23:48:53.655012 12945 net.cpp:122] Setting up conv5
I1104 23:48:53.655020 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1104 23:48:53.655023 12945 net.cpp:137] Memory required for data: 19965348
I1104 23:48:53.655027 12945 layer_factory.hpp:77] Creating layer bn_conv5
I1104 23:48:53.655032 12945 net.cpp:84] Creating Layer bn_conv5
I1104 23:48:53.655035 12945 net.cpp:406] bn_conv5 <- conv5
I1104 23:48:53.655038 12945 net.cpp:367] bn_conv5 -> conv5 (in-place)
I1104 23:48:53.655215 12945 net.cpp:122] Setting up bn_conv5
I1104 23:48:53.655218 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1104 23:48:53.655220 12945 net.cpp:137] Memory required for data: 20138404
I1104 23:48:53.655225 12945 layer_factory.hpp:77] Creating layer scale_conv5
I1104 23:48:53.655228 12945 net.cpp:84] Creating Layer scale_conv5
I1104 23:48:53.655230 12945 net.cpp:406] scale_conv5 <- conv5
I1104 23:48:53.655249 12945 net.cpp:367] scale_conv5 -> conv5 (in-place)
I1104 23:48:53.655282 12945 layer_factory.hpp:77] Creating layer scale_conv5
I1104 23:48:53.655395 12945 net.cpp:122] Setting up scale_conv5
I1104 23:48:53.655398 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1104 23:48:53.655400 12945 net.cpp:137] Memory required for data: 20311460
I1104 23:48:53.655403 12945 layer_factory.hpp:77] Creating layer relu5
I1104 23:48:53.655409 12945 net.cpp:84] Creating Layer relu5
I1104 23:48:53.655411 12945 net.cpp:406] relu5 <- conv5
I1104 23:48:53.655414 12945 net.cpp:367] relu5 -> conv5 (in-place)
I1104 23:48:53.655907 12945 net.cpp:122] Setting up relu5
I1104 23:48:53.655915 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1104 23:48:53.655916 12945 net.cpp:137] Memory required for data: 20484516
I1104 23:48:53.655918 12945 layer_factory.hpp:77] Creating layer pool5
I1104 23:48:53.655923 12945 net.cpp:84] Creating Layer pool5
I1104 23:48:53.655925 12945 net.cpp:406] pool5 <- conv5
I1104 23:48:53.655928 12945 net.cpp:380] pool5 -> pool5
I1104 23:48:53.655966 12945 net.cpp:122] Setting up pool5
I1104 23:48:53.655970 12945 net.cpp:129] Top shape: 1 256 6 6 (9216)
I1104 23:48:53.655972 12945 net.cpp:137] Memory required for data: 20521380
I1104 23:48:53.655973 12945 layer_factory.hpp:77] Creating layer filter_ip6
I1104 23:48:53.655978 12945 net.cpp:84] Creating Layer filter_ip6
I1104 23:48:53.655980 12945 net.cpp:406] filter_ip6 <- embedding_fc2_embedding_fc2_0_split_4
I1104 23:48:53.655983 12945 net.cpp:380] filter_ip6 -> filter_ip6
I1104 23:48:53.693748 12945 net.cpp:122] Setting up filter_ip6
I1104 23:48:53.693768 12945 net.cpp:129] Top shape: 1 4718592 (4718592)
I1104 23:48:53.693770 12945 net.cpp:137] Memory required for data: 39395748
I1104 23:48:53.693778 12945 layer_factory.hpp:77] Creating layer feat0
I1104 23:48:53.693789 12945 net.cpp:84] Creating Layer feat0
I1104 23:48:53.693790 12945 net.cpp:406] feat0 <- pool5
I1104 23:48:53.693814 12945 net.cpp:406] feat0 <- filter_ip6
I1104 23:48:53.693819 12945 net.cpp:380] feat0 -> feat0
I1104 23:48:53.726241 12945 net.cpp:122] Setting up feat0
I1104 23:48:53.726258 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1104 23:48:53.726260 12945 net.cpp:137] Memory required for data: 39397796
I1104 23:48:53.726265 12945 layer_factory.hpp:77] Creating layer bn_feat0
I1104 23:48:53.726272 12945 net.cpp:84] Creating Layer bn_feat0
I1104 23:48:53.726275 12945 net.cpp:406] bn_feat0 <- feat0
I1104 23:48:53.726279 12945 net.cpp:367] bn_feat0 -> feat0 (in-place)
I1104 23:48:53.726461 12945 net.cpp:122] Setting up bn_feat0
I1104 23:48:53.726464 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1104 23:48:53.726466 12945 net.cpp:137] Memory required for data: 39399844
I1104 23:48:53.726471 12945 layer_factory.hpp:77] Creating layer scale_feat0
I1104 23:48:53.726475 12945 net.cpp:84] Creating Layer scale_feat0
I1104 23:48:53.726477 12945 net.cpp:406] scale_feat0 <- feat0
I1104 23:48:53.726480 12945 net.cpp:367] scale_feat0 -> feat0 (in-place)
I1104 23:48:53.726511 12945 layer_factory.hpp:77] Creating layer scale_feat0
I1104 23:48:53.726613 12945 net.cpp:122] Setting up scale_feat0
I1104 23:48:53.726615 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1104 23:48:53.726617 12945 net.cpp:137] Memory required for data: 39401892
I1104 23:48:53.726621 12945 layer_factory.hpp:77] Creating layer relu_feat0
I1104 23:48:53.726624 12945 net.cpp:84] Creating Layer relu_feat0
I1104 23:48:53.726626 12945 net.cpp:406] relu_feat0 <- feat0
I1104 23:48:53.726629 12945 net.cpp:367] relu_feat0 -> feat0 (in-place)
I1104 23:48:53.726991 12945 net.cpp:122] Setting up relu_feat0
I1104 23:48:53.726996 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1104 23:48:53.726999 12945 net.cpp:137] Memory required for data: 39403940
I1104 23:48:53.726999 12945 layer_factory.hpp:77] Creating layer filter_ip7
I1104 23:48:53.727005 12945 net.cpp:84] Creating Layer filter_ip7
I1104 23:48:53.727006 12945 net.cpp:406] filter_ip7 <- embedding_fc2_embedding_fc2_0_split_5
I1104 23:48:53.727010 12945 net.cpp:380] filter_ip7 -> filter_ip7
I1104 23:48:53.727114 12945 net.cpp:122] Setting up filter_ip7
I1104 23:48:53.727118 12945 net.cpp:129] Top shape: 1 512 (512)
I1104 23:48:53.727119 12945 net.cpp:137] Memory required for data: 39405988
I1104 23:48:53.727123 12945 layer_factory.hpp:77] Creating layer feat1
I1104 23:48:53.727128 12945 net.cpp:84] Creating Layer feat1
I1104 23:48:53.727131 12945 net.cpp:406] feat1 <- feat0
I1104 23:48:53.727133 12945 net.cpp:406] feat1 <- filter_ip7
I1104 23:48:53.727136 12945 net.cpp:380] feat1 -> feat1
I1104 23:48:53.727371 12945 net.cpp:122] Setting up feat1
I1104 23:48:53.727375 12945 net.cpp:129] Top shape: 1 1 1 1 (1)
I1104 23:48:53.727377 12945 net.cpp:137] Memory required for data: 39405992
I1104 23:48:53.727385 12945 net.cpp:200] feat1 does not need backward computation.
I1104 23:48:53.727387 12945 net.cpp:200] filter_ip7 does not need backward computation.
I1104 23:48:53.727391 12945 net.cpp:200] relu_feat0 does not need backward computation.
I1104 23:48:53.727391 12945 net.cpp:200] scale_feat0 does not need backward computation.
I1104 23:48:53.727393 12945 net.cpp:200] bn_feat0 does not need backward computation.
I1104 23:48:53.727394 12945 net.cpp:200] feat0 does not need backward computation.
I1104 23:48:53.727397 12945 net.cpp:200] filter_ip6 does not need backward computation.
I1104 23:48:53.727399 12945 net.cpp:200] pool5 does not need backward computation.
I1104 23:48:53.727401 12945 net.cpp:200] relu5 does not need backward computation.
I1104 23:48:53.727403 12945 net.cpp:200] scale_conv5 does not need backward computation.
I1104 23:48:53.727406 12945 net.cpp:200] bn_conv5 does not need backward computation.
I1104 23:48:53.727406 12945 net.cpp:200] conv5 does not need backward computation.
I1104 23:48:53.727409 12945 net.cpp:200] filter_ip5 does not need backward computation.
I1104 23:48:53.727411 12945 net.cpp:200] relu4 does not need backward computation.
I1104 23:48:53.727413 12945 net.cpp:200] scale_conv4 does not need backward computation.
I1104 23:48:53.727429 12945 net.cpp:200] bn_conv4 does not need backward computation.
I1104 23:48:53.727432 12945 net.cpp:200] conv4 does not need backward computation.
I1104 23:48:53.727434 12945 net.cpp:200] filter_ip4 does not need backward computation.
I1104 23:48:53.727437 12945 net.cpp:200] relu3 does not need backward computation.
I1104 23:48:53.727438 12945 net.cpp:200] scale_conv3 does not need backward computation.
I1104 23:48:53.727440 12945 net.cpp:200] bn_conv3 does not need backward computation.
I1104 23:48:53.727442 12945 net.cpp:200] conv3 does not need backward computation.
I1104 23:48:53.727444 12945 net.cpp:200] filter_ip3 does not need backward computation.
I1104 23:48:53.727447 12945 net.cpp:200] pool2 does not need backward computation.
I1104 23:48:53.727448 12945 net.cpp:200] relu2 does not need backward computation.
I1104 23:48:53.727450 12945 net.cpp:200] scale_conv2 does not need backward computation.
I1104 23:48:53.727452 12945 net.cpp:200] bn_conv2 does not need backward computation.
I1104 23:48:53.727454 12945 net.cpp:200] conv2 does not need backward computation.
I1104 23:48:53.727457 12945 net.cpp:200] filter_ip2 does not need backward computation.
I1104 23:48:53.727458 12945 net.cpp:200] pool1 does not need backward computation.
I1104 23:48:53.727460 12945 net.cpp:200] relu1 does not need backward computation.
I1104 23:48:53.727463 12945 net.cpp:200] scale_conv1 does not need backward computation.
I1104 23:48:53.727463 12945 net.cpp:200] bn_conv1 does not need backward computation.
I1104 23:48:53.727465 12945 net.cpp:200] conv1 does not need backward computation.
I1104 23:48:53.727468 12945 net.cpp:200] embedding_fc2_embedding_fc2_0_split does not need backward computation.
I1104 23:48:53.727470 12945 net.cpp:200] embedding_fc2 does not need backward computation.
I1104 23:48:53.727473 12945 net.cpp:200] relu_embedding_fc1 does not need backward computation.
I1104 23:48:53.727474 12945 net.cpp:200] scale_embedding_fc1 does not need backward computation.
I1104 23:48:53.727476 12945 net.cpp:200] bn_embedding_fc1 does not need backward computation.
I1104 23:48:53.727478 12945 net.cpp:200] embedding_fc1 does not need backward computation.
I1104 23:48:53.727480 12945 net.cpp:200] input does not need backward computation.
I1104 23:48:53.727481 12945 net.cpp:242] This network produces output feat1
I1104 23:48:53.727496 12945 net.cpp:255] Network initialization done.
I1104 23:48:53.763634 12945 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./snapshot/1/alex-dy_iter_5000.caffemodel
I1104 23:48:53.763650 12945 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1104 23:48:53.763654 12945 net.cpp:744] Ignoring source layer data
I1104 23:48:53.823845 12945 net.cpp:744] Ignoring source layer eucli_loss
I1104 23:49:09.694121 12945 solver.cpp:397]     Test net output #0: accuracy = 0.861658
I1104 23:49:09.694228 12945 solver.cpp:397]     Test net output #1: mae = 0.301489
I1104 23:49:09.694236 12945 solver.cpp:397]     Test net output #2: rmse = 0.381614
I1104 23:49:09.831596 12945 solver.cpp:218] Iteration 5000 (3.25589 iter/s, 30.7136s/100 iters), loss = 0.0398688
I1104 23:49:09.831640 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0398688 (* 1 = 0.0398688 loss)
I1104 23:49:09.831648 12945 sgd_solver.cpp:114] Iteration 5000, lr = 0.00833333
I1104 23:49:23.626569 12945 solver.cpp:218] Iteration 5100 (7.24935 iter/s, 13.7943s/100 iters), loss = 0.0428255
I1104 23:49:23.626612 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0428255 (* 1 = 0.0428255 loss)
I1104 23:49:23.626619 12945 sgd_solver.cpp:114] Iteration 5100, lr = 0.00827778
I1104 23:49:37.421604 12945 solver.cpp:218] Iteration 5200 (7.24932 iter/s, 13.7944s/100 iters), loss = 0.0506922
I1104 23:49:37.421646 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0506922 (* 1 = 0.0506922 loss)
I1104 23:49:37.421654 12945 sgd_solver.cpp:114] Iteration 5200, lr = 0.00822222
I1104 23:49:51.224414 12945 solver.cpp:218] Iteration 5300 (7.24523 iter/s, 13.8022s/100 iters), loss = 0.0446974
I1104 23:49:51.224592 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0446974 (* 1 = 0.0446974 loss)
I1104 23:49:51.224604 12945 sgd_solver.cpp:114] Iteration 5300, lr = 0.00816667
I1104 23:50:05.031491 12945 solver.cpp:218] Iteration 5400 (7.24306 iter/s, 13.8063s/100 iters), loss = 0.0673768
I1104 23:50:05.031533 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0673768 (* 1 = 0.0673768 loss)
I1104 23:50:05.031540 12945 sgd_solver.cpp:114] Iteration 5400, lr = 0.00811111
I1104 23:50:18.886404 12945 solver.cpp:218] Iteration 5500 (7.21799 iter/s, 13.8543s/100 iters), loss = 0.023837
I1104 23:50:18.886448 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0238369 (* 1 = 0.0238369 loss)
I1104 23:50:18.886456 12945 sgd_solver.cpp:114] Iteration 5500, lr = 0.00805556
I1104 23:50:32.762405 12945 solver.cpp:218] Iteration 5600 (7.20702 iter/s, 13.8754s/100 iters), loss = 0.0723408
I1104 23:50:32.762477 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0723407 (* 1 = 0.0723407 loss)
I1104 23:50:32.762486 12945 sgd_solver.cpp:114] Iteration 5600, lr = 0.008
I1104 23:50:46.632743 12945 solver.cpp:218] Iteration 5700 (7.20997 iter/s, 13.8697s/100 iters), loss = 0.0698934
I1104 23:50:46.632784 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0698934 (* 1 = 0.0698934 loss)
I1104 23:50:46.632791 12945 sgd_solver.cpp:114] Iteration 5700, lr = 0.00794444
I1104 23:51:00.558019 12945 solver.cpp:218] Iteration 5800 (7.18151 iter/s, 13.9246s/100 iters), loss = 0.0490619
I1104 23:51:00.558063 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0490619 (* 1 = 0.0490619 loss)
I1104 23:51:00.558069 12945 sgd_solver.cpp:114] Iteration 5800, lr = 0.00788889
I1104 23:51:14.455467 12945 solver.cpp:218] Iteration 5900 (7.19589 iter/s, 13.8968s/100 iters), loss = 0.0613267
I1104 23:51:14.455613 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0613267 (* 1 = 0.0613267 loss)
I1104 23:51:14.455624 12945 sgd_solver.cpp:114] Iteration 5900, lr = 0.00783333
I1104 23:51:28.344879 12945 solver.cpp:218] Iteration 6000 (7.20011 iter/s, 13.8887s/100 iters), loss = 0.0448121
I1104 23:51:28.344923 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0448121 (* 1 = 0.0448121 loss)
I1104 23:51:28.344930 12945 sgd_solver.cpp:114] Iteration 6000, lr = 0.00777778
I1104 23:51:42.268970 12945 solver.cpp:218] Iteration 6100 (7.18212 iter/s, 13.9235s/100 iters), loss = 0.047453
I1104 23:51:42.269008 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0474529 (* 1 = 0.0474529 loss)
I1104 23:51:42.269016 12945 sgd_solver.cpp:114] Iteration 6100, lr = 0.00772222
I1104 23:51:56.142280 12945 solver.cpp:218] Iteration 6200 (7.20841 iter/s, 13.8727s/100 iters), loss = 0.0289526
I1104 23:51:56.142427 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0289526 (* 1 = 0.0289526 loss)
I1104 23:51:56.142439 12945 sgd_solver.cpp:114] Iteration 6200, lr = 0.00766667
I1104 23:52:10.040506 12945 solver.cpp:218] Iteration 6300 (7.19554 iter/s, 13.8975s/100 iters), loss = 0.065629
I1104 23:52:10.040545 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.065629 (* 1 = 0.065629 loss)
I1104 23:52:10.040552 12945 sgd_solver.cpp:114] Iteration 6300, lr = 0.00761111
I1104 23:52:23.980298 12945 solver.cpp:218] Iteration 6400 (7.17404 iter/s, 13.9392s/100 iters), loss = 0.0479199
I1104 23:52:23.980341 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0479198 (* 1 = 0.0479198 loss)
I1104 23:52:23.980348 12945 sgd_solver.cpp:114] Iteration 6400, lr = 0.00755556
I1104 23:52:37.892099 12945 solver.cpp:218] Iteration 6500 (7.18847 iter/s, 13.9112s/100 iters), loss = 0.0292793
I1104 23:52:37.892206 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0292793 (* 1 = 0.0292793 loss)
I1104 23:52:37.892215 12945 sgd_solver.cpp:114] Iteration 6500, lr = 0.0075
I1104 23:52:51.769477 12945 solver.cpp:218] Iteration 6600 (7.20633 iter/s, 13.8767s/100 iters), loss = 0.0658543
I1104 23:52:51.769520 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0658543 (* 1 = 0.0658543 loss)
I1104 23:52:51.769526 12945 sgd_solver.cpp:114] Iteration 6600, lr = 0.00744444
I1104 23:53:05.668429 12945 solver.cpp:218] Iteration 6700 (7.19512 iter/s, 13.8983s/100 iters), loss = 0.061865
I1104 23:53:05.668470 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.061865 (* 1 = 0.061865 loss)
I1104 23:53:05.668478 12945 sgd_solver.cpp:114] Iteration 6700, lr = 0.00738889
I1104 23:53:19.571568 12945 solver.cpp:218] Iteration 6800 (7.19295 iter/s, 13.9025s/100 iters), loss = 0.0611921
I1104 23:53:19.571735 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0611921 (* 1 = 0.0611921 loss)
I1104 23:53:19.571753 12945 sgd_solver.cpp:114] Iteration 6800, lr = 0.00733333
I1104 23:53:33.490875 12945 solver.cpp:218] Iteration 6900 (7.18465 iter/s, 13.9186s/100 iters), loss = 0.0518523
I1104 23:53:33.490917 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0518523 (* 1 = 0.0518523 loss)
I1104 23:53:33.490926 12945 sgd_solver.cpp:114] Iteration 6900, lr = 0.00727778
I1104 23:53:47.394266 12945 solver.cpp:218] Iteration 7000 (7.19282 iter/s, 13.9028s/100 iters), loss = 0.0236186
I1104 23:53:47.394309 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0236186 (* 1 = 0.0236186 loss)
I1104 23:53:47.394316 12945 sgd_solver.cpp:114] Iteration 7000, lr = 0.00722222
I1104 23:54:01.289489 12945 solver.cpp:218] Iteration 7100 (7.19705 iter/s, 13.8946s/100 iters), loss = 0.0234898
I1104 23:54:01.289589 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0234898 (* 1 = 0.0234898 loss)
I1104 23:54:01.289598 12945 sgd_solver.cpp:114] Iteration 7100, lr = 0.00716667
I1104 23:54:15.137408 12945 solver.cpp:218] Iteration 7200 (7.22166 iter/s, 13.8472s/100 iters), loss = 0.0331811
I1104 23:54:15.137450 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.033181 (* 1 = 0.033181 loss)
I1104 23:54:15.137459 12945 sgd_solver.cpp:114] Iteration 7200, lr = 0.00711111
I1104 23:54:29.049723 12945 solver.cpp:218] Iteration 7300 (7.1882 iter/s, 13.9117s/100 iters), loss = 0.0486108
I1104 23:54:29.049767 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0486108 (* 1 = 0.0486108 loss)
I1104 23:54:29.049774 12945 sgd_solver.cpp:114] Iteration 7300, lr = 0.00705556
I1104 23:54:42.934160 12945 solver.cpp:218] Iteration 7400 (7.20264 iter/s, 13.8838s/100 iters), loss = 0.0401713
I1104 23:54:42.934240 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0401713 (* 1 = 0.0401713 loss)
I1104 23:54:42.934249 12945 sgd_solver.cpp:114] Iteration 7400, lr = 0.007
I1104 23:54:56.823940 12945 solver.cpp:218] Iteration 7500 (7.19988 iter/s, 13.8891s/100 iters), loss = 0.0241693
I1104 23:54:56.823982 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0241693 (* 1 = 0.0241693 loss)
I1104 23:54:56.823989 12945 sgd_solver.cpp:114] Iteration 7500, lr = 0.00694444
I1104 23:55:10.745083 12945 solver.cpp:218] Iteration 7600 (7.18365 iter/s, 13.9205s/100 iters), loss = 0.025178
I1104 23:55:10.745129 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.025178 (* 1 = 0.025178 loss)
I1104 23:55:10.745137 12945 sgd_solver.cpp:114] Iteration 7600, lr = 0.00688889
I1104 23:55:24.620604 12945 solver.cpp:218] Iteration 7700 (7.20727 iter/s, 13.8749s/100 iters), loss = 0.0291085
I1104 23:55:24.620709 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0291085 (* 1 = 0.0291085 loss)
I1104 23:55:24.620716 12945 sgd_solver.cpp:114] Iteration 7700, lr = 0.00683333
I1104 23:55:38.536486 12945 solver.cpp:218] Iteration 7800 (7.18639 iter/s, 13.9152s/100 iters), loss = 0.0501753
I1104 23:55:38.536527 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0501752 (* 1 = 0.0501752 loss)
I1104 23:55:38.536535 12945 sgd_solver.cpp:114] Iteration 7800, lr = 0.00677778
I1104 23:55:52.434296 12945 solver.cpp:218] Iteration 7900 (7.19571 iter/s, 13.8972s/100 iters), loss = 0.031917
I1104 23:55:52.434335 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.031917 (* 1 = 0.031917 loss)
I1104 23:55:52.434343 12945 sgd_solver.cpp:114] Iteration 7900, lr = 0.00672222
I1104 23:56:06.363859 12945 solver.cpp:218] Iteration 8000 (7.1793 iter/s, 13.9289s/100 iters), loss = 0.0373971
I1104 23:56:06.364006 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.037397 (* 1 = 0.037397 loss)
I1104 23:56:06.364014 12945 sgd_solver.cpp:114] Iteration 8000, lr = 0.00666667
I1104 23:56:20.269896 12945 solver.cpp:218] Iteration 8100 (7.1915 iter/s, 13.9053s/100 iters), loss = 0.0239564
I1104 23:56:20.269939 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0239563 (* 1 = 0.0239563 loss)
I1104 23:56:20.269946 12945 sgd_solver.cpp:114] Iteration 8100, lr = 0.00661111
I1104 23:56:34.183759 12945 solver.cpp:218] Iteration 8200 (7.1874 iter/s, 13.9132s/100 iters), loss = 0.034578
I1104 23:56:34.183800 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0345779 (* 1 = 0.0345779 loss)
I1104 23:56:34.183809 12945 sgd_solver.cpp:114] Iteration 8200, lr = 0.00655556
I1104 23:56:48.083354 12945 solver.cpp:218] Iteration 8300 (7.19478 iter/s, 13.899s/100 iters), loss = 0.0344923
I1104 23:56:48.083428 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0344923 (* 1 = 0.0344923 loss)
I1104 23:56:48.083436 12945 sgd_solver.cpp:114] Iteration 8300, lr = 0.0065
I1104 23:57:01.988664 12945 solver.cpp:218] Iteration 8400 (7.19184 iter/s, 13.9046s/100 iters), loss = 0.0262397
I1104 23:57:01.988708 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0262397 (* 1 = 0.0262397 loss)
I1104 23:57:01.988715 12945 sgd_solver.cpp:114] Iteration 8400, lr = 0.00644444
I1104 23:57:15.879160 12945 solver.cpp:218] Iteration 8500 (7.1995 iter/s, 13.8899s/100 iters), loss = 0.0239281
I1104 23:57:15.879204 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.023928 (* 1 = 0.023928 loss)
I1104 23:57:15.879210 12945 sgd_solver.cpp:114] Iteration 8500, lr = 0.00638889
I1104 23:57:29.820014 12945 solver.cpp:218] Iteration 8600 (7.17349 iter/s, 13.9402s/100 iters), loss = 0.0234437
I1104 23:57:29.820132 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0234437 (* 1 = 0.0234437 loss)
I1104 23:57:29.820139 12945 sgd_solver.cpp:114] Iteration 8600, lr = 0.00633333
I1104 23:57:43.726649 12945 solver.cpp:218] Iteration 8700 (7.19115 iter/s, 13.906s/100 iters), loss = 0.032284
I1104 23:57:43.726687 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.032284 (* 1 = 0.032284 loss)
I1104 23:57:43.726694 12945 sgd_solver.cpp:114] Iteration 8700, lr = 0.00627778
I1104 23:57:57.658968 12945 solver.cpp:218] Iteration 8800 (7.17785 iter/s, 13.9317s/100 iters), loss = 0.048513
I1104 23:57:57.659011 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.048513 (* 1 = 0.048513 loss)
I1104 23:57:57.659018 12945 sgd_solver.cpp:114] Iteration 8800, lr = 0.00622222
I1104 23:58:11.556437 12945 solver.cpp:218] Iteration 8900 (7.19586 iter/s, 13.8969s/100 iters), loss = 0.0385798
I1104 23:58:11.556542 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0385798 (* 1 = 0.0385798 loss)
I1104 23:58:11.556551 12945 sgd_solver.cpp:114] Iteration 8900, lr = 0.00616667
I1104 23:58:25.496668 12945 solver.cpp:218] Iteration 9000 (7.17381 iter/s, 13.9396s/100 iters), loss = 0.0599303
I1104 23:58:25.496708 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0599303 (* 1 = 0.0599303 loss)
I1104 23:58:25.496718 12945 sgd_solver.cpp:114] Iteration 9000, lr = 0.00611111
I1104 23:58:39.441824 12945 solver.cpp:218] Iteration 9100 (7.17125 iter/s, 13.9446s/100 iters), loss = 0.0535068
I1104 23:58:39.441867 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0535067 (* 1 = 0.0535067 loss)
I1104 23:58:39.441875 12945 sgd_solver.cpp:114] Iteration 9100, lr = 0.00605556
I1104 23:58:53.384263 12945 solver.cpp:218] Iteration 9200 (7.17265 iter/s, 13.9419s/100 iters), loss = 0.0332148
I1104 23:58:53.384408 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0332147 (* 1 = 0.0332147 loss)
I1104 23:58:53.384416 12945 sgd_solver.cpp:114] Iteration 9200, lr = 0.006
I1104 23:59:07.298709 12945 solver.cpp:218] Iteration 9300 (7.18713 iter/s, 13.9138s/100 iters), loss = 0.0346462
I1104 23:59:07.298749 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0346462 (* 1 = 0.0346462 loss)
I1104 23:59:07.298756 12945 sgd_solver.cpp:114] Iteration 9300, lr = 0.00594444
I1104 23:59:21.225916 12945 solver.cpp:218] Iteration 9400 (7.18049 iter/s, 13.9266s/100 iters), loss = 0.0712221
I1104 23:59:21.225960 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0712221 (* 1 = 0.0712221 loss)
I1104 23:59:21.225966 12945 sgd_solver.cpp:114] Iteration 9400, lr = 0.00588889
I1104 23:59:35.113819 12945 solver.cpp:218] Iteration 9500 (7.20081 iter/s, 13.8873s/100 iters), loss = 0.038731
I1104 23:59:35.113924 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.038731 (* 1 = 0.038731 loss)
I1104 23:59:35.113932 12945 sgd_solver.cpp:114] Iteration 9500, lr = 0.00583333
I1104 23:59:49.024461 12945 solver.cpp:218] Iteration 9600 (7.18908 iter/s, 13.91s/100 iters), loss = 0.0192559
I1104 23:59:49.024499 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0192558 (* 1 = 0.0192558 loss)
I1104 23:59:49.024507 12945 sgd_solver.cpp:114] Iteration 9600, lr = 0.00577778
I1105 00:00:02.917042 12945 solver.cpp:218] Iteration 9700 (7.19839 iter/s, 13.892s/100 iters), loss = 0.0272453
I1105 00:00:02.917083 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0272452 (* 1 = 0.0272452 loss)
I1105 00:00:02.917091 12945 sgd_solver.cpp:114] Iteration 9700, lr = 0.00572222
I1105 00:00:16.844952 12945 solver.cpp:218] Iteration 9800 (7.18013 iter/s, 13.9273s/100 iters), loss = 0.0323706
I1105 00:00:16.845063 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0323706 (* 1 = 0.0323706 loss)
I1105 00:00:16.845072 12945 sgd_solver.cpp:114] Iteration 9800, lr = 0.00566667
I1105 00:00:30.800748 12945 solver.cpp:218] Iteration 9900 (7.16582 iter/s, 13.9551s/100 iters), loss = 0.0518465
I1105 00:00:30.800773 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0518465 (* 1 = 0.0518465 loss)
I1105 00:00:30.800778 12945 sgd_solver.cpp:114] Iteration 9900, lr = 0.00561111
I1105 00:00:44.386822 12945 solver.cpp:447] Snapshotting to binary proto file ./snapshot/1/alex-dy_iter_10000.caffemodel
I1105 00:00:44.624939 12945 sgd_solver.cpp:282] Snapshotting solver state to binary proto file ./snapshot/1/alex-dy_iter_10000.solverstate
I1105 00:00:44.765247 12945 solver.cpp:330] Iteration 10000, Testing net (#0)
I1105 00:00:44.765269 12945 net.cpp:676] Ignoring source layer data
I1105 00:00:44.765273 12945 net.cpp:676] Ignoring source layer embedding_fc1
I1105 00:00:44.765276 12945 net.cpp:676] Ignoring source layer bn_embedding_fc1
I1105 00:00:44.765278 12945 net.cpp:676] Ignoring source layer scale_embedding_fc1
I1105 00:00:44.765281 12945 net.cpp:676] Ignoring source layer relu_embedding_fc1
I1105 00:00:44.765285 12945 net.cpp:676] Ignoring source layer embedding_fc2
I1105 00:00:44.765287 12945 net.cpp:676] Ignoring source layer embedding_fc2_embedding_fc2_0_split
I1105 00:00:44.765290 12945 net.cpp:676] Ignoring source layer conv1
I1105 00:00:44.765293 12945 net.cpp:676] Ignoring source layer bn_conv1
I1105 00:00:44.765298 12945 net.cpp:676] Ignoring source layer scale_conv1
I1105 00:00:44.765301 12945 net.cpp:676] Ignoring source layer relu1
I1105 00:00:44.765305 12945 net.cpp:676] Ignoring source layer pool1
I1105 00:00:44.765306 12945 net.cpp:676] Ignoring source layer filter_ip2
I1105 00:00:44.765311 12945 net.cpp:676] Ignoring source layer conv2
I1105 00:00:44.765313 12945 net.cpp:676] Ignoring source layer bn_conv2
I1105 00:00:44.765316 12945 net.cpp:676] Ignoring source layer scale_conv2
I1105 00:00:44.765318 12945 net.cpp:676] Ignoring source layer relu2
I1105 00:00:44.765322 12945 net.cpp:676] Ignoring source layer pool2
I1105 00:00:44.765326 12945 net.cpp:676] Ignoring source layer filter_ip3
I1105 00:00:44.765328 12945 net.cpp:676] Ignoring source layer conv3
I1105 00:00:44.765331 12945 net.cpp:676] Ignoring source layer bn_conv3
I1105 00:00:44.765336 12945 net.cpp:676] Ignoring source layer scale_conv3
I1105 00:00:44.765337 12945 net.cpp:676] Ignoring source layer relu3
I1105 00:00:44.765341 12945 net.cpp:676] Ignoring source layer filter_ip4
I1105 00:00:44.765343 12945 net.cpp:676] Ignoring source layer conv4
I1105 00:00:44.765347 12945 net.cpp:676] Ignoring source layer bn_conv4
I1105 00:00:44.765350 12945 net.cpp:676] Ignoring source layer scale_conv4
I1105 00:00:44.765354 12945 net.cpp:676] Ignoring source layer relu4
I1105 00:00:44.765357 12945 net.cpp:676] Ignoring source layer filter_ip5
I1105 00:00:44.765360 12945 net.cpp:676] Ignoring source layer conv5
I1105 00:00:44.765363 12945 net.cpp:676] Ignoring source layer bn_conv5
I1105 00:00:44.765367 12945 net.cpp:676] Ignoring source layer scale_conv5
I1105 00:00:44.765370 12945 net.cpp:676] Ignoring source layer relu5
I1105 00:00:44.765374 12945 net.cpp:676] Ignoring source layer pool5
I1105 00:00:44.765377 12945 net.cpp:676] Ignoring source layer filter_ip6
I1105 00:00:44.765380 12945 net.cpp:676] Ignoring source layer feat0
I1105 00:00:44.765384 12945 net.cpp:676] Ignoring source layer bn_feat0
I1105 00:00:44.765388 12945 net.cpp:676] Ignoring source layer scale_feat0
I1105 00:00:44.765391 12945 net.cpp:676] Ignoring source layer relu_feat0
I1105 00:00:44.765394 12945 net.cpp:676] Ignoring source layer filter_ip7
I1105 00:00:44.765398 12945 net.cpp:676] Ignoring source layer feat1
I1105 00:00:44.765403 12945 net.cpp:676] Ignoring source layer eucli_loss
W1105 00:00:44.998183 12945 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W1105 00:00:44.998206 12945 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W1105 00:00:44.998221 12945 _caffe.cpp:142] Net('./alexnet-deploy-dy.prototxt', 1, weights='./snapshot/1/alex-dy_iter_10000.caffemodel')
I1105 00:00:44.998428 12945 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./alexnet-deploy-dy.prototxt
I1105 00:00:44.998437 12945 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W1105 00:00:44.998440 12945 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I1105 00:00:44.998626 12945 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-aanet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "extra"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 2
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding_fc1"
  type: "InnerProduct"
  bottom: "extra"
  top: "embedding_fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_embedding_fc1"
  type: "BatchNorm"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_embedding_fc1"
  type: "Scale"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_embedding_fc1"
  type: "ReLU"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
}
layer {
  name: "embedding_fc2"
  type: "InnerProduct"
  bottom: "embedding_fc1"
  top: "embedding_fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip2"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 307200
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  bottom: "filter_ip2"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip3"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 884736
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  bottom: "filter_ip3"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "filter_ip4"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 663552
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  bottom: "filter_ip4"
  top: "conv4"
  param {
    name: "conv4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "filter_ip5"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 442368
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  bottom: "filter_ip5"
  top: "conv5"
  param {
    name: "conv5_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip6"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4718592
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "feat0"
  type: "Convolution"
  bottom: "pool5"
  bottom: "filter_ip6"
  top: "feat0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 6
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_feat0"
  type: "BatchNorm"
  bottom: "feat0"
  top: "feat0"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_feat0"
  type: "Scale"
  bottom: "feat0"
  top: "feat0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_feat0"
  type: "ReLU"
  bottom: "feat0"
  top: "feat0"
}
layer {
  name: "filter_ip7"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "feat1"
  type: "Convolution"
  bottom: "feat0"
  bottom: "filter_ip7"
  top: "feat1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
I1105 00:00:44.998716 12945 layer_factory.hpp:77] Creating layer input
I1105 00:00:44.998723 12945 net.cpp:84] Creating Layer input
I1105 00:00:44.998728 12945 net.cpp:380] input -> data
I1105 00:00:44.998733 12945 net.cpp:380] input -> extra
I1105 00:00:44.998819 12945 net.cpp:122] Setting up input
I1105 00:00:44.998824 12945 net.cpp:129] Top shape: 1 3 224 224 (150528)
I1105 00:00:44.998827 12945 net.cpp:129] Top shape: 1 2 1 1 (2)
I1105 00:00:44.998828 12945 net.cpp:137] Memory required for data: 602120
I1105 00:00:44.998831 12945 layer_factory.hpp:77] Creating layer embedding_fc1
I1105 00:00:44.998836 12945 net.cpp:84] Creating Layer embedding_fc1
I1105 00:00:44.998837 12945 net.cpp:406] embedding_fc1 <- extra
I1105 00:00:44.998842 12945 net.cpp:380] embedding_fc1 -> embedding_fc1
I1105 00:00:44.998944 12945 net.cpp:122] Setting up embedding_fc1
I1105 00:00:44.998948 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:00:44.998950 12945 net.cpp:137] Memory required for data: 603144
I1105 00:00:44.998956 12945 layer_factory.hpp:77] Creating layer bn_embedding_fc1
I1105 00:00:44.998961 12945 net.cpp:84] Creating Layer bn_embedding_fc1
I1105 00:00:44.998963 12945 net.cpp:406] bn_embedding_fc1 <- embedding_fc1
I1105 00:00:44.998966 12945 net.cpp:367] bn_embedding_fc1 -> embedding_fc1 (in-place)
I1105 00:00:44.999120 12945 net.cpp:122] Setting up bn_embedding_fc1
I1105 00:00:44.999125 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:00:44.999126 12945 net.cpp:137] Memory required for data: 604168
I1105 00:00:44.999132 12945 layer_factory.hpp:77] Creating layer scale_embedding_fc1
I1105 00:00:44.999135 12945 net.cpp:84] Creating Layer scale_embedding_fc1
I1105 00:00:44.999137 12945 net.cpp:406] scale_embedding_fc1 <- embedding_fc1
I1105 00:00:44.999141 12945 net.cpp:367] scale_embedding_fc1 -> embedding_fc1 (in-place)
I1105 00:00:44.999171 12945 layer_factory.hpp:77] Creating layer scale_embedding_fc1
I1105 00:00:44.999256 12945 net.cpp:122] Setting up scale_embedding_fc1
I1105 00:00:44.999259 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:00:44.999261 12945 net.cpp:137] Memory required for data: 605192
I1105 00:00:44.999265 12945 layer_factory.hpp:77] Creating layer relu_embedding_fc1
I1105 00:00:44.999269 12945 net.cpp:84] Creating Layer relu_embedding_fc1
I1105 00:00:44.999270 12945 net.cpp:406] relu_embedding_fc1 <- embedding_fc1
I1105 00:00:44.999279 12945 net.cpp:367] relu_embedding_fc1 -> embedding_fc1 (in-place)
I1105 00:00:44.999522 12945 net.cpp:122] Setting up relu_embedding_fc1
I1105 00:00:44.999527 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:00:44.999528 12945 net.cpp:137] Memory required for data: 606216
I1105 00:00:44.999531 12945 layer_factory.hpp:77] Creating layer embedding_fc2
I1105 00:00:44.999534 12945 net.cpp:84] Creating Layer embedding_fc2
I1105 00:00:44.999536 12945 net.cpp:406] embedding_fc2 <- embedding_fc1
I1105 00:00:44.999539 12945 net.cpp:380] embedding_fc2 -> embedding_fc2
I1105 00:00:44.999629 12945 net.cpp:122] Setting up embedding_fc2
I1105 00:00:44.999631 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:00:44.999634 12945 net.cpp:137] Memory required for data: 606220
I1105 00:00:44.999639 12945 layer_factory.hpp:77] Creating layer embedding_fc2_embedding_fc2_0_split
I1105 00:00:44.999641 12945 net.cpp:84] Creating Layer embedding_fc2_embedding_fc2_0_split
I1105 00:00:44.999644 12945 net.cpp:406] embedding_fc2_embedding_fc2_0_split <- embedding_fc2
I1105 00:00:44.999646 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_0
I1105 00:00:44.999651 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_1
I1105 00:00:44.999655 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_2
I1105 00:00:44.999660 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_3
I1105 00:00:44.999662 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_4
I1105 00:00:44.999666 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_5
I1105 00:00:44.999733 12945 net.cpp:122] Setting up embedding_fc2_embedding_fc2_0_split
I1105 00:00:44.999737 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:00:44.999738 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:00:44.999747 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:00:44.999750 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:00:44.999752 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:00:44.999754 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:00:44.999755 12945 net.cpp:137] Memory required for data: 606244
I1105 00:00:44.999758 12945 layer_factory.hpp:77] Creating layer conv1
I1105 00:00:44.999763 12945 net.cpp:84] Creating Layer conv1
I1105 00:00:44.999765 12945 net.cpp:406] conv1 <- data
I1105 00:00:44.999768 12945 net.cpp:380] conv1 -> conv1
I1105 00:00:45.000202 12945 net.cpp:122] Setting up conv1
I1105 00:00:45.000206 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:00:45.000208 12945 net.cpp:137] Memory required for data: 1725988
I1105 00:00:45.000211 12945 layer_factory.hpp:77] Creating layer bn_conv1
I1105 00:00:45.000216 12945 net.cpp:84] Creating Layer bn_conv1
I1105 00:00:45.000218 12945 net.cpp:406] bn_conv1 <- conv1
I1105 00:00:45.000221 12945 net.cpp:367] bn_conv1 -> conv1 (in-place)
I1105 00:00:45.000387 12945 net.cpp:122] Setting up bn_conv1
I1105 00:00:45.000391 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:00:45.000392 12945 net.cpp:137] Memory required for data: 2845732
I1105 00:00:45.000396 12945 layer_factory.hpp:77] Creating layer scale_conv1
I1105 00:00:45.000401 12945 net.cpp:84] Creating Layer scale_conv1
I1105 00:00:45.000402 12945 net.cpp:406] scale_conv1 <- conv1
I1105 00:00:45.000404 12945 net.cpp:367] scale_conv1 -> conv1 (in-place)
I1105 00:00:45.000434 12945 layer_factory.hpp:77] Creating layer scale_conv1
I1105 00:00:45.000532 12945 net.cpp:122] Setting up scale_conv1
I1105 00:00:45.000536 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:00:45.000537 12945 net.cpp:137] Memory required for data: 3965476
I1105 00:00:45.000541 12945 layer_factory.hpp:77] Creating layer relu1
I1105 00:00:45.000543 12945 net.cpp:84] Creating Layer relu1
I1105 00:00:45.000546 12945 net.cpp:406] relu1 <- conv1
I1105 00:00:45.000548 12945 net.cpp:367] relu1 -> conv1 (in-place)
I1105 00:00:45.000742 12945 net.cpp:122] Setting up relu1
I1105 00:00:45.000753 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:00:45.000756 12945 net.cpp:137] Memory required for data: 5085220
I1105 00:00:45.000758 12945 layer_factory.hpp:77] Creating layer pool1
I1105 00:00:45.000761 12945 net.cpp:84] Creating Layer pool1
I1105 00:00:45.000763 12945 net.cpp:406] pool1 <- conv1
I1105 00:00:45.000767 12945 net.cpp:380] pool1 -> pool1
I1105 00:00:45.000800 12945 net.cpp:122] Setting up pool1
I1105 00:00:45.000804 12945 net.cpp:129] Top shape: 1 96 27 27 (69984)
I1105 00:00:45.000805 12945 net.cpp:137] Memory required for data: 5365156
I1105 00:00:45.000808 12945 layer_factory.hpp:77] Creating layer filter_ip2
I1105 00:00:45.000811 12945 net.cpp:84] Creating Layer filter_ip2
I1105 00:00:45.000813 12945 net.cpp:406] filter_ip2 <- embedding_fc2_embedding_fc2_0_split_0
I1105 00:00:45.000816 12945 net.cpp:380] filter_ip2 -> filter_ip2
I1105 00:00:45.003939 12945 net.cpp:122] Setting up filter_ip2
I1105 00:00:45.003947 12945 net.cpp:129] Top shape: 1 307200 (307200)
I1105 00:00:45.003949 12945 net.cpp:137] Memory required for data: 6593956
I1105 00:00:45.003957 12945 layer_factory.hpp:77] Creating layer conv2
I1105 00:00:45.003962 12945 net.cpp:84] Creating Layer conv2
I1105 00:00:45.003965 12945 net.cpp:406] conv2 <- pool1
I1105 00:00:45.003968 12945 net.cpp:406] conv2 <- filter_ip2
I1105 00:00:45.003971 12945 net.cpp:380] conv2 -> conv2
I1105 00:00:45.006489 12945 net.cpp:122] Setting up conv2
I1105 00:00:45.006496 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:00:45.006498 12945 net.cpp:137] Memory required for data: 7340452
I1105 00:00:45.006502 12945 layer_factory.hpp:77] Creating layer bn_conv2
I1105 00:00:45.006507 12945 net.cpp:84] Creating Layer bn_conv2
I1105 00:00:45.006510 12945 net.cpp:406] bn_conv2 <- conv2
I1105 00:00:45.006512 12945 net.cpp:367] bn_conv2 -> conv2 (in-place)
I1105 00:00:45.006678 12945 net.cpp:122] Setting up bn_conv2
I1105 00:00:45.006682 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:00:45.006685 12945 net.cpp:137] Memory required for data: 8086948
I1105 00:00:45.006688 12945 layer_factory.hpp:77] Creating layer scale_conv2
I1105 00:00:45.006692 12945 net.cpp:84] Creating Layer scale_conv2
I1105 00:00:45.006695 12945 net.cpp:406] scale_conv2 <- conv2
I1105 00:00:45.006697 12945 net.cpp:367] scale_conv2 -> conv2 (in-place)
I1105 00:00:45.006727 12945 layer_factory.hpp:77] Creating layer scale_conv2
I1105 00:00:45.006821 12945 net.cpp:122] Setting up scale_conv2
I1105 00:00:45.006825 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:00:45.006827 12945 net.cpp:137] Memory required for data: 8833444
I1105 00:00:45.006850 12945 layer_factory.hpp:77] Creating layer relu2
I1105 00:00:45.006856 12945 net.cpp:84] Creating Layer relu2
I1105 00:00:45.006858 12945 net.cpp:406] relu2 <- conv2
I1105 00:00:45.006861 12945 net.cpp:367] relu2 -> conv2 (in-place)
I1105 00:00:45.007084 12945 net.cpp:122] Setting up relu2
I1105 00:00:45.007089 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:00:45.007091 12945 net.cpp:137] Memory required for data: 9579940
I1105 00:00:45.007093 12945 layer_factory.hpp:77] Creating layer pool2
I1105 00:00:45.007097 12945 net.cpp:84] Creating Layer pool2
I1105 00:00:45.007098 12945 net.cpp:406] pool2 <- conv2
I1105 00:00:45.007102 12945 net.cpp:380] pool2 -> pool2
I1105 00:00:45.007136 12945 net.cpp:122] Setting up pool2
I1105 00:00:45.007139 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:00:45.007141 12945 net.cpp:137] Memory required for data: 9752996
I1105 00:00:45.007143 12945 layer_factory.hpp:77] Creating layer filter_ip3
I1105 00:00:45.007148 12945 net.cpp:84] Creating Layer filter_ip3
I1105 00:00:45.007149 12945 net.cpp:406] filter_ip3 <- embedding_fc2_embedding_fc2_0_split_1
I1105 00:00:45.007153 12945 net.cpp:380] filter_ip3 -> filter_ip3
I1105 00:00:45.014325 12945 net.cpp:122] Setting up filter_ip3
I1105 00:00:45.014338 12945 net.cpp:129] Top shape: 1 884736 (884736)
I1105 00:00:45.014340 12945 net.cpp:137] Memory required for data: 13291940
I1105 00:00:45.014360 12945 layer_factory.hpp:77] Creating layer conv3
I1105 00:00:45.014370 12945 net.cpp:84] Creating Layer conv3
I1105 00:00:45.014372 12945 net.cpp:406] conv3 <- pool2
I1105 00:00:45.014376 12945 net.cpp:406] conv3 <- filter_ip3
I1105 00:00:45.014379 12945 net.cpp:380] conv3 -> conv3
I1105 00:00:45.020695 12945 net.cpp:122] Setting up conv3
I1105 00:00:45.020705 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:00:45.020707 12945 net.cpp:137] Memory required for data: 13551524
I1105 00:00:45.020712 12945 layer_factory.hpp:77] Creating layer bn_conv3
I1105 00:00:45.020718 12945 net.cpp:84] Creating Layer bn_conv3
I1105 00:00:45.020720 12945 net.cpp:406] bn_conv3 <- conv3
I1105 00:00:45.020725 12945 net.cpp:367] bn_conv3 -> conv3 (in-place)
I1105 00:00:45.020892 12945 net.cpp:122] Setting up bn_conv3
I1105 00:00:45.020896 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:00:45.020898 12945 net.cpp:137] Memory required for data: 13811108
I1105 00:00:45.020903 12945 layer_factory.hpp:77] Creating layer scale_conv3
I1105 00:00:45.020907 12945 net.cpp:84] Creating Layer scale_conv3
I1105 00:00:45.020910 12945 net.cpp:406] scale_conv3 <- conv3
I1105 00:00:45.020912 12945 net.cpp:367] scale_conv3 -> conv3 (in-place)
I1105 00:00:45.020941 12945 layer_factory.hpp:77] Creating layer scale_conv3
I1105 00:00:45.021037 12945 net.cpp:122] Setting up scale_conv3
I1105 00:00:45.021041 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:00:45.021042 12945 net.cpp:137] Memory required for data: 14070692
I1105 00:00:45.021049 12945 layer_factory.hpp:77] Creating layer relu3
I1105 00:00:45.021052 12945 net.cpp:84] Creating Layer relu3
I1105 00:00:45.021055 12945 net.cpp:406] relu3 <- conv3
I1105 00:00:45.021057 12945 net.cpp:367] relu3 -> conv3 (in-place)
I1105 00:00:45.021358 12945 net.cpp:122] Setting up relu3
I1105 00:00:45.021363 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:00:45.021365 12945 net.cpp:137] Memory required for data: 14330276
I1105 00:00:45.021368 12945 layer_factory.hpp:77] Creating layer filter_ip4
I1105 00:00:45.021371 12945 net.cpp:84] Creating Layer filter_ip4
I1105 00:00:45.021373 12945 net.cpp:406] filter_ip4 <- embedding_fc2_embedding_fc2_0_split_2
I1105 00:00:45.021378 12945 net.cpp:380] filter_ip4 -> filter_ip4
I1105 00:00:45.026783 12945 net.cpp:122] Setting up filter_ip4
I1105 00:00:45.026794 12945 net.cpp:129] Top shape: 1 663552 (663552)
I1105 00:00:45.026796 12945 net.cpp:137] Memory required for data: 16984484
I1105 00:00:45.026801 12945 layer_factory.hpp:77] Creating layer conv4
I1105 00:00:45.026809 12945 net.cpp:84] Creating Layer conv4
I1105 00:00:45.026813 12945 net.cpp:406] conv4 <- conv3
I1105 00:00:45.026815 12945 net.cpp:406] conv4 <- filter_ip4
I1105 00:00:45.026819 12945 net.cpp:380] conv4 -> conv4
I1105 00:00:45.031666 12945 net.cpp:122] Setting up conv4
I1105 00:00:45.031674 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:00:45.031677 12945 net.cpp:137] Memory required for data: 17244068
I1105 00:00:45.031682 12945 layer_factory.hpp:77] Creating layer bn_conv4
I1105 00:00:45.031687 12945 net.cpp:84] Creating Layer bn_conv4
I1105 00:00:45.031689 12945 net.cpp:406] bn_conv4 <- conv4
I1105 00:00:45.031692 12945 net.cpp:367] bn_conv4 -> conv4 (in-place)
I1105 00:00:45.031869 12945 net.cpp:122] Setting up bn_conv4
I1105 00:00:45.031873 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:00:45.031875 12945 net.cpp:137] Memory required for data: 17503652
I1105 00:00:45.031879 12945 layer_factory.hpp:77] Creating layer scale_conv4
I1105 00:00:45.031884 12945 net.cpp:84] Creating Layer scale_conv4
I1105 00:00:45.031886 12945 net.cpp:406] scale_conv4 <- conv4
I1105 00:00:45.031889 12945 net.cpp:367] scale_conv4 -> conv4 (in-place)
I1105 00:00:45.031919 12945 layer_factory.hpp:77] Creating layer scale_conv4
I1105 00:00:45.032014 12945 net.cpp:122] Setting up scale_conv4
I1105 00:00:45.032017 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:00:45.032019 12945 net.cpp:137] Memory required for data: 17763236
I1105 00:00:45.032038 12945 layer_factory.hpp:77] Creating layer relu4
I1105 00:00:45.032042 12945 net.cpp:84] Creating Layer relu4
I1105 00:00:45.032044 12945 net.cpp:406] relu4 <- conv4
I1105 00:00:45.032047 12945 net.cpp:367] relu4 -> conv4 (in-place)
I1105 00:00:45.032362 12945 net.cpp:122] Setting up relu4
I1105 00:00:45.032368 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:00:45.032369 12945 net.cpp:137] Memory required for data: 18022820
I1105 00:00:45.032371 12945 layer_factory.hpp:77] Creating layer filter_ip5
I1105 00:00:45.032377 12945 net.cpp:84] Creating Layer filter_ip5
I1105 00:00:45.032378 12945 net.cpp:406] filter_ip5 <- embedding_fc2_embedding_fc2_0_split_3
I1105 00:00:45.032382 12945 net.cpp:380] filter_ip5 -> filter_ip5
I1105 00:00:45.036180 12945 net.cpp:122] Setting up filter_ip5
I1105 00:00:45.036190 12945 net.cpp:129] Top shape: 1 442368 (442368)
I1105 00:00:45.036191 12945 net.cpp:137] Memory required for data: 19792292
I1105 00:00:45.036196 12945 layer_factory.hpp:77] Creating layer conv5
I1105 00:00:45.036204 12945 net.cpp:84] Creating Layer conv5
I1105 00:00:45.036206 12945 net.cpp:406] conv5 <- conv4
I1105 00:00:45.036209 12945 net.cpp:406] conv5 <- filter_ip5
I1105 00:00:45.036212 12945 net.cpp:380] conv5 -> conv5
I1105 00:00:45.039546 12945 net.cpp:122] Setting up conv5
I1105 00:00:45.039553 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:00:45.039556 12945 net.cpp:137] Memory required for data: 19965348
I1105 00:00:45.039561 12945 layer_factory.hpp:77] Creating layer bn_conv5
I1105 00:00:45.039564 12945 net.cpp:84] Creating Layer bn_conv5
I1105 00:00:45.039566 12945 net.cpp:406] bn_conv5 <- conv5
I1105 00:00:45.039570 12945 net.cpp:367] bn_conv5 -> conv5 (in-place)
I1105 00:00:45.039746 12945 net.cpp:122] Setting up bn_conv5
I1105 00:00:45.039749 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:00:45.039752 12945 net.cpp:137] Memory required for data: 20138404
I1105 00:00:45.039757 12945 layer_factory.hpp:77] Creating layer scale_conv5
I1105 00:00:45.039760 12945 net.cpp:84] Creating Layer scale_conv5
I1105 00:00:45.039762 12945 net.cpp:406] scale_conv5 <- conv5
I1105 00:00:45.039764 12945 net.cpp:367] scale_conv5 -> conv5 (in-place)
I1105 00:00:45.039798 12945 layer_factory.hpp:77] Creating layer scale_conv5
I1105 00:00:45.039891 12945 net.cpp:122] Setting up scale_conv5
I1105 00:00:45.039893 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:00:45.039896 12945 net.cpp:137] Memory required for data: 20311460
I1105 00:00:45.039899 12945 layer_factory.hpp:77] Creating layer relu5
I1105 00:00:45.039904 12945 net.cpp:84] Creating Layer relu5
I1105 00:00:45.039906 12945 net.cpp:406] relu5 <- conv5
I1105 00:00:45.039909 12945 net.cpp:367] relu5 -> conv5 (in-place)
I1105 00:00:45.040474 12945 net.cpp:122] Setting up relu5
I1105 00:00:45.040480 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:00:45.040482 12945 net.cpp:137] Memory required for data: 20484516
I1105 00:00:45.040484 12945 layer_factory.hpp:77] Creating layer pool5
I1105 00:00:45.040489 12945 net.cpp:84] Creating Layer pool5
I1105 00:00:45.040491 12945 net.cpp:406] pool5 <- conv5
I1105 00:00:45.040494 12945 net.cpp:380] pool5 -> pool5
I1105 00:00:45.040532 12945 net.cpp:122] Setting up pool5
I1105 00:00:45.040536 12945 net.cpp:129] Top shape: 1 256 6 6 (9216)
I1105 00:00:45.040539 12945 net.cpp:137] Memory required for data: 20521380
I1105 00:00:45.040540 12945 layer_factory.hpp:77] Creating layer filter_ip6
I1105 00:00:45.040544 12945 net.cpp:84] Creating Layer filter_ip6
I1105 00:00:45.040546 12945 net.cpp:406] filter_ip6 <- embedding_fc2_embedding_fc2_0_split_4
I1105 00:00:45.040550 12945 net.cpp:380] filter_ip6 -> filter_ip6
I1105 00:00:45.077579 12945 net.cpp:122] Setting up filter_ip6
I1105 00:00:45.077596 12945 net.cpp:129] Top shape: 1 4718592 (4718592)
I1105 00:00:45.077598 12945 net.cpp:137] Memory required for data: 39395748
I1105 00:00:45.077605 12945 layer_factory.hpp:77] Creating layer feat0
I1105 00:00:45.077615 12945 net.cpp:84] Creating Layer feat0
I1105 00:00:45.077618 12945 net.cpp:406] feat0 <- pool5
I1105 00:00:45.077644 12945 net.cpp:406] feat0 <- filter_ip6
I1105 00:00:45.077648 12945 net.cpp:380] feat0 -> feat0
I1105 00:00:45.109594 12945 net.cpp:122] Setting up feat0
I1105 00:00:45.109608 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:00:45.109611 12945 net.cpp:137] Memory required for data: 39397796
I1105 00:00:45.109617 12945 layer_factory.hpp:77] Creating layer bn_feat0
I1105 00:00:45.109623 12945 net.cpp:84] Creating Layer bn_feat0
I1105 00:00:45.109627 12945 net.cpp:406] bn_feat0 <- feat0
I1105 00:00:45.109630 12945 net.cpp:367] bn_feat0 -> feat0 (in-place)
I1105 00:00:45.109805 12945 net.cpp:122] Setting up bn_feat0
I1105 00:00:45.109809 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:00:45.109812 12945 net.cpp:137] Memory required for data: 39399844
I1105 00:00:45.109817 12945 layer_factory.hpp:77] Creating layer scale_feat0
I1105 00:00:45.109820 12945 net.cpp:84] Creating Layer scale_feat0
I1105 00:00:45.109822 12945 net.cpp:406] scale_feat0 <- feat0
I1105 00:00:45.109824 12945 net.cpp:367] scale_feat0 -> feat0 (in-place)
I1105 00:00:45.109855 12945 layer_factory.hpp:77] Creating layer scale_feat0
I1105 00:00:45.109953 12945 net.cpp:122] Setting up scale_feat0
I1105 00:00:45.109957 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:00:45.109958 12945 net.cpp:137] Memory required for data: 39401892
I1105 00:00:45.109962 12945 layer_factory.hpp:77] Creating layer relu_feat0
I1105 00:00:45.109966 12945 net.cpp:84] Creating Layer relu_feat0
I1105 00:00:45.109967 12945 net.cpp:406] relu_feat0 <- feat0
I1105 00:00:45.109971 12945 net.cpp:367] relu_feat0 -> feat0 (in-place)
I1105 00:00:45.110306 12945 net.cpp:122] Setting up relu_feat0
I1105 00:00:45.110311 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:00:45.110312 12945 net.cpp:137] Memory required for data: 39403940
I1105 00:00:45.110314 12945 layer_factory.hpp:77] Creating layer filter_ip7
I1105 00:00:45.110319 12945 net.cpp:84] Creating Layer filter_ip7
I1105 00:00:45.110321 12945 net.cpp:406] filter_ip7 <- embedding_fc2_embedding_fc2_0_split_5
I1105 00:00:45.110325 12945 net.cpp:380] filter_ip7 -> filter_ip7
I1105 00:00:45.110424 12945 net.cpp:122] Setting up filter_ip7
I1105 00:00:45.110427 12945 net.cpp:129] Top shape: 1 512 (512)
I1105 00:00:45.110430 12945 net.cpp:137] Memory required for data: 39405988
I1105 00:00:45.110433 12945 layer_factory.hpp:77] Creating layer feat1
I1105 00:00:45.110438 12945 net.cpp:84] Creating Layer feat1
I1105 00:00:45.110441 12945 net.cpp:406] feat1 <- feat0
I1105 00:00:45.110443 12945 net.cpp:406] feat1 <- filter_ip7
I1105 00:00:45.110446 12945 net.cpp:380] feat1 -> feat1
I1105 00:00:45.110674 12945 net.cpp:122] Setting up feat1
I1105 00:00:45.110679 12945 net.cpp:129] Top shape: 1 1 1 1 (1)
I1105 00:00:45.110680 12945 net.cpp:137] Memory required for data: 39405992
I1105 00:00:45.110688 12945 net.cpp:200] feat1 does not need backward computation.
I1105 00:00:45.110692 12945 net.cpp:200] filter_ip7 does not need backward computation.
I1105 00:00:45.110693 12945 net.cpp:200] relu_feat0 does not need backward computation.
I1105 00:00:45.110695 12945 net.cpp:200] scale_feat0 does not need backward computation.
I1105 00:00:45.110697 12945 net.cpp:200] bn_feat0 does not need backward computation.
I1105 00:00:45.110698 12945 net.cpp:200] feat0 does not need backward computation.
I1105 00:00:45.110702 12945 net.cpp:200] filter_ip6 does not need backward computation.
I1105 00:00:45.110703 12945 net.cpp:200] pool5 does not need backward computation.
I1105 00:00:45.110705 12945 net.cpp:200] relu5 does not need backward computation.
I1105 00:00:45.110707 12945 net.cpp:200] scale_conv5 does not need backward computation.
I1105 00:00:45.110709 12945 net.cpp:200] bn_conv5 does not need backward computation.
I1105 00:00:45.110711 12945 net.cpp:200] conv5 does not need backward computation.
I1105 00:00:45.110713 12945 net.cpp:200] filter_ip5 does not need backward computation.
I1105 00:00:45.110715 12945 net.cpp:200] relu4 does not need backward computation.
I1105 00:00:45.110718 12945 net.cpp:200] scale_conv4 does not need backward computation.
I1105 00:00:45.110735 12945 net.cpp:200] bn_conv4 does not need backward computation.
I1105 00:00:45.110738 12945 net.cpp:200] conv4 does not need backward computation.
I1105 00:00:45.110740 12945 net.cpp:200] filter_ip4 does not need backward computation.
I1105 00:00:45.110743 12945 net.cpp:200] relu3 does not need backward computation.
I1105 00:00:45.110744 12945 net.cpp:200] scale_conv3 does not need backward computation.
I1105 00:00:45.110746 12945 net.cpp:200] bn_conv3 does not need backward computation.
I1105 00:00:45.110749 12945 net.cpp:200] conv3 does not need backward computation.
I1105 00:00:45.110750 12945 net.cpp:200] filter_ip3 does not need backward computation.
I1105 00:00:45.110752 12945 net.cpp:200] pool2 does not need backward computation.
I1105 00:00:45.110754 12945 net.cpp:200] relu2 does not need backward computation.
I1105 00:00:45.110756 12945 net.cpp:200] scale_conv2 does not need backward computation.
I1105 00:00:45.110759 12945 net.cpp:200] bn_conv2 does not need backward computation.
I1105 00:00:45.110760 12945 net.cpp:200] conv2 does not need backward computation.
I1105 00:00:45.110762 12945 net.cpp:200] filter_ip2 does not need backward computation.
I1105 00:00:45.110764 12945 net.cpp:200] pool1 does not need backward computation.
I1105 00:00:45.110766 12945 net.cpp:200] relu1 does not need backward computation.
I1105 00:00:45.110769 12945 net.cpp:200] scale_conv1 does not need backward computation.
I1105 00:00:45.110770 12945 net.cpp:200] bn_conv1 does not need backward computation.
I1105 00:00:45.110771 12945 net.cpp:200] conv1 does not need backward computation.
I1105 00:00:45.110774 12945 net.cpp:200] embedding_fc2_embedding_fc2_0_split does not need backward computation.
I1105 00:00:45.110776 12945 net.cpp:200] embedding_fc2 does not need backward computation.
I1105 00:00:45.110780 12945 net.cpp:200] relu_embedding_fc1 does not need backward computation.
I1105 00:00:45.110781 12945 net.cpp:200] scale_embedding_fc1 does not need backward computation.
I1105 00:00:45.110783 12945 net.cpp:200] bn_embedding_fc1 does not need backward computation.
I1105 00:00:45.110785 12945 net.cpp:200] embedding_fc1 does not need backward computation.
I1105 00:00:45.110787 12945 net.cpp:200] input does not need backward computation.
I1105 00:00:45.110790 12945 net.cpp:242] This network produces output feat1
I1105 00:00:45.110803 12945 net.cpp:255] Network initialization done.
I1105 00:00:45.142031 12945 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./snapshot/1/alex-dy_iter_10000.caffemodel
I1105 00:00:45.142048 12945 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1105 00:00:45.142050 12945 net.cpp:744] Ignoring source layer data
I1105 00:00:45.200613 12945 net.cpp:744] Ignoring source layer eucli_loss
I1105 00:01:01.098670 12945 solver.cpp:397]     Test net output #0: accuracy = 0.871352
I1105 00:01:01.098747 12945 solver.cpp:397]     Test net output #1: mae = 0.298724
I1105 00:01:01.098752 12945 solver.cpp:397]     Test net output #2: rmse = 0.380769
I1105 00:01:01.240815 12945 solver.cpp:218] Iteration 10000 (3.28527 iter/s, 30.4389s/100 iters), loss = 0.0330125
I1105 00:01:01.240839 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0330125 (* 1 = 0.0330125 loss)
I1105 00:01:01.240844 12945 sgd_solver.cpp:114] Iteration 10000, lr = 0.00555556
I1105 00:01:14.822821 12945 solver.cpp:218] Iteration 10100 (7.36299 iter/s, 13.5814s/100 iters), loss = 0.0259429
I1105 00:01:14.822849 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0259429 (* 1 = 0.0259429 loss)
I1105 00:01:14.822854 12945 sgd_solver.cpp:114] Iteration 10100, lr = 0.0055
I1105 00:01:28.394933 12945 solver.cpp:218] Iteration 10200 (7.36836 iter/s, 13.5715s/100 iters), loss = 0.0114762
I1105 00:01:28.394958 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0114762 (* 1 = 0.0114762 loss)
I1105 00:01:28.394963 12945 sgd_solver.cpp:114] Iteration 10200, lr = 0.00544444
I1105 00:01:41.959558 12945 solver.cpp:218] Iteration 10300 (7.37242 iter/s, 13.5641s/100 iters), loss = 0.0300893
I1105 00:01:41.959669 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0300893 (* 1 = 0.0300893 loss)
I1105 00:01:41.959677 12945 sgd_solver.cpp:114] Iteration 10300, lr = 0.00538889
I1105 00:01:55.559334 12945 solver.cpp:218] Iteration 10400 (7.35341 iter/s, 13.5991s/100 iters), loss = 0.0444389
I1105 00:01:55.559357 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0444389 (* 1 = 0.0444389 loss)
I1105 00:01:55.559362 12945 sgd_solver.cpp:114] Iteration 10400, lr = 0.00533333
I1105 00:02:09.221359 12945 solver.cpp:218] Iteration 10500 (7.31986 iter/s, 13.6615s/100 iters), loss = 0.0357665
I1105 00:02:09.221385 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0357665 (* 1 = 0.0357665 loss)
I1105 00:02:09.221390 12945 sgd_solver.cpp:114] Iteration 10500, lr = 0.00527778
I1105 00:02:22.871361 12945 solver.cpp:218] Iteration 10600 (7.32631 iter/s, 13.6494s/100 iters), loss = 0.0337818
I1105 00:02:22.871402 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0337817 (* 1 = 0.0337817 loss)
I1105 00:02:22.871407 12945 sgd_solver.cpp:114] Iteration 10600, lr = 0.00522222
I1105 00:02:36.523268 12945 solver.cpp:218] Iteration 10700 (7.3253 iter/s, 13.6513s/100 iters), loss = 0.019202
I1105 00:02:36.523293 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.019202 (* 1 = 0.019202 loss)
I1105 00:02:36.523298 12945 sgd_solver.cpp:114] Iteration 10700, lr = 0.00516667
I1105 00:02:50.177297 12945 solver.cpp:218] Iteration 10800 (7.32415 iter/s, 13.6535s/100 iters), loss = 0.0332697
I1105 00:02:50.177320 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0332696 (* 1 = 0.0332696 loss)
I1105 00:02:50.177325 12945 sgd_solver.cpp:114] Iteration 10800, lr = 0.00511111
I1105 00:03:03.840294 12945 solver.cpp:218] Iteration 10900 (7.31934 iter/s, 13.6624s/100 iters), loss = 0.0199549
I1105 00:03:03.840426 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0199548 (* 1 = 0.0199548 loss)
I1105 00:03:03.840433 12945 sgd_solver.cpp:114] Iteration 10900, lr = 0.00505556
I1105 00:03:17.484129 12945 solver.cpp:218] Iteration 11000 (7.32968 iter/s, 13.6432s/100 iters), loss = 0.0185834
I1105 00:03:17.484153 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0185834 (* 1 = 0.0185834 loss)
I1105 00:03:17.484159 12945 sgd_solver.cpp:114] Iteration 11000, lr = 0.005
I1105 00:03:31.142283 12945 solver.cpp:218] Iteration 11100 (7.32194 iter/s, 13.6576s/100 iters), loss = 0.0463033
I1105 00:03:31.142307 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0463032 (* 1 = 0.0463032 loss)
I1105 00:03:31.142313 12945 sgd_solver.cpp:114] Iteration 11100, lr = 0.00494444
I1105 00:03:44.790388 12945 solver.cpp:218] Iteration 11200 (7.32733 iter/s, 13.6475s/100 iters), loss = 0.0171275
I1105 00:03:44.790496 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0171274 (* 1 = 0.0171274 loss)
I1105 00:03:44.790503 12945 sgd_solver.cpp:114] Iteration 11200, lr = 0.00488889
I1105 00:03:58.448794 12945 solver.cpp:218] Iteration 11300 (7.32185 iter/s, 13.6578s/100 iters), loss = 0.0253536
I1105 00:03:58.448818 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0253536 (* 1 = 0.0253536 loss)
I1105 00:03:58.448824 12945 sgd_solver.cpp:114] Iteration 11300, lr = 0.00483333
I1105 00:04:12.096724 12945 solver.cpp:218] Iteration 11400 (7.32742 iter/s, 13.6474s/100 iters), loss = 0.0441057
I1105 00:04:12.096747 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0441056 (* 1 = 0.0441056 loss)
I1105 00:04:12.096753 12945 sgd_solver.cpp:114] Iteration 11400, lr = 0.00477778
I1105 00:04:25.754078 12945 solver.cpp:218] Iteration 11500 (7.32237 iter/s, 13.6568s/100 iters), loss = 0.0215615
I1105 00:04:25.754186 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0215615 (* 1 = 0.0215615 loss)
I1105 00:04:25.754194 12945 sgd_solver.cpp:114] Iteration 11500, lr = 0.00472222
I1105 00:04:39.411872 12945 solver.cpp:218] Iteration 11600 (7.32218 iter/s, 13.6571s/100 iters), loss = 0.021278
I1105 00:04:39.411897 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.021278 (* 1 = 0.021278 loss)
I1105 00:04:39.411903 12945 sgd_solver.cpp:114] Iteration 11600, lr = 0.00466667
I1105 00:04:53.064069 12945 solver.cpp:218] Iteration 11700 (7.32514 iter/s, 13.6516s/100 iters), loss = 0.0244821
I1105 00:04:53.064092 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0244821 (* 1 = 0.0244821 loss)
I1105 00:04:53.064098 12945 sgd_solver.cpp:114] Iteration 11700, lr = 0.00461111
I1105 00:05:06.716045 12945 solver.cpp:218] Iteration 11800 (7.32525 iter/s, 13.6514s/100 iters), loss = 0.0246297
I1105 00:05:06.716086 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0246297 (* 1 = 0.0246297 loss)
I1105 00:05:06.716091 12945 sgd_solver.cpp:114] Iteration 11800, lr = 0.00455556
I1105 00:05:20.372045 12945 solver.cpp:218] Iteration 11900 (7.3231 iter/s, 13.6554s/100 iters), loss = 0.0369079
I1105 00:05:20.372068 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0369078 (* 1 = 0.0369078 loss)
I1105 00:05:20.372074 12945 sgd_solver.cpp:114] Iteration 11900, lr = 0.0045
I1105 00:05:34.023692 12945 solver.cpp:218] Iteration 12000 (7.32543 iter/s, 13.6511s/100 iters), loss = 0.0203996
I1105 00:05:34.023716 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0203996 (* 1 = 0.0203996 loss)
I1105 00:05:34.023722 12945 sgd_solver.cpp:114] Iteration 12000, lr = 0.00444444
I1105 00:05:47.671008 12945 solver.cpp:218] Iteration 12100 (7.32775 iter/s, 13.6467s/100 iters), loss = 0.0247419
I1105 00:05:47.671113 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0247418 (* 1 = 0.0247418 loss)
I1105 00:05:47.671121 12945 sgd_solver.cpp:114] Iteration 12100, lr = 0.00438889
I1105 00:06:01.328379 12945 solver.cpp:218] Iteration 12200 (7.3224 iter/s, 13.6567s/100 iters), loss = 0.0208121
I1105 00:06:01.328404 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0208121 (* 1 = 0.0208121 loss)
I1105 00:06:01.328409 12945 sgd_solver.cpp:114] Iteration 12200, lr = 0.00433333
I1105 00:06:14.981724 12945 solver.cpp:218] Iteration 12300 (7.32452 iter/s, 13.6528s/100 iters), loss = 0.0475871
I1105 00:06:14.981750 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.047587 (* 1 = 0.047587 loss)
I1105 00:06:14.981755 12945 sgd_solver.cpp:114] Iteration 12300, lr = 0.00427778
I1105 00:06:28.637748 12945 solver.cpp:218] Iteration 12400 (7.32308 iter/s, 13.6555s/100 iters), loss = 0.01893
I1105 00:06:28.637814 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.01893 (* 1 = 0.01893 loss)
I1105 00:06:28.637818 12945 sgd_solver.cpp:114] Iteration 12400, lr = 0.00422222
I1105 00:06:42.290578 12945 solver.cpp:218] Iteration 12500 (7.32482 iter/s, 13.6522s/100 iters), loss = 0.0338169
I1105 00:06:42.290603 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0338169 (* 1 = 0.0338169 loss)
I1105 00:06:42.290609 12945 sgd_solver.cpp:114] Iteration 12500, lr = 0.00416667
I1105 00:06:55.942065 12945 solver.cpp:218] Iteration 12600 (7.32552 iter/s, 13.6509s/100 iters), loss = 0.0232795
I1105 00:06:55.942090 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0232795 (* 1 = 0.0232795 loss)
I1105 00:06:55.942095 12945 sgd_solver.cpp:114] Iteration 12600, lr = 0.00411111
I1105 00:07:09.604437 12945 solver.cpp:218] Iteration 12700 (7.31968 iter/s, 13.6618s/100 iters), loss = 0.0165482
I1105 00:07:09.604540 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0165482 (* 1 = 0.0165482 loss)
I1105 00:07:09.604547 12945 sgd_solver.cpp:114] Iteration 12700, lr = 0.00405556
I1105 00:07:23.251889 12945 solver.cpp:218] Iteration 12800 (7.32772 iter/s, 13.6468s/100 iters), loss = 0.018305
I1105 00:07:23.251914 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.018305 (* 1 = 0.018305 loss)
I1105 00:07:23.251920 12945 sgd_solver.cpp:114] Iteration 12800, lr = 0.004
I1105 00:07:36.906666 12945 solver.cpp:218] Iteration 12900 (7.32375 iter/s, 13.6542s/100 iters), loss = 0.0274732
I1105 00:07:36.906689 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0274732 (* 1 = 0.0274732 loss)
I1105 00:07:36.906694 12945 sgd_solver.cpp:114] Iteration 12900, lr = 0.00394444
I1105 00:07:50.561376 12945 solver.cpp:218] Iteration 13000 (7.32379 iter/s, 13.6541s/100 iters), loss = 0.0316242
I1105 00:07:50.561453 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0316242 (* 1 = 0.0316242 loss)
I1105 00:07:50.561460 12945 sgd_solver.cpp:114] Iteration 13000, lr = 0.00388889
I1105 00:08:04.220080 12945 solver.cpp:218] Iteration 13100 (7.32167 iter/s, 13.6581s/100 iters), loss = 0.018717
I1105 00:08:04.220104 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.018717 (* 1 = 0.018717 loss)
I1105 00:08:04.220109 12945 sgd_solver.cpp:114] Iteration 13100, lr = 0.00383333
I1105 00:08:17.867944 12945 solver.cpp:218] Iteration 13200 (7.32746 iter/s, 13.6473s/100 iters), loss = 0.0348407
I1105 00:08:17.867966 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0348407 (* 1 = 0.0348407 loss)
I1105 00:08:17.867972 12945 sgd_solver.cpp:114] Iteration 13200, lr = 0.00377778
I1105 00:08:31.518239 12945 solver.cpp:218] Iteration 13300 (7.32616 iter/s, 13.6497s/100 iters), loss = 0.0287542
I1105 00:08:31.518278 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0287542 (* 1 = 0.0287542 loss)
I1105 00:08:31.518285 12945 sgd_solver.cpp:114] Iteration 13300, lr = 0.00372222
I1105 00:08:45.174713 12945 solver.cpp:218] Iteration 13400 (7.32285 iter/s, 13.6559s/100 iters), loss = 0.0228974
I1105 00:08:45.174738 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0228974 (* 1 = 0.0228974 loss)
I1105 00:08:45.174744 12945 sgd_solver.cpp:114] Iteration 13400, lr = 0.00366667
I1105 00:08:58.829800 12945 solver.cpp:218] Iteration 13500 (7.32359 iter/s, 13.6545s/100 iters), loss = 0.0145443
I1105 00:08:58.829824 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0145443 (* 1 = 0.0145443 loss)
I1105 00:08:58.829829 12945 sgd_solver.cpp:114] Iteration 13500, lr = 0.00361111
I1105 00:09:12.485143 12945 solver.cpp:218] Iteration 13600 (7.32345 iter/s, 13.6548s/100 iters), loss = 0.0155467
I1105 00:09:12.485206 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0155467 (* 1 = 0.0155467 loss)
I1105 00:09:12.485213 12945 sgd_solver.cpp:114] Iteration 13600, lr = 0.00355556
I1105 00:09:26.138396 12945 solver.cpp:218] Iteration 13700 (7.32459 iter/s, 13.6526s/100 iters), loss = 0.0166669
I1105 00:09:26.138419 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0166668 (* 1 = 0.0166668 loss)
I1105 00:09:26.138424 12945 sgd_solver.cpp:114] Iteration 13700, lr = 0.0035
I1105 00:09:39.793396 12945 solver.cpp:218] Iteration 13800 (7.32363 iter/s, 13.6544s/100 iters), loss = 0.00918341
I1105 00:09:39.793421 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.00918338 (* 1 = 0.00918338 loss)
I1105 00:09:39.793427 12945 sgd_solver.cpp:114] Iteration 13800, lr = 0.00344444
I1105 00:09:53.442963 12945 solver.cpp:218] Iteration 13900 (7.32655 iter/s, 13.649s/100 iters), loss = 0.0252516
I1105 00:09:53.443053 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0252515 (* 1 = 0.0252515 loss)
I1105 00:09:53.443059 12945 sgd_solver.cpp:114] Iteration 13900, lr = 0.00338889
I1105 00:10:07.095511 12945 solver.cpp:218] Iteration 14000 (7.32499 iter/s, 13.6519s/100 iters), loss = 0.0292771
I1105 00:10:07.095536 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0292771 (* 1 = 0.0292771 loss)
I1105 00:10:07.095542 12945 sgd_solver.cpp:114] Iteration 14000, lr = 0.00333333
I1105 00:10:20.752293 12945 solver.cpp:218] Iteration 14100 (7.32268 iter/s, 13.6562s/100 iters), loss = 0.0170125
I1105 00:10:20.752317 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0170124 (* 1 = 0.0170124 loss)
I1105 00:10:20.752322 12945 sgd_solver.cpp:114] Iteration 14100, lr = 0.00327778
I1105 00:10:34.404280 12945 solver.cpp:218] Iteration 14200 (7.32525 iter/s, 13.6514s/100 iters), loss = 0.0383766
I1105 00:10:34.404321 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0383766 (* 1 = 0.0383766 loss)
I1105 00:10:34.404326 12945 sgd_solver.cpp:114] Iteration 14200, lr = 0.00322222
I1105 00:10:48.064324 12945 solver.cpp:218] Iteration 14300 (7.32094 iter/s, 13.6594s/100 iters), loss = 0.0119484
I1105 00:10:48.064348 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0119484 (* 1 = 0.0119484 loss)
I1105 00:10:48.064354 12945 sgd_solver.cpp:114] Iteration 14300, lr = 0.00316667
I1105 00:11:01.713833 12945 solver.cpp:218] Iteration 14400 (7.32658 iter/s, 13.6489s/100 iters), loss = 0.0147154
I1105 00:11:01.713857 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0147154 (* 1 = 0.0147154 loss)
I1105 00:11:01.713862 12945 sgd_solver.cpp:114] Iteration 14400, lr = 0.00311111
I1105 00:11:15.367792 12945 solver.cpp:218] Iteration 14500 (7.32419 iter/s, 13.6534s/100 iters), loss = 0.0183149
I1105 00:11:15.367882 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0183149 (* 1 = 0.0183149 loss)
I1105 00:11:15.367887 12945 sgd_solver.cpp:114] Iteration 14500, lr = 0.00305556
I1105 00:11:29.023329 12945 solver.cpp:218] Iteration 14600 (7.32338 iter/s, 13.6549s/100 iters), loss = 0.0190569
I1105 00:11:29.023355 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0190569 (* 1 = 0.0190569 loss)
I1105 00:11:29.023360 12945 sgd_solver.cpp:114] Iteration 14600, lr = 0.003
I1105 00:11:42.676430 12945 solver.cpp:218] Iteration 14700 (7.32465 iter/s, 13.6525s/100 iters), loss = 0.0245469
I1105 00:11:42.676455 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0245468 (* 1 = 0.0245468 loss)
I1105 00:11:42.676460 12945 sgd_solver.cpp:114] Iteration 14700, lr = 0.00294444
I1105 00:11:56.350948 12945 solver.cpp:218] Iteration 14800 (7.31318 iter/s, 13.6739s/100 iters), loss = 0.0141319
I1105 00:11:56.350988 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0141319 (* 1 = 0.0141319 loss)
I1105 00:11:56.350994 12945 sgd_solver.cpp:114] Iteration 14800, lr = 0.00288889
I1105 00:12:09.982414 12945 solver.cpp:218] Iteration 14900 (7.33629 iter/s, 13.6309s/100 iters), loss = 0.026103
I1105 00:12:09.982439 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.026103 (* 1 = 0.026103 loss)
I1105 00:12:09.982443 12945 sgd_solver.cpp:114] Iteration 14900, lr = 0.00283333
I1105 00:12:23.519845 12945 solver.cpp:447] Snapshotting to binary proto file ./snapshot/1/alex-dy_iter_15000.caffemodel
I1105 00:12:23.965958 12945 sgd_solver.cpp:282] Snapshotting solver state to binary proto file ./snapshot/1/alex-dy_iter_15000.solverstate
I1105 00:12:24.073639 12945 solver.cpp:330] Iteration 15000, Testing net (#0)
I1105 00:12:24.073659 12945 net.cpp:676] Ignoring source layer data
I1105 00:12:24.073662 12945 net.cpp:676] Ignoring source layer embedding_fc1
I1105 00:12:24.073664 12945 net.cpp:676] Ignoring source layer bn_embedding_fc1
I1105 00:12:24.073666 12945 net.cpp:676] Ignoring source layer scale_embedding_fc1
I1105 00:12:24.073668 12945 net.cpp:676] Ignoring source layer relu_embedding_fc1
I1105 00:12:24.073671 12945 net.cpp:676] Ignoring source layer embedding_fc2
I1105 00:12:24.073673 12945 net.cpp:676] Ignoring source layer embedding_fc2_embedding_fc2_0_split
I1105 00:12:24.073675 12945 net.cpp:676] Ignoring source layer conv1
I1105 00:12:24.073678 12945 net.cpp:676] Ignoring source layer bn_conv1
I1105 00:12:24.073679 12945 net.cpp:676] Ignoring source layer scale_conv1
I1105 00:12:24.073681 12945 net.cpp:676] Ignoring source layer relu1
I1105 00:12:24.073683 12945 net.cpp:676] Ignoring source layer pool1
I1105 00:12:24.073685 12945 net.cpp:676] Ignoring source layer filter_ip2
I1105 00:12:24.073689 12945 net.cpp:676] Ignoring source layer conv2
I1105 00:12:24.073696 12945 net.cpp:676] Ignoring source layer bn_conv2
I1105 00:12:24.073699 12945 net.cpp:676] Ignoring source layer scale_conv2
I1105 00:12:24.073701 12945 net.cpp:676] Ignoring source layer relu2
I1105 00:12:24.073704 12945 net.cpp:676] Ignoring source layer pool2
I1105 00:12:24.073706 12945 net.cpp:676] Ignoring source layer filter_ip3
I1105 00:12:24.073709 12945 net.cpp:676] Ignoring source layer conv3
I1105 00:12:24.073710 12945 net.cpp:676] Ignoring source layer bn_conv3
I1105 00:12:24.073714 12945 net.cpp:676] Ignoring source layer scale_conv3
I1105 00:12:24.073716 12945 net.cpp:676] Ignoring source layer relu3
I1105 00:12:24.073719 12945 net.cpp:676] Ignoring source layer filter_ip4
I1105 00:12:24.073720 12945 net.cpp:676] Ignoring source layer conv4
I1105 00:12:24.073725 12945 net.cpp:676] Ignoring source layer bn_conv4
I1105 00:12:24.073729 12945 net.cpp:676] Ignoring source layer scale_conv4
I1105 00:12:24.073730 12945 net.cpp:676] Ignoring source layer relu4
I1105 00:12:24.073732 12945 net.cpp:676] Ignoring source layer filter_ip5
I1105 00:12:24.073735 12945 net.cpp:676] Ignoring source layer conv5
I1105 00:12:24.073737 12945 net.cpp:676] Ignoring source layer bn_conv5
I1105 00:12:24.073740 12945 net.cpp:676] Ignoring source layer scale_conv5
I1105 00:12:24.073741 12945 net.cpp:676] Ignoring source layer relu5
I1105 00:12:24.073745 12945 net.cpp:676] Ignoring source layer pool5
I1105 00:12:24.073746 12945 net.cpp:676] Ignoring source layer filter_ip6
I1105 00:12:24.073750 12945 net.cpp:676] Ignoring source layer feat0
I1105 00:12:24.073751 12945 net.cpp:676] Ignoring source layer bn_feat0
I1105 00:12:24.073755 12945 net.cpp:676] Ignoring source layer scale_feat0
I1105 00:12:24.073757 12945 net.cpp:676] Ignoring source layer relu_feat0
I1105 00:12:24.073760 12945 net.cpp:676] Ignoring source layer filter_ip7
I1105 00:12:24.073762 12945 net.cpp:676] Ignoring source layer feat1
I1105 00:12:24.073765 12945 net.cpp:676] Ignoring source layer eucli_loss
W1105 00:12:24.301723 12945 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W1105 00:12:24.301746 12945 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W1105 00:12:24.301760 12945 _caffe.cpp:142] Net('./alexnet-deploy-dy.prototxt', 1, weights='./snapshot/1/alex-dy_iter_15000.caffemodel')
I1105 00:12:24.301967 12945 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./alexnet-deploy-dy.prototxt
I1105 00:12:24.301975 12945 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W1105 00:12:24.301977 12945 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I1105 00:12:24.302163 12945 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-aanet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "extra"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 2
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding_fc1"
  type: "InnerProduct"
  bottom: "extra"
  top: "embedding_fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_embedding_fc1"
  type: "BatchNorm"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_embedding_fc1"
  type: "Scale"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_embedding_fc1"
  type: "ReLU"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
}
layer {
  name: "embedding_fc2"
  type: "InnerProduct"
  bottom: "embedding_fc1"
  top: "embedding_fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip2"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 307200
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  bottom: "filter_ip2"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip3"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 884736
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  bottom: "filter_ip3"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "filter_ip4"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 663552
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  bottom: "filter_ip4"
  top: "conv4"
  param {
    name: "conv4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "filter_ip5"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 442368
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  bottom: "filter_ip5"
  top: "conv5"
  param {
    name: "conv5_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip6"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4718592
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "feat0"
  type: "Convolution"
  bottom: "pool5"
  bottom: "filter_ip6"
  top: "feat0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 6
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_feat0"
  type: "BatchNorm"
  bottom: "feat0"
  top: "feat0"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_feat0"
  type: "Scale"
  bottom: "feat0"
  top: "feat0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_feat0"
  type: "ReLU"
  bottom: "feat0"
  top: "feat0"
}
layer {
  name: "filter_ip7"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "feat1"
  type: "Convolution"
  bottom: "feat0"
  bottom: "filter_ip7"
  top: "feat1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
I1105 00:12:24.302258 12945 layer_factory.hpp:77] Creating layer input
I1105 00:12:24.302263 12945 net.cpp:84] Creating Layer input
I1105 00:12:24.302266 12945 net.cpp:380] input -> data
I1105 00:12:24.302273 12945 net.cpp:380] input -> extra
I1105 00:12:24.302361 12945 net.cpp:122] Setting up input
I1105 00:12:24.302364 12945 net.cpp:129] Top shape: 1 3 224 224 (150528)
I1105 00:12:24.302366 12945 net.cpp:129] Top shape: 1 2 1 1 (2)
I1105 00:12:24.302368 12945 net.cpp:137] Memory required for data: 602120
I1105 00:12:24.302371 12945 layer_factory.hpp:77] Creating layer embedding_fc1
I1105 00:12:24.302374 12945 net.cpp:84] Creating Layer embedding_fc1
I1105 00:12:24.302376 12945 net.cpp:406] embedding_fc1 <- extra
I1105 00:12:24.302381 12945 net.cpp:380] embedding_fc1 -> embedding_fc1
I1105 00:12:24.302484 12945 net.cpp:122] Setting up embedding_fc1
I1105 00:12:24.302487 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:12:24.302489 12945 net.cpp:137] Memory required for data: 603144
I1105 00:12:24.302495 12945 layer_factory.hpp:77] Creating layer bn_embedding_fc1
I1105 00:12:24.302500 12945 net.cpp:84] Creating Layer bn_embedding_fc1
I1105 00:12:24.302501 12945 net.cpp:406] bn_embedding_fc1 <- embedding_fc1
I1105 00:12:24.302505 12945 net.cpp:367] bn_embedding_fc1 -> embedding_fc1 (in-place)
I1105 00:12:24.302657 12945 net.cpp:122] Setting up bn_embedding_fc1
I1105 00:12:24.302661 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:12:24.302662 12945 net.cpp:137] Memory required for data: 604168
I1105 00:12:24.302668 12945 layer_factory.hpp:77] Creating layer scale_embedding_fc1
I1105 00:12:24.302672 12945 net.cpp:84] Creating Layer scale_embedding_fc1
I1105 00:12:24.302675 12945 net.cpp:406] scale_embedding_fc1 <- embedding_fc1
I1105 00:12:24.302677 12945 net.cpp:367] scale_embedding_fc1 -> embedding_fc1 (in-place)
I1105 00:12:24.302706 12945 layer_factory.hpp:77] Creating layer scale_embedding_fc1
I1105 00:12:24.302794 12945 net.cpp:122] Setting up scale_embedding_fc1
I1105 00:12:24.302798 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:12:24.302799 12945 net.cpp:137] Memory required for data: 605192
I1105 00:12:24.302803 12945 layer_factory.hpp:77] Creating layer relu_embedding_fc1
I1105 00:12:24.302806 12945 net.cpp:84] Creating Layer relu_embedding_fc1
I1105 00:12:24.302809 12945 net.cpp:406] relu_embedding_fc1 <- embedding_fc1
I1105 00:12:24.302820 12945 net.cpp:367] relu_embedding_fc1 -> embedding_fc1 (in-place)
I1105 00:12:24.303064 12945 net.cpp:122] Setting up relu_embedding_fc1
I1105 00:12:24.303069 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:12:24.303071 12945 net.cpp:137] Memory required for data: 606216
I1105 00:12:24.303073 12945 layer_factory.hpp:77] Creating layer embedding_fc2
I1105 00:12:24.303077 12945 net.cpp:84] Creating Layer embedding_fc2
I1105 00:12:24.303079 12945 net.cpp:406] embedding_fc2 <- embedding_fc1
I1105 00:12:24.303082 12945 net.cpp:380] embedding_fc2 -> embedding_fc2
I1105 00:12:24.303170 12945 net.cpp:122] Setting up embedding_fc2
I1105 00:12:24.303174 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:12:24.303175 12945 net.cpp:137] Memory required for data: 606220
I1105 00:12:24.303180 12945 layer_factory.hpp:77] Creating layer embedding_fc2_embedding_fc2_0_split
I1105 00:12:24.303184 12945 net.cpp:84] Creating Layer embedding_fc2_embedding_fc2_0_split
I1105 00:12:24.303185 12945 net.cpp:406] embedding_fc2_embedding_fc2_0_split <- embedding_fc2
I1105 00:12:24.303189 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_0
I1105 00:12:24.303194 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_1
I1105 00:12:24.303197 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_2
I1105 00:12:24.303201 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_3
I1105 00:12:24.303205 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_4
I1105 00:12:24.303208 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_5
I1105 00:12:24.303277 12945 net.cpp:122] Setting up embedding_fc2_embedding_fc2_0_split
I1105 00:12:24.303280 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:12:24.303282 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:12:24.303284 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:12:24.303287 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:12:24.303288 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:12:24.303290 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:12:24.303292 12945 net.cpp:137] Memory required for data: 606244
I1105 00:12:24.303294 12945 layer_factory.hpp:77] Creating layer conv1
I1105 00:12:24.303299 12945 net.cpp:84] Creating Layer conv1
I1105 00:12:24.303301 12945 net.cpp:406] conv1 <- data
I1105 00:12:24.303305 12945 net.cpp:380] conv1 -> conv1
I1105 00:12:24.303750 12945 net.cpp:122] Setting up conv1
I1105 00:12:24.303753 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:12:24.303755 12945 net.cpp:137] Memory required for data: 1725988
I1105 00:12:24.303758 12945 layer_factory.hpp:77] Creating layer bn_conv1
I1105 00:12:24.303763 12945 net.cpp:84] Creating Layer bn_conv1
I1105 00:12:24.303766 12945 net.cpp:406] bn_conv1 <- conv1
I1105 00:12:24.303767 12945 net.cpp:367] bn_conv1 -> conv1 (in-place)
I1105 00:12:24.303932 12945 net.cpp:122] Setting up bn_conv1
I1105 00:12:24.303936 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:12:24.303937 12945 net.cpp:137] Memory required for data: 2845732
I1105 00:12:24.303941 12945 layer_factory.hpp:77] Creating layer scale_conv1
I1105 00:12:24.303944 12945 net.cpp:84] Creating Layer scale_conv1
I1105 00:12:24.303946 12945 net.cpp:406] scale_conv1 <- conv1
I1105 00:12:24.303949 12945 net.cpp:367] scale_conv1 -> conv1 (in-place)
I1105 00:12:24.303979 12945 layer_factory.hpp:77] Creating layer scale_conv1
I1105 00:12:24.304078 12945 net.cpp:122] Setting up scale_conv1
I1105 00:12:24.304081 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:12:24.304083 12945 net.cpp:137] Memory required for data: 3965476
I1105 00:12:24.304086 12945 layer_factory.hpp:77] Creating layer relu1
I1105 00:12:24.304090 12945 net.cpp:84] Creating Layer relu1
I1105 00:12:24.304091 12945 net.cpp:406] relu1 <- conv1
I1105 00:12:24.304095 12945 net.cpp:367] relu1 -> conv1 (in-place)
I1105 00:12:24.304291 12945 net.cpp:122] Setting up relu1
I1105 00:12:24.304302 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:12:24.304304 12945 net.cpp:137] Memory required for data: 5085220
I1105 00:12:24.304306 12945 layer_factory.hpp:77] Creating layer pool1
I1105 00:12:24.304309 12945 net.cpp:84] Creating Layer pool1
I1105 00:12:24.304312 12945 net.cpp:406] pool1 <- conv1
I1105 00:12:24.304314 12945 net.cpp:380] pool1 -> pool1
I1105 00:12:24.304349 12945 net.cpp:122] Setting up pool1
I1105 00:12:24.304353 12945 net.cpp:129] Top shape: 1 96 27 27 (69984)
I1105 00:12:24.304355 12945 net.cpp:137] Memory required for data: 5365156
I1105 00:12:24.304356 12945 layer_factory.hpp:77] Creating layer filter_ip2
I1105 00:12:24.304360 12945 net.cpp:84] Creating Layer filter_ip2
I1105 00:12:24.304361 12945 net.cpp:406] filter_ip2 <- embedding_fc2_embedding_fc2_0_split_0
I1105 00:12:24.304365 12945 net.cpp:380] filter_ip2 -> filter_ip2
I1105 00:12:24.307407 12945 net.cpp:122] Setting up filter_ip2
I1105 00:12:24.307416 12945 net.cpp:129] Top shape: 1 307200 (307200)
I1105 00:12:24.307418 12945 net.cpp:137] Memory required for data: 6593956
I1105 00:12:24.307425 12945 layer_factory.hpp:77] Creating layer conv2
I1105 00:12:24.307432 12945 net.cpp:84] Creating Layer conv2
I1105 00:12:24.307435 12945 net.cpp:406] conv2 <- pool1
I1105 00:12:24.307437 12945 net.cpp:406] conv2 <- filter_ip2
I1105 00:12:24.307440 12945 net.cpp:380] conv2 -> conv2
I1105 00:12:24.309952 12945 net.cpp:122] Setting up conv2
I1105 00:12:24.309959 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:12:24.309962 12945 net.cpp:137] Memory required for data: 7340452
I1105 00:12:24.309967 12945 layer_factory.hpp:77] Creating layer bn_conv2
I1105 00:12:24.309970 12945 net.cpp:84] Creating Layer bn_conv2
I1105 00:12:24.309973 12945 net.cpp:406] bn_conv2 <- conv2
I1105 00:12:24.309975 12945 net.cpp:367] bn_conv2 -> conv2 (in-place)
I1105 00:12:24.310142 12945 net.cpp:122] Setting up bn_conv2
I1105 00:12:24.310144 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:12:24.310146 12945 net.cpp:137] Memory required for data: 8086948
I1105 00:12:24.310150 12945 layer_factory.hpp:77] Creating layer scale_conv2
I1105 00:12:24.310154 12945 net.cpp:84] Creating Layer scale_conv2
I1105 00:12:24.310156 12945 net.cpp:406] scale_conv2 <- conv2
I1105 00:12:24.310158 12945 net.cpp:367] scale_conv2 -> conv2 (in-place)
I1105 00:12:24.310189 12945 layer_factory.hpp:77] Creating layer scale_conv2
I1105 00:12:24.310286 12945 net.cpp:122] Setting up scale_conv2
I1105 00:12:24.310288 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:12:24.310290 12945 net.cpp:137] Memory required for data: 8833444
I1105 00:12:24.310293 12945 layer_factory.hpp:77] Creating layer relu2
I1105 00:12:24.310299 12945 net.cpp:84] Creating Layer relu2
I1105 00:12:24.310300 12945 net.cpp:406] relu2 <- conv2
I1105 00:12:24.310303 12945 net.cpp:367] relu2 -> conv2 (in-place)
I1105 00:12:24.310523 12945 net.cpp:122] Setting up relu2
I1105 00:12:24.310528 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:12:24.310530 12945 net.cpp:137] Memory required for data: 9579940
I1105 00:12:24.310532 12945 layer_factory.hpp:77] Creating layer pool2
I1105 00:12:24.310535 12945 net.cpp:84] Creating Layer pool2
I1105 00:12:24.310539 12945 net.cpp:406] pool2 <- conv2
I1105 00:12:24.310541 12945 net.cpp:380] pool2 -> pool2
I1105 00:12:24.310575 12945 net.cpp:122] Setting up pool2
I1105 00:12:24.310578 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:12:24.310581 12945 net.cpp:137] Memory required for data: 9752996
I1105 00:12:24.310582 12945 layer_factory.hpp:77] Creating layer filter_ip3
I1105 00:12:24.310586 12945 net.cpp:84] Creating Layer filter_ip3
I1105 00:12:24.310588 12945 net.cpp:406] filter_ip3 <- embedding_fc2_embedding_fc2_0_split_1
I1105 00:12:24.310591 12945 net.cpp:380] filter_ip3 -> filter_ip3
I1105 00:12:24.317728 12945 net.cpp:122] Setting up filter_ip3
I1105 00:12:24.317739 12945 net.cpp:129] Top shape: 1 884736 (884736)
I1105 00:12:24.317741 12945 net.cpp:137] Memory required for data: 13291940
I1105 00:12:24.317762 12945 layer_factory.hpp:77] Creating layer conv3
I1105 00:12:24.317770 12945 net.cpp:84] Creating Layer conv3
I1105 00:12:24.317773 12945 net.cpp:406] conv3 <- pool2
I1105 00:12:24.317776 12945 net.cpp:406] conv3 <- filter_ip3
I1105 00:12:24.317780 12945 net.cpp:380] conv3 -> conv3
I1105 00:12:24.324100 12945 net.cpp:122] Setting up conv3
I1105 00:12:24.324111 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:12:24.324113 12945 net.cpp:137] Memory required for data: 13551524
I1105 00:12:24.324118 12945 layer_factory.hpp:77] Creating layer bn_conv3
I1105 00:12:24.324123 12945 net.cpp:84] Creating Layer bn_conv3
I1105 00:12:24.324126 12945 net.cpp:406] bn_conv3 <- conv3
I1105 00:12:24.324131 12945 net.cpp:367] bn_conv3 -> conv3 (in-place)
I1105 00:12:24.324301 12945 net.cpp:122] Setting up bn_conv3
I1105 00:12:24.324304 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:12:24.324306 12945 net.cpp:137] Memory required for data: 13811108
I1105 00:12:24.324311 12945 layer_factory.hpp:77] Creating layer scale_conv3
I1105 00:12:24.324314 12945 net.cpp:84] Creating Layer scale_conv3
I1105 00:12:24.324316 12945 net.cpp:406] scale_conv3 <- conv3
I1105 00:12:24.324319 12945 net.cpp:367] scale_conv3 -> conv3 (in-place)
I1105 00:12:24.324349 12945 layer_factory.hpp:77] Creating layer scale_conv3
I1105 00:12:24.324445 12945 net.cpp:122] Setting up scale_conv3
I1105 00:12:24.324448 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:12:24.324450 12945 net.cpp:137] Memory required for data: 14070692
I1105 00:12:24.324456 12945 layer_factory.hpp:77] Creating layer relu3
I1105 00:12:24.324460 12945 net.cpp:84] Creating Layer relu3
I1105 00:12:24.324462 12945 net.cpp:406] relu3 <- conv3
I1105 00:12:24.324465 12945 net.cpp:367] relu3 -> conv3 (in-place)
I1105 00:12:24.324764 12945 net.cpp:122] Setting up relu3
I1105 00:12:24.324769 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:12:24.324770 12945 net.cpp:137] Memory required for data: 14330276
I1105 00:12:24.324772 12945 layer_factory.hpp:77] Creating layer filter_ip4
I1105 00:12:24.324777 12945 net.cpp:84] Creating Layer filter_ip4
I1105 00:12:24.324779 12945 net.cpp:406] filter_ip4 <- embedding_fc2_embedding_fc2_0_split_2
I1105 00:12:24.324784 12945 net.cpp:380] filter_ip4 -> filter_ip4
I1105 00:12:24.330200 12945 net.cpp:122] Setting up filter_ip4
I1105 00:12:24.330210 12945 net.cpp:129] Top shape: 1 663552 (663552)
I1105 00:12:24.330212 12945 net.cpp:137] Memory required for data: 16984484
I1105 00:12:24.330219 12945 layer_factory.hpp:77] Creating layer conv4
I1105 00:12:24.330225 12945 net.cpp:84] Creating Layer conv4
I1105 00:12:24.330229 12945 net.cpp:406] conv4 <- conv3
I1105 00:12:24.330232 12945 net.cpp:406] conv4 <- filter_ip4
I1105 00:12:24.330235 12945 net.cpp:380] conv4 -> conv4
I1105 00:12:24.335052 12945 net.cpp:122] Setting up conv4
I1105 00:12:24.335060 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:12:24.335062 12945 net.cpp:137] Memory required for data: 17244068
I1105 00:12:24.335067 12945 layer_factory.hpp:77] Creating layer bn_conv4
I1105 00:12:24.335072 12945 net.cpp:84] Creating Layer bn_conv4
I1105 00:12:24.335074 12945 net.cpp:406] bn_conv4 <- conv4
I1105 00:12:24.335078 12945 net.cpp:367] bn_conv4 -> conv4 (in-place)
I1105 00:12:24.335247 12945 net.cpp:122] Setting up bn_conv4
I1105 00:12:24.335252 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:12:24.335253 12945 net.cpp:137] Memory required for data: 17503652
I1105 00:12:24.335258 12945 layer_factory.hpp:77] Creating layer scale_conv4
I1105 00:12:24.335261 12945 net.cpp:84] Creating Layer scale_conv4
I1105 00:12:24.335263 12945 net.cpp:406] scale_conv4 <- conv4
I1105 00:12:24.335266 12945 net.cpp:367] scale_conv4 -> conv4 (in-place)
I1105 00:12:24.335296 12945 layer_factory.hpp:77] Creating layer scale_conv4
I1105 00:12:24.335391 12945 net.cpp:122] Setting up scale_conv4
I1105 00:12:24.335395 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:12:24.335397 12945 net.cpp:137] Memory required for data: 17763236
I1105 00:12:24.335415 12945 layer_factory.hpp:77] Creating layer relu4
I1105 00:12:24.335418 12945 net.cpp:84] Creating Layer relu4
I1105 00:12:24.335420 12945 net.cpp:406] relu4 <- conv4
I1105 00:12:24.335423 12945 net.cpp:367] relu4 -> conv4 (in-place)
I1105 00:12:24.335739 12945 net.cpp:122] Setting up relu4
I1105 00:12:24.335749 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:12:24.335752 12945 net.cpp:137] Memory required for data: 18022820
I1105 00:12:24.335752 12945 layer_factory.hpp:77] Creating layer filter_ip5
I1105 00:12:24.335758 12945 net.cpp:84] Creating Layer filter_ip5
I1105 00:12:24.335760 12945 net.cpp:406] filter_ip5 <- embedding_fc2_embedding_fc2_0_split_3
I1105 00:12:24.335763 12945 net.cpp:380] filter_ip5 -> filter_ip5
I1105 00:12:24.339589 12945 net.cpp:122] Setting up filter_ip5
I1105 00:12:24.339598 12945 net.cpp:129] Top shape: 1 442368 (442368)
I1105 00:12:24.339601 12945 net.cpp:137] Memory required for data: 19792292
I1105 00:12:24.339605 12945 layer_factory.hpp:77] Creating layer conv5
I1105 00:12:24.339612 12945 net.cpp:84] Creating Layer conv5
I1105 00:12:24.339615 12945 net.cpp:406] conv5 <- conv4
I1105 00:12:24.339618 12945 net.cpp:406] conv5 <- filter_ip5
I1105 00:12:24.339622 12945 net.cpp:380] conv5 -> conv5
I1105 00:12:24.342927 12945 net.cpp:122] Setting up conv5
I1105 00:12:24.342934 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:12:24.342936 12945 net.cpp:137] Memory required for data: 19965348
I1105 00:12:24.342941 12945 layer_factory.hpp:77] Creating layer bn_conv5
I1105 00:12:24.342944 12945 net.cpp:84] Creating Layer bn_conv5
I1105 00:12:24.342947 12945 net.cpp:406] bn_conv5 <- conv5
I1105 00:12:24.342950 12945 net.cpp:367] bn_conv5 -> conv5 (in-place)
I1105 00:12:24.343207 12945 net.cpp:122] Setting up bn_conv5
I1105 00:12:24.343211 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:12:24.343214 12945 net.cpp:137] Memory required for data: 20138404
I1105 00:12:24.343219 12945 layer_factory.hpp:77] Creating layer scale_conv5
I1105 00:12:24.343221 12945 net.cpp:84] Creating Layer scale_conv5
I1105 00:12:24.343223 12945 net.cpp:406] scale_conv5 <- conv5
I1105 00:12:24.343226 12945 net.cpp:367] scale_conv5 -> conv5 (in-place)
I1105 00:12:24.343258 12945 layer_factory.hpp:77] Creating layer scale_conv5
I1105 00:12:24.343350 12945 net.cpp:122] Setting up scale_conv5
I1105 00:12:24.343354 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:12:24.343356 12945 net.cpp:137] Memory required for data: 20311460
I1105 00:12:24.343359 12945 layer_factory.hpp:77] Creating layer relu5
I1105 00:12:24.343365 12945 net.cpp:84] Creating Layer relu5
I1105 00:12:24.343367 12945 net.cpp:406] relu5 <- conv5
I1105 00:12:24.343370 12945 net.cpp:367] relu5 -> conv5 (in-place)
I1105 00:12:24.343691 12945 net.cpp:122] Setting up relu5
I1105 00:12:24.343698 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:12:24.343698 12945 net.cpp:137] Memory required for data: 20484516
I1105 00:12:24.343701 12945 layer_factory.hpp:77] Creating layer pool5
I1105 00:12:24.343704 12945 net.cpp:84] Creating Layer pool5
I1105 00:12:24.343706 12945 net.cpp:406] pool5 <- conv5
I1105 00:12:24.343709 12945 net.cpp:380] pool5 -> pool5
I1105 00:12:24.343751 12945 net.cpp:122] Setting up pool5
I1105 00:12:24.343755 12945 net.cpp:129] Top shape: 1 256 6 6 (9216)
I1105 00:12:24.343756 12945 net.cpp:137] Memory required for data: 20521380
I1105 00:12:24.343758 12945 layer_factory.hpp:77] Creating layer filter_ip6
I1105 00:12:24.343762 12945 net.cpp:84] Creating Layer filter_ip6
I1105 00:12:24.343765 12945 net.cpp:406] filter_ip6 <- embedding_fc2_embedding_fc2_0_split_4
I1105 00:12:24.343768 12945 net.cpp:380] filter_ip6 -> filter_ip6
I1105 00:12:24.380760 12945 net.cpp:122] Setting up filter_ip6
I1105 00:12:24.380779 12945 net.cpp:129] Top shape: 1 4718592 (4718592)
I1105 00:12:24.380782 12945 net.cpp:137] Memory required for data: 39395748
I1105 00:12:24.380789 12945 layer_factory.hpp:77] Creating layer feat0
I1105 00:12:24.380800 12945 net.cpp:84] Creating Layer feat0
I1105 00:12:24.380802 12945 net.cpp:406] feat0 <- pool5
I1105 00:12:24.380825 12945 net.cpp:406] feat0 <- filter_ip6
I1105 00:12:24.380829 12945 net.cpp:380] feat0 -> feat0
I1105 00:12:24.412725 12945 net.cpp:122] Setting up feat0
I1105 00:12:24.412740 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:12:24.412742 12945 net.cpp:137] Memory required for data: 39397796
I1105 00:12:24.412748 12945 layer_factory.hpp:77] Creating layer bn_feat0
I1105 00:12:24.412755 12945 net.cpp:84] Creating Layer bn_feat0
I1105 00:12:24.412757 12945 net.cpp:406] bn_feat0 <- feat0
I1105 00:12:24.412761 12945 net.cpp:367] bn_feat0 -> feat0 (in-place)
I1105 00:12:24.412935 12945 net.cpp:122] Setting up bn_feat0
I1105 00:12:24.412938 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:12:24.412940 12945 net.cpp:137] Memory required for data: 39399844
I1105 00:12:24.412945 12945 layer_factory.hpp:77] Creating layer scale_feat0
I1105 00:12:24.412948 12945 net.cpp:84] Creating Layer scale_feat0
I1105 00:12:24.412950 12945 net.cpp:406] scale_feat0 <- feat0
I1105 00:12:24.412953 12945 net.cpp:367] scale_feat0 -> feat0 (in-place)
I1105 00:12:24.412983 12945 layer_factory.hpp:77] Creating layer scale_feat0
I1105 00:12:24.413081 12945 net.cpp:122] Setting up scale_feat0
I1105 00:12:24.413084 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:12:24.413087 12945 net.cpp:137] Memory required for data: 39401892
I1105 00:12:24.413090 12945 layer_factory.hpp:77] Creating layer relu_feat0
I1105 00:12:24.413094 12945 net.cpp:84] Creating Layer relu_feat0
I1105 00:12:24.413095 12945 net.cpp:406] relu_feat0 <- feat0
I1105 00:12:24.413098 12945 net.cpp:367] relu_feat0 -> feat0 (in-place)
I1105 00:12:24.413435 12945 net.cpp:122] Setting up relu_feat0
I1105 00:12:24.413440 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:12:24.413442 12945 net.cpp:137] Memory required for data: 39403940
I1105 00:12:24.413444 12945 layer_factory.hpp:77] Creating layer filter_ip7
I1105 00:12:24.413448 12945 net.cpp:84] Creating Layer filter_ip7
I1105 00:12:24.413450 12945 net.cpp:406] filter_ip7 <- embedding_fc2_embedding_fc2_0_split_5
I1105 00:12:24.413455 12945 net.cpp:380] filter_ip7 -> filter_ip7
I1105 00:12:24.413555 12945 net.cpp:122] Setting up filter_ip7
I1105 00:12:24.413558 12945 net.cpp:129] Top shape: 1 512 (512)
I1105 00:12:24.413560 12945 net.cpp:137] Memory required for data: 39405988
I1105 00:12:24.413563 12945 layer_factory.hpp:77] Creating layer feat1
I1105 00:12:24.413569 12945 net.cpp:84] Creating Layer feat1
I1105 00:12:24.413571 12945 net.cpp:406] feat1 <- feat0
I1105 00:12:24.413573 12945 net.cpp:406] feat1 <- filter_ip7
I1105 00:12:24.413576 12945 net.cpp:380] feat1 -> feat1
I1105 00:12:24.413805 12945 net.cpp:122] Setting up feat1
I1105 00:12:24.413810 12945 net.cpp:129] Top shape: 1 1 1 1 (1)
I1105 00:12:24.413810 12945 net.cpp:137] Memory required for data: 39405992
I1105 00:12:24.413818 12945 net.cpp:200] feat1 does not need backward computation.
I1105 00:12:24.413821 12945 net.cpp:200] filter_ip7 does not need backward computation.
I1105 00:12:24.413823 12945 net.cpp:200] relu_feat0 does not need backward computation.
I1105 00:12:24.413825 12945 net.cpp:200] scale_feat0 does not need backward computation.
I1105 00:12:24.413826 12945 net.cpp:200] bn_feat0 does not need backward computation.
I1105 00:12:24.413828 12945 net.cpp:200] feat0 does not need backward computation.
I1105 00:12:24.413831 12945 net.cpp:200] filter_ip6 does not need backward computation.
I1105 00:12:24.413833 12945 net.cpp:200] pool5 does not need backward computation.
I1105 00:12:24.413836 12945 net.cpp:200] relu5 does not need backward computation.
I1105 00:12:24.413837 12945 net.cpp:200] scale_conv5 does not need backward computation.
I1105 00:12:24.413839 12945 net.cpp:200] bn_conv5 does not need backward computation.
I1105 00:12:24.413841 12945 net.cpp:200] conv5 does not need backward computation.
I1105 00:12:24.413843 12945 net.cpp:200] filter_ip5 does not need backward computation.
I1105 00:12:24.413846 12945 net.cpp:200] relu4 does not need backward computation.
I1105 00:12:24.413847 12945 net.cpp:200] scale_conv4 does not need backward computation.
I1105 00:12:24.413866 12945 net.cpp:200] bn_conv4 does not need backward computation.
I1105 00:12:24.413867 12945 net.cpp:200] conv4 does not need backward computation.
I1105 00:12:24.413870 12945 net.cpp:200] filter_ip4 does not need backward computation.
I1105 00:12:24.413872 12945 net.cpp:200] relu3 does not need backward computation.
I1105 00:12:24.413874 12945 net.cpp:200] scale_conv3 does not need backward computation.
I1105 00:12:24.413877 12945 net.cpp:200] bn_conv3 does not need backward computation.
I1105 00:12:24.413878 12945 net.cpp:200] conv3 does not need backward computation.
I1105 00:12:24.413880 12945 net.cpp:200] filter_ip3 does not need backward computation.
I1105 00:12:24.413882 12945 net.cpp:200] pool2 does not need backward computation.
I1105 00:12:24.413884 12945 net.cpp:200] relu2 does not need backward computation.
I1105 00:12:24.413887 12945 net.cpp:200] scale_conv2 does not need backward computation.
I1105 00:12:24.413888 12945 net.cpp:200] bn_conv2 does not need backward computation.
I1105 00:12:24.413889 12945 net.cpp:200] conv2 does not need backward computation.
I1105 00:12:24.413892 12945 net.cpp:200] filter_ip2 does not need backward computation.
I1105 00:12:24.413894 12945 net.cpp:200] pool1 does not need backward computation.
I1105 00:12:24.413895 12945 net.cpp:200] relu1 does not need backward computation.
I1105 00:12:24.413897 12945 net.cpp:200] scale_conv1 does not need backward computation.
I1105 00:12:24.413899 12945 net.cpp:200] bn_conv1 does not need backward computation.
I1105 00:12:24.413902 12945 net.cpp:200] conv1 does not need backward computation.
I1105 00:12:24.413903 12945 net.cpp:200] embedding_fc2_embedding_fc2_0_split does not need backward computation.
I1105 00:12:24.413905 12945 net.cpp:200] embedding_fc2 does not need backward computation.
I1105 00:12:24.413908 12945 net.cpp:200] relu_embedding_fc1 does not need backward computation.
I1105 00:12:24.413910 12945 net.cpp:200] scale_embedding_fc1 does not need backward computation.
I1105 00:12:24.413913 12945 net.cpp:200] bn_embedding_fc1 does not need backward computation.
I1105 00:12:24.413913 12945 net.cpp:200] embedding_fc1 does not need backward computation.
I1105 00:12:24.413915 12945 net.cpp:200] input does not need backward computation.
I1105 00:12:24.413918 12945 net.cpp:242] This network produces output feat1
I1105 00:12:24.413931 12945 net.cpp:255] Network initialization done.
I1105 00:12:24.445256 12945 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./snapshot/1/alex-dy_iter_15000.caffemodel
I1105 00:12:24.445274 12945 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1105 00:12:24.445277 12945 net.cpp:744] Ignoring source layer data
I1105 00:12:24.505239 12945 net.cpp:744] Ignoring source layer eucli_loss
I1105 00:12:40.495750 12945 solver.cpp:397]     Test net output #0: accuracy = 0.876325
I1105 00:12:40.495898 12945 solver.cpp:397]     Test net output #1: mae = 0.26502
I1105 00:12:40.495905 12945 solver.cpp:397]     Test net output #2: rmse = 0.337065
I1105 00:12:40.638459 12945 solver.cpp:218] Iteration 15000 (3.26213 iter/s, 30.6548s/100 iters), loss = 0.0086596
I1105 00:12:40.638489 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.00865956 (* 1 = 0.00865956 loss)
I1105 00:12:40.638494 12945 sgd_solver.cpp:114] Iteration 15000, lr = 0.00277778
I1105 00:12:54.225419 12945 solver.cpp:218] Iteration 15100 (7.36032 iter/s, 13.5864s/100 iters), loss = 0.0169398
I1105 00:12:54.225443 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0169398 (* 1 = 0.0169398 loss)
I1105 00:12:54.225450 12945 sgd_solver.cpp:114] Iteration 15100, lr = 0.00272222
I1105 00:13:07.809065 12945 solver.cpp:218] Iteration 15200 (7.36211 iter/s, 13.5831s/100 iters), loss = 0.0131702
I1105 00:13:07.809090 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0131702 (* 1 = 0.0131702 loss)
I1105 00:13:07.809095 12945 sgd_solver.cpp:114] Iteration 15200, lr = 0.00266667
I1105 00:13:21.392572 12945 solver.cpp:218] Iteration 15300 (7.36219 iter/s, 13.5829s/100 iters), loss = 0.02583
I1105 00:13:21.392680 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0258299 (* 1 = 0.0258299 loss)
I1105 00:13:21.392688 12945 sgd_solver.cpp:114] Iteration 15300, lr = 0.00261111
I1105 00:13:34.972841 12945 solver.cpp:218] Iteration 15400 (7.36399 iter/s, 13.5796s/100 iters), loss = 0.0376624
I1105 00:13:34.972864 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0376624 (* 1 = 0.0376624 loss)
I1105 00:13:34.972869 12945 sgd_solver.cpp:114] Iteration 15400, lr = 0.00255556
I1105 00:13:48.635747 12945 solver.cpp:218] Iteration 15500 (7.3194 iter/s, 13.6623s/100 iters), loss = 0.0128941
I1105 00:13:48.635772 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0128941 (* 1 = 0.0128941 loss)
I1105 00:13:48.635777 12945 sgd_solver.cpp:114] Iteration 15500, lr = 0.0025
I1105 00:14:02.289191 12945 solver.cpp:218] Iteration 15600 (7.32447 iter/s, 13.6529s/100 iters), loss = 0.0167211
I1105 00:14:02.289316 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0167211 (* 1 = 0.0167211 loss)
I1105 00:14:02.289324 12945 sgd_solver.cpp:114] Iteration 15600, lr = 0.00244444
I1105 00:14:15.945466 12945 solver.cpp:218] Iteration 15700 (7.32301 iter/s, 13.6556s/100 iters), loss = 0.0134557
I1105 00:14:15.945490 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0134557 (* 1 = 0.0134557 loss)
I1105 00:14:15.945495 12945 sgd_solver.cpp:114] Iteration 15700, lr = 0.00238889
I1105 00:14:29.597538 12945 solver.cpp:218] Iteration 15800 (7.32521 iter/s, 13.6515s/100 iters), loss = 0.0152111
I1105 00:14:29.597563 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0152111 (* 1 = 0.0152111 loss)
I1105 00:14:29.597569 12945 sgd_solver.cpp:114] Iteration 15800, lr = 0.00233333
I1105 00:14:43.254017 12945 solver.cpp:218] Iteration 15900 (7.32285 iter/s, 13.6559s/100 iters), loss = 0.0169437
I1105 00:14:43.254127 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0169437 (* 1 = 0.0169437 loss)
I1105 00:14:43.254135 12945 sgd_solver.cpp:114] Iteration 15900, lr = 0.00227778
I1105 00:14:56.908250 12945 solver.cpp:218] Iteration 16000 (7.32409 iter/s, 13.6536s/100 iters), loss = 0.0182709
I1105 00:14:56.908275 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0182709 (* 1 = 0.0182709 loss)
I1105 00:14:56.908282 12945 sgd_solver.cpp:114] Iteration 16000, lr = 0.00222222
I1105 00:15:10.556715 12945 solver.cpp:218] Iteration 16100 (7.32715 iter/s, 13.6479s/100 iters), loss = 0.0117273
I1105 00:15:10.556740 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0117273 (* 1 = 0.0117273 loss)
I1105 00:15:10.556744 12945 sgd_solver.cpp:114] Iteration 16100, lr = 0.00216667
I1105 00:15:24.212288 12945 solver.cpp:218] Iteration 16200 (7.32333 iter/s, 13.655s/100 iters), loss = 0.0118163
I1105 00:15:24.212397 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0118163 (* 1 = 0.0118163 loss)
I1105 00:15:24.212404 12945 sgd_solver.cpp:114] Iteration 16200, lr = 0.00211111
I1105 00:15:37.865900 12945 solver.cpp:218] Iteration 16300 (7.32443 iter/s, 13.6529s/100 iters), loss = 0.014067
I1105 00:15:37.865926 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.014067 (* 1 = 0.014067 loss)
I1105 00:15:37.865931 12945 sgd_solver.cpp:114] Iteration 16300, lr = 0.00205556
I1105 00:15:51.521175 12945 solver.cpp:218] Iteration 16400 (7.32349 iter/s, 13.6547s/100 iters), loss = 0.0154969
I1105 00:15:51.521200 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0154969 (* 1 = 0.0154969 loss)
I1105 00:15:51.521206 12945 sgd_solver.cpp:114] Iteration 16400, lr = 0.002
I1105 00:16:05.172813 12945 solver.cpp:218] Iteration 16500 (7.32544 iter/s, 13.6511s/100 iters), loss = 0.0185905
I1105 00:16:05.172857 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0185904 (* 1 = 0.0185904 loss)
I1105 00:16:05.172863 12945 sgd_solver.cpp:114] Iteration 16500, lr = 0.00194444
I1105 00:16:18.827522 12945 solver.cpp:218] Iteration 16600 (7.3238 iter/s, 13.6541s/100 iters), loss = 0.0329925
I1105 00:16:18.827548 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0329925 (* 1 = 0.0329925 loss)
I1105 00:16:18.827553 12945 sgd_solver.cpp:114] Iteration 16600, lr = 0.00188889
I1105 00:16:32.484999 12945 solver.cpp:218] Iteration 16700 (7.32231 iter/s, 13.6569s/100 iters), loss = 0.0243781
I1105 00:16:32.485024 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0243781 (* 1 = 0.0243781 loss)
I1105 00:16:32.485029 12945 sgd_solver.cpp:114] Iteration 16700, lr = 0.00183333
I1105 00:16:46.134390 12945 solver.cpp:218] Iteration 16800 (7.32665 iter/s, 13.6488s/100 iters), loss = 0.0181755
I1105 00:16:46.134531 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0181755 (* 1 = 0.0181755 loss)
I1105 00:16:46.134538 12945 sgd_solver.cpp:114] Iteration 16800, lr = 0.00177778
I1105 00:16:59.790251 12945 solver.cpp:218] Iteration 16900 (7.32324 iter/s, 13.6552s/100 iters), loss = 0.0185938
I1105 00:16:59.790277 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0185938 (* 1 = 0.0185938 loss)
I1105 00:16:59.790282 12945 sgd_solver.cpp:114] Iteration 16900, lr = 0.00172222
I1105 00:17:13.442713 12945 solver.cpp:218] Iteration 17000 (7.325 iter/s, 13.6519s/100 iters), loss = 0.018857
I1105 00:17:13.442737 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.018857 (* 1 = 0.018857 loss)
I1105 00:17:13.442742 12945 sgd_solver.cpp:114] Iteration 17000, lr = 0.00166667
I1105 00:17:27.095770 12945 solver.cpp:218] Iteration 17100 (7.32468 iter/s, 13.6525s/100 iters), loss = 0.0119229
I1105 00:17:27.095814 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0119228 (* 1 = 0.0119228 loss)
I1105 00:17:27.095820 12945 sgd_solver.cpp:114] Iteration 17100, lr = 0.00161111
I1105 00:17:40.750968 12945 solver.cpp:218] Iteration 17200 (7.32354 iter/s, 13.6546s/100 iters), loss = 0.0178225
I1105 00:17:40.750993 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0178224 (* 1 = 0.0178224 loss)
I1105 00:17:40.750998 12945 sgd_solver.cpp:114] Iteration 17200, lr = 0.00155556
I1105 00:17:54.406438 12945 solver.cpp:218] Iteration 17300 (7.32339 iter/s, 13.6549s/100 iters), loss = 0.0388488
I1105 00:17:54.406462 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0388488 (* 1 = 0.0388488 loss)
I1105 00:17:54.406467 12945 sgd_solver.cpp:114] Iteration 17300, lr = 0.0015
I1105 00:18:08.060778 12945 solver.cpp:218] Iteration 17400 (7.32399 iter/s, 13.6538s/100 iters), loss = 0.00968577
I1105 00:18:08.060820 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.00968575 (* 1 = 0.00968575 loss)
I1105 00:18:08.060825 12945 sgd_solver.cpp:114] Iteration 17400, lr = 0.00144444
I1105 00:18:21.710763 12945 solver.cpp:218] Iteration 17500 (7.32634 iter/s, 13.6494s/100 iters), loss = 0.0136847
I1105 00:18:21.710789 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0136847 (* 1 = 0.0136847 loss)
I1105 00:18:21.710794 12945 sgd_solver.cpp:114] Iteration 17500, lr = 0.00138889
I1105 00:18:35.369452 12945 solver.cpp:218] Iteration 17600 (7.32166 iter/s, 13.6581s/100 iters), loss = 0.0168981
I1105 00:18:35.369477 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0168981 (* 1 = 0.0168981 loss)
I1105 00:18:35.369482 12945 sgd_solver.cpp:114] Iteration 17600, lr = 0.00133333
I1105 00:18:49.027446 12945 solver.cpp:218] Iteration 17700 (7.32203 iter/s, 13.6574s/100 iters), loss = 0.0126459
I1105 00:18:49.027551 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0126459 (* 1 = 0.0126459 loss)
I1105 00:18:49.027559 12945 sgd_solver.cpp:114] Iteration 17700, lr = 0.00127778
I1105 00:19:02.680311 12945 solver.cpp:218] Iteration 17800 (7.32483 iter/s, 13.6522s/100 iters), loss = 0.00999732
I1105 00:19:02.680335 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0099973 (* 1 = 0.0099973 loss)
I1105 00:19:02.680341 12945 sgd_solver.cpp:114] Iteration 17800, lr = 0.00122222
I1105 00:19:16.325490 12945 solver.cpp:218] Iteration 17900 (7.32891 iter/s, 13.6446s/100 iters), loss = 0.00654217
I1105 00:19:16.325516 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.00654215 (* 1 = 0.00654215 loss)
I1105 00:19:16.325521 12945 sgd_solver.cpp:114] Iteration 17900, lr = 0.00116667
I1105 00:19:29.982312 12945 solver.cpp:218] Iteration 18000 (7.32266 iter/s, 13.6562s/100 iters), loss = 0.00838063
I1105 00:19:29.982376 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.00838061 (* 1 = 0.00838061 loss)
I1105 00:19:29.982383 12945 sgd_solver.cpp:114] Iteration 18000, lr = 0.00111111
I1105 00:19:43.638998 12945 solver.cpp:218] Iteration 18100 (7.32276 iter/s, 13.6561s/100 iters), loss = 0.00907243
I1105 00:19:43.639022 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.00907241 (* 1 = 0.00907241 loss)
I1105 00:19:43.639029 12945 sgd_solver.cpp:114] Iteration 18100, lr = 0.00105556
I1105 00:19:57.294826 12945 solver.cpp:218] Iteration 18200 (7.3232 iter/s, 13.6552s/100 iters), loss = 0.052688
I1105 00:19:57.294852 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.052688 (* 1 = 0.052688 loss)
I1105 00:19:57.294857 12945 sgd_solver.cpp:114] Iteration 18200, lr = 0.001
I1105 00:20:10.941723 12945 solver.cpp:218] Iteration 18300 (7.32799 iter/s, 13.6463s/100 iters), loss = 0.00881341
I1105 00:20:10.941831 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.00881339 (* 1 = 0.00881339 loss)
I1105 00:20:10.941839 12945 sgd_solver.cpp:114] Iteration 18300, lr = 0.000944445
I1105 00:20:24.596076 12945 solver.cpp:218] Iteration 18400 (7.32403 iter/s, 13.6537s/100 iters), loss = 0.0290644
I1105 00:20:24.596101 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0290643 (* 1 = 0.0290643 loss)
I1105 00:20:24.596105 12945 sgd_solver.cpp:114] Iteration 18400, lr = 0.000888889
I1105 00:20:38.253409 12945 solver.cpp:218] Iteration 18500 (7.32239 iter/s, 13.6567s/100 iters), loss = 0.00924746
I1105 00:20:38.253434 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.00924745 (* 1 = 0.00924745 loss)
I1105 00:20:38.253439 12945 sgd_solver.cpp:114] Iteration 18500, lr = 0.000833333
I1105 00:20:51.922453 12945 solver.cpp:218] Iteration 18600 (7.31612 iter/s, 13.6685s/100 iters), loss = 0.013016
I1105 00:20:51.922492 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.013016 (* 1 = 0.013016 loss)
I1105 00:20:51.922497 12945 sgd_solver.cpp:114] Iteration 18600, lr = 0.000777778
I1105 00:21:05.560209 12945 solver.cpp:218] Iteration 18700 (7.33291 iter/s, 13.6372s/100 iters), loss = 0.0079067
I1105 00:21:05.560235 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.00790669 (* 1 = 0.00790669 loss)
I1105 00:21:05.560240 12945 sgd_solver.cpp:114] Iteration 18700, lr = 0.000722222
I1105 00:21:19.216280 12945 solver.cpp:218] Iteration 18800 (7.32307 iter/s, 13.6555s/100 iters), loss = 0.0150901
I1105 00:21:19.216305 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.01509 (* 1 = 0.01509 loss)
I1105 00:21:19.216310 12945 sgd_solver.cpp:114] Iteration 18800, lr = 0.000666667
I1105 00:21:32.868746 12945 solver.cpp:218] Iteration 18900 (7.325 iter/s, 13.6519s/100 iters), loss = 0.0177709
I1105 00:21:32.868852 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0177709 (* 1 = 0.0177709 loss)
I1105 00:21:32.868860 12945 sgd_solver.cpp:114] Iteration 18900, lr = 0.000611111
I1105 00:21:46.523357 12945 solver.cpp:218] Iteration 19000 (7.32389 iter/s, 13.6539s/100 iters), loss = 0.0141693
I1105 00:21:46.523382 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0141693 (* 1 = 0.0141693 loss)
I1105 00:21:46.523386 12945 sgd_solver.cpp:114] Iteration 19000, lr = 0.000555556
I1105 00:22:00.192404 12945 solver.cpp:218] Iteration 19100 (7.31611 iter/s, 13.6685s/100 iters), loss = 0.0126781
I1105 00:22:00.192430 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0126781 (* 1 = 0.0126781 loss)
I1105 00:22:00.192435 12945 sgd_solver.cpp:114] Iteration 19100, lr = 0.0005
I1105 00:22:13.826442 12945 solver.cpp:218] Iteration 19200 (7.3349 iter/s, 13.6335s/100 iters), loss = 0.0101096
I1105 00:22:13.826483 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0101096 (* 1 = 0.0101096 loss)
I1105 00:22:13.826489 12945 sgd_solver.cpp:114] Iteration 19200, lr = 0.000444444
I1105 00:22:27.485836 12945 solver.cpp:218] Iteration 19300 (7.32129 iter/s, 13.6588s/100 iters), loss = 0.0303264
I1105 00:22:27.485862 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0303263 (* 1 = 0.0303263 loss)
I1105 00:22:27.485867 12945 sgd_solver.cpp:114] Iteration 19300, lr = 0.000388889
I1105 00:22:41.140872 12945 solver.cpp:218] Iteration 19400 (7.32362 iter/s, 13.6544s/100 iters), loss = 0.0168488
I1105 00:22:41.140897 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0168488 (* 1 = 0.0168488 loss)
I1105 00:22:41.140902 12945 sgd_solver.cpp:114] Iteration 19400, lr = 0.000333334
I1105 00:22:54.791155 12945 solver.cpp:218] Iteration 19500 (7.32617 iter/s, 13.6497s/100 iters), loss = 0.0113365
I1105 00:22:54.791220 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0113365 (* 1 = 0.0113365 loss)
I1105 00:22:54.791226 12945 sgd_solver.cpp:114] Iteration 19500, lr = 0.000277778
I1105 00:23:08.446874 12945 solver.cpp:218] Iteration 19600 (7.32328 iter/s, 13.6551s/100 iters), loss = 0.0173125
I1105 00:23:08.446899 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0173125 (* 1 = 0.0173125 loss)
I1105 00:23:08.446904 12945 sgd_solver.cpp:114] Iteration 19600, lr = 0.000222222
I1105 00:23:22.100312 12945 solver.cpp:218] Iteration 19700 (7.32448 iter/s, 13.6528s/100 iters), loss = 0.0177948
I1105 00:23:22.100337 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.0177948 (* 1 = 0.0177948 loss)
I1105 00:23:22.100343 12945 sgd_solver.cpp:114] Iteration 19700, lr = 0.000166667
I1105 00:23:35.752112 12945 solver.cpp:218] Iteration 19800 (7.32536 iter/s, 13.6512s/100 iters), loss = 0.016878
I1105 00:23:35.752233 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.016878 (* 1 = 0.016878 loss)
I1105 00:23:35.752240 12945 sgd_solver.cpp:114] Iteration 19800, lr = 0.000111111
I1105 00:23:49.408907 12945 solver.cpp:218] Iteration 19900 (7.32273 iter/s, 13.6561s/100 iters), loss = 0.00481163
I1105 00:23:49.408932 12945 solver.cpp:237]     Train net output #0: eucli_loss = 0.00481162 (* 1 = 0.00481162 loss)
I1105 00:23:49.408937 12945 sgd_solver.cpp:114] Iteration 19900, lr = 5.55557e-05
I1105 00:24:02.926296 12945 solver.cpp:447] Snapshotting to binary proto file ./snapshot/1/alex-dy_iter_20000.caffemodel
I1105 00:24:03.151501 12945 sgd_solver.cpp:282] Snapshotting solver state to binary proto file ./snapshot/1/alex-dy_iter_20000.solverstate
I1105 00:24:03.328270 12945 solver.cpp:310] Iteration 20000, loss = 0.0187761
I1105 00:24:03.328290 12945 solver.cpp:330] Iteration 20000, Testing net (#0)
I1105 00:24:03.328294 12945 net.cpp:676] Ignoring source layer data
I1105 00:24:03.328295 12945 net.cpp:676] Ignoring source layer embedding_fc1
I1105 00:24:03.328297 12945 net.cpp:676] Ignoring source layer bn_embedding_fc1
I1105 00:24:03.328300 12945 net.cpp:676] Ignoring source layer scale_embedding_fc1
I1105 00:24:03.328302 12945 net.cpp:676] Ignoring source layer relu_embedding_fc1
I1105 00:24:03.328305 12945 net.cpp:676] Ignoring source layer embedding_fc2
I1105 00:24:03.328306 12945 net.cpp:676] Ignoring source layer embedding_fc2_embedding_fc2_0_split
I1105 00:24:03.328308 12945 net.cpp:676] Ignoring source layer conv1
I1105 00:24:03.328310 12945 net.cpp:676] Ignoring source layer bn_conv1
I1105 00:24:03.328312 12945 net.cpp:676] Ignoring source layer scale_conv1
I1105 00:24:03.328315 12945 net.cpp:676] Ignoring source layer relu1
I1105 00:24:03.328317 12945 net.cpp:676] Ignoring source layer pool1
I1105 00:24:03.328318 12945 net.cpp:676] Ignoring source layer filter_ip2
I1105 00:24:03.328322 12945 net.cpp:676] Ignoring source layer conv2
I1105 00:24:03.328325 12945 net.cpp:676] Ignoring source layer bn_conv2
I1105 00:24:03.328327 12945 net.cpp:676] Ignoring source layer scale_conv2
I1105 00:24:03.328330 12945 net.cpp:676] Ignoring source layer relu2
I1105 00:24:03.328332 12945 net.cpp:676] Ignoring source layer pool2
I1105 00:24:03.328334 12945 net.cpp:676] Ignoring source layer filter_ip3
I1105 00:24:03.328337 12945 net.cpp:676] Ignoring source layer conv3
I1105 00:24:03.328339 12945 net.cpp:676] Ignoring source layer bn_conv3
I1105 00:24:03.328341 12945 net.cpp:676] Ignoring source layer scale_conv3
I1105 00:24:03.328344 12945 net.cpp:676] Ignoring source layer relu3
I1105 00:24:03.328372 12945 net.cpp:676] Ignoring source layer filter_ip4
I1105 00:24:03.328375 12945 net.cpp:676] Ignoring source layer conv4
I1105 00:24:03.328377 12945 net.cpp:676] Ignoring source layer bn_conv4
I1105 00:24:03.328380 12945 net.cpp:676] Ignoring source layer scale_conv4
I1105 00:24:03.328383 12945 net.cpp:676] Ignoring source layer relu4
I1105 00:24:03.328385 12945 net.cpp:676] Ignoring source layer filter_ip5
I1105 00:24:03.328388 12945 net.cpp:676] Ignoring source layer conv5
I1105 00:24:03.328390 12945 net.cpp:676] Ignoring source layer bn_conv5
I1105 00:24:03.328394 12945 net.cpp:676] Ignoring source layer scale_conv5
I1105 00:24:03.328397 12945 net.cpp:676] Ignoring source layer relu5
I1105 00:24:03.328399 12945 net.cpp:676] Ignoring source layer pool5
I1105 00:24:03.328423 12945 net.cpp:676] Ignoring source layer filter_ip6
I1105 00:24:03.328425 12945 net.cpp:676] Ignoring source layer feat0
I1105 00:24:03.328428 12945 net.cpp:676] Ignoring source layer bn_feat0
I1105 00:24:03.328430 12945 net.cpp:676] Ignoring source layer scale_feat0
I1105 00:24:03.328433 12945 net.cpp:676] Ignoring source layer relu_feat0
I1105 00:24:03.328436 12945 net.cpp:676] Ignoring source layer filter_ip7
I1105 00:24:03.328438 12945 net.cpp:676] Ignoring source layer feat1
I1105 00:24:03.328441 12945 net.cpp:676] Ignoring source layer eucli_loss
W1105 00:24:03.555882 12945 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W1105 00:24:03.555917 12945 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W1105 00:24:03.555920 12945 _caffe.cpp:142] Net('./alexnet-deploy-dy.prototxt', 1, weights='./snapshot/1/alex-dy_iter_20000.caffemodel')
I1105 00:24:03.556128 12945 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./alexnet-deploy-dy.prototxt
I1105 00:24:03.556135 12945 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W1105 00:24:03.556138 12945 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I1105 00:24:03.556327 12945 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-aanet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "extra"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 2
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding_fc1"
  type: "InnerProduct"
  bottom: "extra"
  top: "embedding_fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_embedding_fc1"
  type: "BatchNorm"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_embedding_fc1"
  type: "Scale"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_embedding_fc1"
  type: "ReLU"
  bottom: "embedding_fc1"
  top: "embedding_fc1"
}
layer {
  name: "embedding_fc2"
  type: "InnerProduct"
  bottom: "embedding_fc1"
  top: "embedding_fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip2"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 307200
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  bottom: "filter_ip2"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip3"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 884736
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  bottom: "filter_ip3"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "filter_ip4"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 663552
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  bottom: "filter_ip4"
  top: "conv4"
  param {
    name: "conv4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "filter_ip5"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 442368
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  bottom: "filter_ip5"
  top: "conv5"
  param {
    name: "conv5_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_conv5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_conv5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "filter_ip6"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4718592
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "feat0"
  type: "Convolution"
  bottom: "pool5"
  bottom: "filter_ip6"
  top: "feat0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 6
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
layer {
  name: "bn_feat0"
  type: "BatchNorm"
  bottom: "feat0"
  top: "feat0"
  batch_norm_param {
    moving_average_fraction: 0.999
  }
}
layer {
  name: "scale_feat0"
  type: "Scale"
  bottom: "feat0"
  top: "feat0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_feat0"
  type: "ReLU"
  bottom: "feat0"
  top: "feat0"
}
layer {
  name: "filter_ip7"
  type: "InnerProduct"
  bottom: "embedding_fc2"
  top: "filter_ip7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "feat1"
  type: "Convolution"
  bottom: "feat0"
  bottom: "filter_ip7"
  top: "feat1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
    weight_operation: COPY
  }
}
I1105 00:24:03.556421 12945 layer_factory.hpp:77] Creating layer input
I1105 00:24:03.556427 12945 net.cpp:84] Creating Layer input
I1105 00:24:03.556430 12945 net.cpp:380] input -> data
I1105 00:24:03.556437 12945 net.cpp:380] input -> extra
I1105 00:24:03.556524 12945 net.cpp:122] Setting up input
I1105 00:24:03.556527 12945 net.cpp:129] Top shape: 1 3 224 224 (150528)
I1105 00:24:03.556529 12945 net.cpp:129] Top shape: 1 2 1 1 (2)
I1105 00:24:03.556532 12945 net.cpp:137] Memory required for data: 602120
I1105 00:24:03.556535 12945 layer_factory.hpp:77] Creating layer embedding_fc1
I1105 00:24:03.556538 12945 net.cpp:84] Creating Layer embedding_fc1
I1105 00:24:03.556540 12945 net.cpp:406] embedding_fc1 <- extra
I1105 00:24:03.556545 12945 net.cpp:380] embedding_fc1 -> embedding_fc1
I1105 00:24:03.556646 12945 net.cpp:122] Setting up embedding_fc1
I1105 00:24:03.556650 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:24:03.556651 12945 net.cpp:137] Memory required for data: 603144
I1105 00:24:03.556658 12945 layer_factory.hpp:77] Creating layer bn_embedding_fc1
I1105 00:24:03.556663 12945 net.cpp:84] Creating Layer bn_embedding_fc1
I1105 00:24:03.556664 12945 net.cpp:406] bn_embedding_fc1 <- embedding_fc1
I1105 00:24:03.556668 12945 net.cpp:367] bn_embedding_fc1 -> embedding_fc1 (in-place)
I1105 00:24:03.556821 12945 net.cpp:122] Setting up bn_embedding_fc1
I1105 00:24:03.556824 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:24:03.556826 12945 net.cpp:137] Memory required for data: 604168
I1105 00:24:03.556831 12945 layer_factory.hpp:77] Creating layer scale_embedding_fc1
I1105 00:24:03.556836 12945 net.cpp:84] Creating Layer scale_embedding_fc1
I1105 00:24:03.556838 12945 net.cpp:406] scale_embedding_fc1 <- embedding_fc1
I1105 00:24:03.556841 12945 net.cpp:367] scale_embedding_fc1 -> embedding_fc1 (in-place)
I1105 00:24:03.556870 12945 layer_factory.hpp:77] Creating layer scale_embedding_fc1
I1105 00:24:03.556959 12945 net.cpp:122] Setting up scale_embedding_fc1
I1105 00:24:03.556962 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:24:03.556964 12945 net.cpp:137] Memory required for data: 605192
I1105 00:24:03.556968 12945 layer_factory.hpp:77] Creating layer relu_embedding_fc1
I1105 00:24:03.556972 12945 net.cpp:84] Creating Layer relu_embedding_fc1
I1105 00:24:03.556979 12945 net.cpp:406] relu_embedding_fc1 <- embedding_fc1
I1105 00:24:03.556982 12945 net.cpp:367] relu_embedding_fc1 -> embedding_fc1 (in-place)
I1105 00:24:03.557226 12945 net.cpp:122] Setting up relu_embedding_fc1
I1105 00:24:03.557231 12945 net.cpp:129] Top shape: 1 256 (256)
I1105 00:24:03.557233 12945 net.cpp:137] Memory required for data: 606216
I1105 00:24:03.557235 12945 layer_factory.hpp:77] Creating layer embedding_fc2
I1105 00:24:03.557240 12945 net.cpp:84] Creating Layer embedding_fc2
I1105 00:24:03.557241 12945 net.cpp:406] embedding_fc2 <- embedding_fc1
I1105 00:24:03.557245 12945 net.cpp:380] embedding_fc2 -> embedding_fc2
I1105 00:24:03.557333 12945 net.cpp:122] Setting up embedding_fc2
I1105 00:24:03.557337 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:24:03.557338 12945 net.cpp:137] Memory required for data: 606220
I1105 00:24:03.557343 12945 layer_factory.hpp:77] Creating layer embedding_fc2_embedding_fc2_0_split
I1105 00:24:03.557346 12945 net.cpp:84] Creating Layer embedding_fc2_embedding_fc2_0_split
I1105 00:24:03.557348 12945 net.cpp:406] embedding_fc2_embedding_fc2_0_split <- embedding_fc2
I1105 00:24:03.557353 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_0
I1105 00:24:03.557356 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_1
I1105 00:24:03.557360 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_2
I1105 00:24:03.557364 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_3
I1105 00:24:03.557368 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_4
I1105 00:24:03.557371 12945 net.cpp:380] embedding_fc2_embedding_fc2_0_split -> embedding_fc2_embedding_fc2_0_split_5
I1105 00:24:03.557440 12945 net.cpp:122] Setting up embedding_fc2_embedding_fc2_0_split
I1105 00:24:03.557442 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:24:03.557446 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:24:03.557447 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:24:03.557449 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:24:03.557451 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:24:03.557454 12945 net.cpp:129] Top shape: 1 1 (1)
I1105 00:24:03.557456 12945 net.cpp:137] Memory required for data: 606244
I1105 00:24:03.557457 12945 layer_factory.hpp:77] Creating layer conv1
I1105 00:24:03.557462 12945 net.cpp:84] Creating Layer conv1
I1105 00:24:03.557466 12945 net.cpp:406] conv1 <- data
I1105 00:24:03.557469 12945 net.cpp:380] conv1 -> conv1
I1105 00:24:03.557902 12945 net.cpp:122] Setting up conv1
I1105 00:24:03.557906 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:24:03.557909 12945 net.cpp:137] Memory required for data: 1725988
I1105 00:24:03.557912 12945 layer_factory.hpp:77] Creating layer bn_conv1
I1105 00:24:03.557916 12945 net.cpp:84] Creating Layer bn_conv1
I1105 00:24:03.557919 12945 net.cpp:406] bn_conv1 <- conv1
I1105 00:24:03.557921 12945 net.cpp:367] bn_conv1 -> conv1 (in-place)
I1105 00:24:03.558085 12945 net.cpp:122] Setting up bn_conv1
I1105 00:24:03.558089 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:24:03.558091 12945 net.cpp:137] Memory required for data: 2845732
I1105 00:24:03.558095 12945 layer_factory.hpp:77] Creating layer scale_conv1
I1105 00:24:03.558099 12945 net.cpp:84] Creating Layer scale_conv1
I1105 00:24:03.558100 12945 net.cpp:406] scale_conv1 <- conv1
I1105 00:24:03.558104 12945 net.cpp:367] scale_conv1 -> conv1 (in-place)
I1105 00:24:03.558135 12945 layer_factory.hpp:77] Creating layer scale_conv1
I1105 00:24:03.558234 12945 net.cpp:122] Setting up scale_conv1
I1105 00:24:03.558238 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:24:03.558239 12945 net.cpp:137] Memory required for data: 3965476
I1105 00:24:03.558243 12945 layer_factory.hpp:77] Creating layer relu1
I1105 00:24:03.558246 12945 net.cpp:84] Creating Layer relu1
I1105 00:24:03.558248 12945 net.cpp:406] relu1 <- conv1
I1105 00:24:03.558250 12945 net.cpp:367] relu1 -> conv1 (in-place)
I1105 00:24:03.558454 12945 net.cpp:122] Setting up relu1
I1105 00:24:03.558459 12945 net.cpp:129] Top shape: 1 96 54 54 (279936)
I1105 00:24:03.558460 12945 net.cpp:137] Memory required for data: 5085220
I1105 00:24:03.558462 12945 layer_factory.hpp:77] Creating layer pool1
I1105 00:24:03.558466 12945 net.cpp:84] Creating Layer pool1
I1105 00:24:03.558468 12945 net.cpp:406] pool1 <- conv1
I1105 00:24:03.558471 12945 net.cpp:380] pool1 -> pool1
I1105 00:24:03.558506 12945 net.cpp:122] Setting up pool1
I1105 00:24:03.558509 12945 net.cpp:129] Top shape: 1 96 27 27 (69984)
I1105 00:24:03.558511 12945 net.cpp:137] Memory required for data: 5365156
I1105 00:24:03.558512 12945 layer_factory.hpp:77] Creating layer filter_ip2
I1105 00:24:03.558516 12945 net.cpp:84] Creating Layer filter_ip2
I1105 00:24:03.558518 12945 net.cpp:406] filter_ip2 <- embedding_fc2_embedding_fc2_0_split_0
I1105 00:24:03.558522 12945 net.cpp:380] filter_ip2 -> filter_ip2
I1105 00:24:03.561645 12945 net.cpp:122] Setting up filter_ip2
I1105 00:24:03.561655 12945 net.cpp:129] Top shape: 1 307200 (307200)
I1105 00:24:03.561656 12945 net.cpp:137] Memory required for data: 6593956
I1105 00:24:03.561663 12945 layer_factory.hpp:77] Creating layer conv2
I1105 00:24:03.561669 12945 net.cpp:84] Creating Layer conv2
I1105 00:24:03.561671 12945 net.cpp:406] conv2 <- pool1
I1105 00:24:03.561676 12945 net.cpp:406] conv2 <- filter_ip2
I1105 00:24:03.561678 12945 net.cpp:380] conv2 -> conv2
I1105 00:24:03.564175 12945 net.cpp:122] Setting up conv2
I1105 00:24:03.564182 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:24:03.564185 12945 net.cpp:137] Memory required for data: 7340452
I1105 00:24:03.564188 12945 layer_factory.hpp:77] Creating layer bn_conv2
I1105 00:24:03.564193 12945 net.cpp:84] Creating Layer bn_conv2
I1105 00:24:03.564195 12945 net.cpp:406] bn_conv2 <- conv2
I1105 00:24:03.564198 12945 net.cpp:367] bn_conv2 -> conv2 (in-place)
I1105 00:24:03.564364 12945 net.cpp:122] Setting up bn_conv2
I1105 00:24:03.564368 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:24:03.564369 12945 net.cpp:137] Memory required for data: 8086948
I1105 00:24:03.564374 12945 layer_factory.hpp:77] Creating layer scale_conv2
I1105 00:24:03.564378 12945 net.cpp:84] Creating Layer scale_conv2
I1105 00:24:03.564380 12945 net.cpp:406] scale_conv2 <- conv2
I1105 00:24:03.564383 12945 net.cpp:367] scale_conv2 -> conv2 (in-place)
I1105 00:24:03.564414 12945 layer_factory.hpp:77] Creating layer scale_conv2
I1105 00:24:03.564510 12945 net.cpp:122] Setting up scale_conv2
I1105 00:24:03.564513 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:24:03.564515 12945 net.cpp:137] Memory required for data: 8833444
I1105 00:24:03.564519 12945 layer_factory.hpp:77] Creating layer relu2
I1105 00:24:03.564524 12945 net.cpp:84] Creating Layer relu2
I1105 00:24:03.564527 12945 net.cpp:406] relu2 <- conv2
I1105 00:24:03.564528 12945 net.cpp:367] relu2 -> conv2 (in-place)
I1105 00:24:03.564749 12945 net.cpp:122] Setting up relu2
I1105 00:24:03.564754 12945 net.cpp:129] Top shape: 1 256 27 27 (186624)
I1105 00:24:03.564756 12945 net.cpp:137] Memory required for data: 9579940
I1105 00:24:03.564759 12945 layer_factory.hpp:77] Creating layer pool2
I1105 00:24:03.564762 12945 net.cpp:84] Creating Layer pool2
I1105 00:24:03.564764 12945 net.cpp:406] pool2 <- conv2
I1105 00:24:03.564767 12945 net.cpp:380] pool2 -> pool2
I1105 00:24:03.564801 12945 net.cpp:122] Setting up pool2
I1105 00:24:03.564805 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:24:03.564807 12945 net.cpp:137] Memory required for data: 9752996
I1105 00:24:03.564810 12945 layer_factory.hpp:77] Creating layer filter_ip3
I1105 00:24:03.564813 12945 net.cpp:84] Creating Layer filter_ip3
I1105 00:24:03.564815 12945 net.cpp:406] filter_ip3 <- embedding_fc2_embedding_fc2_0_split_1
I1105 00:24:03.564818 12945 net.cpp:380] filter_ip3 -> filter_ip3
I1105 00:24:03.571971 12945 net.cpp:122] Setting up filter_ip3
I1105 00:24:03.571985 12945 net.cpp:129] Top shape: 1 884736 (884736)
I1105 00:24:03.572002 12945 net.cpp:137] Memory required for data: 13291940
I1105 00:24:03.572010 12945 layer_factory.hpp:77] Creating layer conv3
I1105 00:24:03.572018 12945 net.cpp:84] Creating Layer conv3
I1105 00:24:03.572021 12945 net.cpp:406] conv3 <- pool2
I1105 00:24:03.572024 12945 net.cpp:406] conv3 <- filter_ip3
I1105 00:24:03.572028 12945 net.cpp:380] conv3 -> conv3
I1105 00:24:03.578260 12945 net.cpp:122] Setting up conv3
I1105 00:24:03.578270 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:24:03.578274 12945 net.cpp:137] Memory required for data: 13551524
I1105 00:24:03.578279 12945 layer_factory.hpp:77] Creating layer bn_conv3
I1105 00:24:03.578284 12945 net.cpp:84] Creating Layer bn_conv3
I1105 00:24:03.578285 12945 net.cpp:406] bn_conv3 <- conv3
I1105 00:24:03.578289 12945 net.cpp:367] bn_conv3 -> conv3 (in-place)
I1105 00:24:03.578459 12945 net.cpp:122] Setting up bn_conv3
I1105 00:24:03.578462 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:24:03.578464 12945 net.cpp:137] Memory required for data: 13811108
I1105 00:24:03.578469 12945 layer_factory.hpp:77] Creating layer scale_conv3
I1105 00:24:03.578472 12945 net.cpp:84] Creating Layer scale_conv3
I1105 00:24:03.578474 12945 net.cpp:406] scale_conv3 <- conv3
I1105 00:24:03.578477 12945 net.cpp:367] scale_conv3 -> conv3 (in-place)
I1105 00:24:03.578507 12945 layer_factory.hpp:77] Creating layer scale_conv3
I1105 00:24:03.578603 12945 net.cpp:122] Setting up scale_conv3
I1105 00:24:03.578608 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:24:03.578609 12945 net.cpp:137] Memory required for data: 14070692
I1105 00:24:03.578616 12945 layer_factory.hpp:77] Creating layer relu3
I1105 00:24:03.578620 12945 net.cpp:84] Creating Layer relu3
I1105 00:24:03.578621 12945 net.cpp:406] relu3 <- conv3
I1105 00:24:03.578624 12945 net.cpp:367] relu3 -> conv3 (in-place)
I1105 00:24:03.578933 12945 net.cpp:122] Setting up relu3
I1105 00:24:03.578938 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:24:03.578939 12945 net.cpp:137] Memory required for data: 14330276
I1105 00:24:03.578941 12945 layer_factory.hpp:77] Creating layer filter_ip4
I1105 00:24:03.578946 12945 net.cpp:84] Creating Layer filter_ip4
I1105 00:24:03.578949 12945 net.cpp:406] filter_ip4 <- embedding_fc2_embedding_fc2_0_split_2
I1105 00:24:03.578953 12945 net.cpp:380] filter_ip4 -> filter_ip4
I1105 00:24:03.584450 12945 net.cpp:122] Setting up filter_ip4
I1105 00:24:03.584461 12945 net.cpp:129] Top shape: 1 663552 (663552)
I1105 00:24:03.584463 12945 net.cpp:137] Memory required for data: 16984484
I1105 00:24:03.584470 12945 layer_factory.hpp:77] Creating layer conv4
I1105 00:24:03.584477 12945 net.cpp:84] Creating Layer conv4
I1105 00:24:03.584481 12945 net.cpp:406] conv4 <- conv3
I1105 00:24:03.584483 12945 net.cpp:406] conv4 <- filter_ip4
I1105 00:24:03.584487 12945 net.cpp:380] conv4 -> conv4
I1105 00:24:03.589329 12945 net.cpp:122] Setting up conv4
I1105 00:24:03.589337 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:24:03.589339 12945 net.cpp:137] Memory required for data: 17244068
I1105 00:24:03.589344 12945 layer_factory.hpp:77] Creating layer bn_conv4
I1105 00:24:03.589349 12945 net.cpp:84] Creating Layer bn_conv4
I1105 00:24:03.589351 12945 net.cpp:406] bn_conv4 <- conv4
I1105 00:24:03.589355 12945 net.cpp:367] bn_conv4 -> conv4 (in-place)
I1105 00:24:03.589525 12945 net.cpp:122] Setting up bn_conv4
I1105 00:24:03.589529 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:24:03.589531 12945 net.cpp:137] Memory required for data: 17503652
I1105 00:24:03.589536 12945 layer_factory.hpp:77] Creating layer scale_conv4
I1105 00:24:03.589540 12945 net.cpp:84] Creating Layer scale_conv4
I1105 00:24:03.589541 12945 net.cpp:406] scale_conv4 <- conv4
I1105 00:24:03.589545 12945 net.cpp:367] scale_conv4 -> conv4 (in-place)
I1105 00:24:03.589574 12945 layer_factory.hpp:77] Creating layer scale_conv4
I1105 00:24:03.589670 12945 net.cpp:122] Setting up scale_conv4
I1105 00:24:03.589674 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:24:03.589691 12945 net.cpp:137] Memory required for data: 17763236
I1105 00:24:03.589695 12945 layer_factory.hpp:77] Creating layer relu4
I1105 00:24:03.589699 12945 net.cpp:84] Creating Layer relu4
I1105 00:24:03.589700 12945 net.cpp:406] relu4 <- conv4
I1105 00:24:03.589704 12945 net.cpp:367] relu4 -> conv4 (in-place)
I1105 00:24:03.590026 12945 net.cpp:122] Setting up relu4
I1105 00:24:03.590032 12945 net.cpp:129] Top shape: 1 384 13 13 (64896)
I1105 00:24:03.590034 12945 net.cpp:137] Memory required for data: 18022820
I1105 00:24:03.590036 12945 layer_factory.hpp:77] Creating layer filter_ip5
I1105 00:24:03.590041 12945 net.cpp:84] Creating Layer filter_ip5
I1105 00:24:03.590044 12945 net.cpp:406] filter_ip5 <- embedding_fc2_embedding_fc2_0_split_3
I1105 00:24:03.590047 12945 net.cpp:380] filter_ip5 -> filter_ip5
I1105 00:24:03.593855 12945 net.cpp:122] Setting up filter_ip5
I1105 00:24:03.593864 12945 net.cpp:129] Top shape: 1 442368 (442368)
I1105 00:24:03.593868 12945 net.cpp:137] Memory required for data: 19792292
I1105 00:24:03.593873 12945 layer_factory.hpp:77] Creating layer conv5
I1105 00:24:03.593879 12945 net.cpp:84] Creating Layer conv5
I1105 00:24:03.593883 12945 net.cpp:406] conv5 <- conv4
I1105 00:24:03.593885 12945 net.cpp:406] conv5 <- filter_ip5
I1105 00:24:03.593888 12945 net.cpp:380] conv5 -> conv5
I1105 00:24:03.597229 12945 net.cpp:122] Setting up conv5
I1105 00:24:03.597237 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:24:03.597239 12945 net.cpp:137] Memory required for data: 19965348
I1105 00:24:03.597244 12945 layer_factory.hpp:77] Creating layer bn_conv5
I1105 00:24:03.597249 12945 net.cpp:84] Creating Layer bn_conv5
I1105 00:24:03.597251 12945 net.cpp:406] bn_conv5 <- conv5
I1105 00:24:03.597254 12945 net.cpp:367] bn_conv5 -> conv5 (in-place)
I1105 00:24:03.597426 12945 net.cpp:122] Setting up bn_conv5
I1105 00:24:03.597430 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:24:03.597432 12945 net.cpp:137] Memory required for data: 20138404
I1105 00:24:03.597436 12945 layer_factory.hpp:77] Creating layer scale_conv5
I1105 00:24:03.597440 12945 net.cpp:84] Creating Layer scale_conv5
I1105 00:24:03.597443 12945 net.cpp:406] scale_conv5 <- conv5
I1105 00:24:03.597445 12945 net.cpp:367] scale_conv5 -> conv5 (in-place)
I1105 00:24:03.597477 12945 layer_factory.hpp:77] Creating layer scale_conv5
I1105 00:24:03.597571 12945 net.cpp:122] Setting up scale_conv5
I1105 00:24:03.597575 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:24:03.597577 12945 net.cpp:137] Memory required for data: 20311460
I1105 00:24:03.597580 12945 layer_factory.hpp:77] Creating layer relu5
I1105 00:24:03.597586 12945 net.cpp:84] Creating Layer relu5
I1105 00:24:03.597589 12945 net.cpp:406] relu5 <- conv5
I1105 00:24:03.597591 12945 net.cpp:367] relu5 -> conv5 (in-place)
I1105 00:24:03.597918 12945 net.cpp:122] Setting up relu5
I1105 00:24:03.597923 12945 net.cpp:129] Top shape: 1 256 13 13 (43264)
I1105 00:24:03.597925 12945 net.cpp:137] Memory required for data: 20484516
I1105 00:24:03.597927 12945 layer_factory.hpp:77] Creating layer pool5
I1105 00:24:03.597931 12945 net.cpp:84] Creating Layer pool5
I1105 00:24:03.597934 12945 net.cpp:406] pool5 <- conv5
I1105 00:24:03.597936 12945 net.cpp:380] pool5 -> pool5
I1105 00:24:03.598057 12945 net.cpp:122] Setting up pool5
I1105 00:24:03.598060 12945 net.cpp:129] Top shape: 1 256 6 6 (9216)
I1105 00:24:03.598062 12945 net.cpp:137] Memory required for data: 20521380
I1105 00:24:03.598064 12945 layer_factory.hpp:77] Creating layer filter_ip6
I1105 00:24:03.598069 12945 net.cpp:84] Creating Layer filter_ip6
I1105 00:24:03.598071 12945 net.cpp:406] filter_ip6 <- embedding_fc2_embedding_fc2_0_split_4
I1105 00:24:03.598074 12945 net.cpp:380] filter_ip6 -> filter_ip6
I1105 00:24:03.635085 12945 net.cpp:122] Setting up filter_ip6
I1105 00:24:03.635104 12945 net.cpp:129] Top shape: 1 4718592 (4718592)
I1105 00:24:03.635107 12945 net.cpp:137] Memory required for data: 39395748
I1105 00:24:03.635113 12945 layer_factory.hpp:77] Creating layer feat0
I1105 00:24:03.635143 12945 net.cpp:84] Creating Layer feat0
I1105 00:24:03.635145 12945 net.cpp:406] feat0 <- pool5
I1105 00:24:03.635149 12945 net.cpp:406] feat0 <- filter_ip6
I1105 00:24:03.635154 12945 net.cpp:380] feat0 -> feat0
I1105 00:24:03.667192 12945 net.cpp:122] Setting up feat0
I1105 00:24:03.667209 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:24:03.667212 12945 net.cpp:137] Memory required for data: 39397796
I1105 00:24:03.667217 12945 layer_factory.hpp:77] Creating layer bn_feat0
I1105 00:24:03.667224 12945 net.cpp:84] Creating Layer bn_feat0
I1105 00:24:03.667227 12945 net.cpp:406] bn_feat0 <- feat0
I1105 00:24:03.667232 12945 net.cpp:367] bn_feat0 -> feat0 (in-place)
I1105 00:24:03.667408 12945 net.cpp:122] Setting up bn_feat0
I1105 00:24:03.667412 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:24:03.667414 12945 net.cpp:137] Memory required for data: 39399844
I1105 00:24:03.667418 12945 layer_factory.hpp:77] Creating layer scale_feat0
I1105 00:24:03.667421 12945 net.cpp:84] Creating Layer scale_feat0
I1105 00:24:03.667424 12945 net.cpp:406] scale_feat0 <- feat0
I1105 00:24:03.667426 12945 net.cpp:367] scale_feat0 -> feat0 (in-place)
I1105 00:24:03.667457 12945 layer_factory.hpp:77] Creating layer scale_feat0
I1105 00:24:03.667557 12945 net.cpp:122] Setting up scale_feat0
I1105 00:24:03.667560 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:24:03.667562 12945 net.cpp:137] Memory required for data: 39401892
I1105 00:24:03.667565 12945 layer_factory.hpp:77] Creating layer relu_feat0
I1105 00:24:03.667569 12945 net.cpp:84] Creating Layer relu_feat0
I1105 00:24:03.667572 12945 net.cpp:406] relu_feat0 <- feat0
I1105 00:24:03.667574 12945 net.cpp:367] relu_feat0 -> feat0 (in-place)
I1105 00:24:03.667918 12945 net.cpp:122] Setting up relu_feat0
I1105 00:24:03.667923 12945 net.cpp:129] Top shape: 1 512 1 1 (512)
I1105 00:24:03.667925 12945 net.cpp:137] Memory required for data: 39403940
I1105 00:24:03.667927 12945 layer_factory.hpp:77] Creating layer filter_ip7
I1105 00:24:03.667932 12945 net.cpp:84] Creating Layer filter_ip7
I1105 00:24:03.667934 12945 net.cpp:406] filter_ip7 <- embedding_fc2_embedding_fc2_0_split_5
I1105 00:24:03.667938 12945 net.cpp:380] filter_ip7 -> filter_ip7
I1105 00:24:03.668040 12945 net.cpp:122] Setting up filter_ip7
I1105 00:24:03.668043 12945 net.cpp:129] Top shape: 1 512 (512)
I1105 00:24:03.668045 12945 net.cpp:137] Memory required for data: 39405988
I1105 00:24:03.668048 12945 layer_factory.hpp:77] Creating layer feat1
I1105 00:24:03.668054 12945 net.cpp:84] Creating Layer feat1
I1105 00:24:03.668056 12945 net.cpp:406] feat1 <- feat0
I1105 00:24:03.668058 12945 net.cpp:406] feat1 <- filter_ip7
I1105 00:24:03.668062 12945 net.cpp:380] feat1 -> feat1
I1105 00:24:03.668292 12945 net.cpp:122] Setting up feat1
I1105 00:24:03.668296 12945 net.cpp:129] Top shape: 1 1 1 1 (1)
I1105 00:24:03.668298 12945 net.cpp:137] Memory required for data: 39405992
I1105 00:24:03.668306 12945 net.cpp:200] feat1 does not need backward computation.
I1105 00:24:03.668308 12945 net.cpp:200] filter_ip7 does not need backward computation.
I1105 00:24:03.668310 12945 net.cpp:200] relu_feat0 does not need backward computation.
I1105 00:24:03.668313 12945 net.cpp:200] scale_feat0 does not need backward computation.
I1105 00:24:03.668314 12945 net.cpp:200] bn_feat0 does not need backward computation.
I1105 00:24:03.668316 12945 net.cpp:200] feat0 does not need backward computation.
I1105 00:24:03.668318 12945 net.cpp:200] filter_ip6 does not need backward computation.
I1105 00:24:03.668320 12945 net.cpp:200] pool5 does not need backward computation.
I1105 00:24:03.668323 12945 net.cpp:200] relu5 does not need backward computation.
I1105 00:24:03.668325 12945 net.cpp:200] scale_conv5 does not need backward computation.
I1105 00:24:03.668327 12945 net.cpp:200] bn_conv5 does not need backward computation.
I1105 00:24:03.668329 12945 net.cpp:200] conv5 does not need backward computation.
I1105 00:24:03.668331 12945 net.cpp:200] filter_ip5 does not need backward computation.
I1105 00:24:03.668334 12945 net.cpp:200] relu4 does not need backward computation.
I1105 00:24:03.668352 12945 net.cpp:200] scale_conv4 does not need backward computation.
I1105 00:24:03.668354 12945 net.cpp:200] bn_conv4 does not need backward computation.
I1105 00:24:03.668357 12945 net.cpp:200] conv4 does not need backward computation.
I1105 00:24:03.668359 12945 net.cpp:200] filter_ip4 does not need backward computation.
I1105 00:24:03.668361 12945 net.cpp:200] relu3 does not need backward computation.
I1105 00:24:03.668363 12945 net.cpp:200] scale_conv3 does not need backward computation.
I1105 00:24:03.668365 12945 net.cpp:200] bn_conv3 does not need backward computation.
I1105 00:24:03.668367 12945 net.cpp:200] conv3 does not need backward computation.
I1105 00:24:03.668370 12945 net.cpp:200] filter_ip3 does not need backward computation.
I1105 00:24:03.668371 12945 net.cpp:200] pool2 does not need backward computation.
I1105 00:24:03.668375 12945 net.cpp:200] relu2 does not need backward computation.
I1105 00:24:03.668376 12945 net.cpp:200] scale_conv2 does not need backward computation.
I1105 00:24:03.668377 12945 net.cpp:200] bn_conv2 does not need backward computation.
I1105 00:24:03.668380 12945 net.cpp:200] conv2 does not need backward computation.
I1105 00:24:03.668381 12945 net.cpp:200] filter_ip2 does not need backward computation.
I1105 00:24:03.668383 12945 net.cpp:200] pool1 does not need backward computation.
I1105 00:24:03.668385 12945 net.cpp:200] relu1 does not need backward computation.
I1105 00:24:03.668387 12945 net.cpp:200] scale_conv1 does not need backward computation.
I1105 00:24:03.668390 12945 net.cpp:200] bn_conv1 does not need backward computation.
I1105 00:24:03.668391 12945 net.cpp:200] conv1 does not need backward computation.
I1105 00:24:03.668395 12945 net.cpp:200] embedding_fc2_embedding_fc2_0_split does not need backward computation.
I1105 00:24:03.668396 12945 net.cpp:200] embedding_fc2 does not need backward computation.
I1105 00:24:03.668399 12945 net.cpp:200] relu_embedding_fc1 does not need backward computation.
I1105 00:24:03.668401 12945 net.cpp:200] scale_embedding_fc1 does not need backward computation.
I1105 00:24:03.668402 12945 net.cpp:200] bn_embedding_fc1 does not need backward computation.
I1105 00:24:03.668404 12945 net.cpp:200] embedding_fc1 does not need backward computation.
I1105 00:24:03.668407 12945 net.cpp:200] input does not need backward computation.
I1105 00:24:03.668408 12945 net.cpp:242] This network produces output feat1
I1105 00:24:03.668422 12945 net.cpp:255] Network initialization done.
I1105 00:24:03.699770 12945 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./snapshot/1/alex-dy_iter_20000.caffemodel
I1105 00:24:03.699787 12945 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1105 00:24:03.699790 12945 net.cpp:744] Ignoring source layer data
I1105 00:24:03.758623 12945 net.cpp:744] Ignoring source layer eucli_loss
I1105 00:24:19.585285 12945 solver.cpp:397]     Test net output #0: accuracy = 0.883965
I1105 00:24:19.585358 12945 solver.cpp:397]     Test net output #1: mae = 0.249995
I1105 00:24:19.585364 12945 solver.cpp:397]     Test net output #2: rmse = 0.320316
I1105 00:24:19.585367 12945 solver.cpp:315] Optimization Done.
I1105 00:24:19.585371 12945 caffe.cpp:259] Optimization Done.
